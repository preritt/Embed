{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complete of 04182019_Satim_FullDatasetADAM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/Complete_of_04182019_Satim_FullDatasetADAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0SINGreLFCRz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "My4EmvydE3bW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dTAGPqvlFEuQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ovvpmlXeFH1x",
        "outputId": "af18a765-cfc1-40c8-c0d8-a60e2599476a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "train_data_pandas = pd.DataFrame(train_data)\n",
        "train_data_labels = pd.DataFrame(train_label)\n",
        "train_data_pandas.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.127273</td>\n",
              "      <td>-0.095238</td>\n",
              "      <td>-0.289256</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.054545</td>\n",
              "      <td>-0.157895</td>\n",
              "      <td>-0.265625</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.106796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.138462</td>\n",
              "      <td>-0.188119</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.546875</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.484375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.571429</td>\n",
              "      <td>-0.603306</td>\n",
              "      <td>-0.096774</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.494737</td>\n",
              "      <td>-0.562500</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>-0.106796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.517241</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.015385</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.609375</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.494737</td>\n",
              "      <td>-0.609375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5625</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.074380</td>\n",
              "      <td>0.354839</td>\n",
              "      <td>0.327273</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.1875</td>\n",
              "      <td>0.242718</td>\n",
              "      <td>...</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>-0.233333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.207921</td>\n",
              "      <td>-0.010526</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>-0.15625</td>\n",
              "      <td>0.009709</td>\n",
              "      <td>-0.326316</td>\n",
              "      <td>-0.437500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.018182</td>\n",
              "      <td>-0.380952</td>\n",
              "      <td>-0.471074</td>\n",
              "      <td>-0.225806</td>\n",
              "      <td>-0.163636</td>\n",
              "      <td>-0.410526</td>\n",
              "      <td>-0.437500</td>\n",
              "      <td>-0.3750</td>\n",
              "      <td>-0.242718</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.383333</td>\n",
              "      <td>-0.138462</td>\n",
              "      <td>-0.049505</td>\n",
              "      <td>-0.347368</td>\n",
              "      <td>-0.484375</td>\n",
              "      <td>0.09375</td>\n",
              "      <td>0.087379</td>\n",
              "      <td>-0.031579</td>\n",
              "      <td>-0.218750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.018182</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>-0.471074</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.326316</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.1250</td>\n",
              "      <td>-0.184466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287356</td>\n",
              "      <td>-0.183333</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.267327</td>\n",
              "      <td>-0.031579</td>\n",
              "      <td>-0.281250</td>\n",
              "      <td>-0.03125</td>\n",
              "      <td>-0.126214</td>\n",
              "      <td>-0.431579</td>\n",
              "      <td>-0.546875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2         3         4         5         6   \\\n",
              "0  0.0000  0.127273 -0.095238 -0.289256  0.032258  0.054545 -0.157895   \n",
              "1  0.0000 -0.090909 -0.571429 -0.603306 -0.096774 -0.090909 -0.494737   \n",
              "2  0.5625  0.490909  0.333333 -0.074380  0.354839  0.327273  0.052632   \n",
              "3  0.0000 -0.018182 -0.380952 -0.471074 -0.225806 -0.163636 -0.410526   \n",
              "4  0.0000 -0.018182 -0.285714 -0.471074  0.032258 -0.090909 -0.326316   \n",
              "\n",
              "         7       8         9     ...           26        27        28  \\\n",
              "0 -0.265625 -0.2500 -0.106796    ...    -0.517241 -0.600000 -0.138462   \n",
              "1 -0.562500 -0.2500 -0.106796    ...    -0.517241 -0.600000 -0.015385   \n",
              "2 -0.187500  0.1875  0.242718    ...     0.103448 -0.233333  0.200000   \n",
              "3 -0.437500 -0.3750 -0.242718    ...    -0.011494 -0.383333 -0.138462   \n",
              "4 -0.500000 -0.1250 -0.184466    ...     0.287356 -0.183333  0.230769   \n",
              "\n",
              "         29        30        31       32        33        34        35  \n",
              "0 -0.188119 -0.431579 -0.546875 -0.15625 -0.126214 -0.431579 -0.484375  \n",
              "1 -0.049505 -0.431579 -0.609375 -0.15625 -0.126214 -0.494737 -0.609375  \n",
              "2  0.207921 -0.010526 -0.312500 -0.15625  0.009709 -0.326316 -0.437500  \n",
              "3 -0.049505 -0.347368 -0.484375  0.09375  0.087379 -0.031579 -0.218750  \n",
              "4  0.267327 -0.031579 -0.281250 -0.03125 -0.126214 -0.431579 -0.546875  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "epqBn1YjFlII",
        "outputId": "288b79fa-8b30-4a43-e0f9-020764721cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "train_data_labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  5\n",
              "1  5\n",
              "2  5\n",
              "3  5\n",
              "4  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ewLyg3iuFqkO",
        "outputId": "8641afa7-aa32-4de2-d1f1-de88d9809861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w5wMHmhIFthO",
        "outputId": "65ee5036-a14d-4512-ad1c-42666394adb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Jg0BONTGBA1"
      },
      "cell_type": "markdown",
      "source": [
        "#### Combine Validation and train data for MLP classifier - and set validation fraction to 4500/15000 = 0.3"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8krXltl9GPfv",
        "outputId": "492c9d1c-96e3-480c-b6f3-398a02a115db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_combined.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUWNzsz4v04T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bWN_sAWEFNtb"
      },
      "cell_type": "markdown",
      "source": [
        "#### Fit MLP Classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QSdXJQLnFKa2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf = MLPClassifier(hidden_layer_sizes=(104),validation_fraction=0.3)\n",
        "# clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xfKh_nDUvj5G",
        "outputId": "f993011b-2c12-4885-ac4d-5db0750a8234",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "clf =MLPClassifier(hidden_layer_sizes=(90, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "# clf.fit(train_valid_combined, train_valid_label)\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.95444174\n",
            "Iteration 2, loss = 0.41361696\n",
            "Iteration 3, loss = 0.37376292\n",
            "Iteration 4, loss = 0.35310299\n",
            "Iteration 5, loss = 0.33669458\n",
            "Iteration 6, loss = 0.32397037\n",
            "Iteration 7, loss = 0.31519296\n",
            "Iteration 8, loss = 0.30943933\n",
            "Iteration 9, loss = 0.30110286\n",
            "Iteration 10, loss = 0.29639559\n",
            "Iteration 11, loss = 0.29181714\n",
            "Iteration 12, loss = 0.28519907\n",
            "Iteration 13, loss = 0.27945018\n",
            "Iteration 14, loss = 0.27446988\n",
            "Iteration 15, loss = 0.27230486\n",
            "Iteration 16, loss = 0.26854954\n",
            "Iteration 17, loss = 0.26347512\n",
            "Iteration 18, loss = 0.25999897\n",
            "Iteration 19, loss = 0.25824005\n",
            "Iteration 20, loss = 0.25456133\n",
            "Iteration 21, loss = 0.24952501\n",
            "Iteration 22, loss = 0.24607191\n",
            "Iteration 23, loss = 0.24673228\n",
            "Iteration 24, loss = 0.24442729\n",
            "Iteration 25, loss = 0.24115307\n",
            "Iteration 26, loss = 0.23827513\n",
            "Iteration 27, loss = 0.23520357\n",
            "Iteration 28, loss = 0.23354455\n",
            "Iteration 29, loss = 0.22978524\n",
            "Iteration 30, loss = 0.22810795\n",
            "Iteration 31, loss = 0.22567502\n",
            "Iteration 32, loss = 0.22661689\n",
            "Iteration 33, loss = 0.22176630\n",
            "Iteration 34, loss = 0.22185255\n",
            "Iteration 35, loss = 0.21909550\n",
            "Iteration 36, loss = 0.21857916\n",
            "Iteration 37, loss = 0.21802408\n",
            "Iteration 38, loss = 0.21273616\n",
            "Iteration 39, loss = 0.21271724\n",
            "Iteration 40, loss = 0.21180686\n",
            "Iteration 41, loss = 0.20911150\n",
            "Iteration 42, loss = 0.20824662\n",
            "Iteration 43, loss = 0.20727753\n",
            "Iteration 44, loss = 0.20444614\n",
            "Iteration 45, loss = 0.20458268\n",
            "Iteration 46, loss = 0.20322771\n",
            "Iteration 47, loss = 0.20093423\n",
            "Iteration 48, loss = 0.19972227\n",
            "Iteration 49, loss = 0.19969319\n",
            "Iteration 50, loss = 0.19881669\n",
            "Iteration 51, loss = 0.19614789\n",
            "Iteration 52, loss = 0.19417483\n",
            "Iteration 53, loss = 0.19168104\n",
            "Iteration 54, loss = 0.19479601\n",
            "Iteration 55, loss = 0.19010506\n",
            "Iteration 56, loss = 0.19106383\n",
            "Iteration 57, loss = 0.19142207\n",
            "Iteration 58, loss = 0.18865416\n",
            "Iteration 59, loss = 0.18610193\n",
            "Iteration 60, loss = 0.18574850\n",
            "Iteration 61, loss = 0.18561203\n",
            "Iteration 62, loss = 0.18429022\n",
            "Iteration 63, loss = 0.18052444\n",
            "Iteration 64, loss = 0.18136414\n",
            "Iteration 65, loss = 0.18031222\n",
            "Iteration 66, loss = 0.17744159\n",
            "Iteration 67, loss = 0.18027992\n",
            "Iteration 68, loss = 0.17645335\n",
            "Iteration 69, loss = 0.17403393\n",
            "Iteration 70, loss = 0.17429126\n",
            "Iteration 71, loss = 0.17618357\n",
            "Iteration 72, loss = 0.17183623\n",
            "Iteration 73, loss = 0.17166370\n",
            "Iteration 74, loss = 0.17217259\n",
            "Iteration 75, loss = 0.16904945\n",
            "Iteration 76, loss = 0.17088875\n",
            "Iteration 77, loss = 0.17259165\n",
            "Iteration 78, loss = 0.16779362\n",
            "Iteration 79, loss = 0.16512526\n",
            "Iteration 80, loss = 0.16614422\n",
            "Iteration 81, loss = 0.16629507\n",
            "Iteration 82, loss = 0.16287885\n",
            "Iteration 83, loss = 0.16415537\n",
            "Iteration 84, loss = 0.16234924\n",
            "Iteration 85, loss = 0.16424623\n",
            "Iteration 86, loss = 0.15978972\n",
            "Iteration 87, loss = 0.16143070\n",
            "Iteration 88, loss = 0.15866024\n",
            "Iteration 89, loss = 0.15941105\n",
            "Iteration 90, loss = 0.15681068\n",
            "Iteration 91, loss = 0.15561312\n",
            "Iteration 92, loss = 0.15621932\n",
            "Iteration 93, loss = 0.15605395\n",
            "Iteration 94, loss = 0.15510723\n",
            "Iteration 95, loss = 0.15339714\n",
            "Iteration 96, loss = 0.15174013\n",
            "Iteration 97, loss = 0.15426171\n",
            "Iteration 98, loss = 0.15044099\n",
            "Iteration 99, loss = 0.15172792\n",
            "Iteration 100, loss = 0.14968459\n",
            "Iteration 101, loss = 0.14847401\n",
            "Iteration 102, loss = 0.14847588\n",
            "Iteration 103, loss = 0.14778554\n",
            "Iteration 104, loss = 0.14824874\n",
            "Iteration 105, loss = 0.14742960\n",
            "Iteration 106, loss = 0.14452012\n",
            "Iteration 107, loss = 0.14947363\n",
            "Iteration 108, loss = 0.14322124\n",
            "Iteration 109, loss = 0.14478542\n",
            "Iteration 110, loss = 0.14181720\n",
            "Iteration 111, loss = 0.14135020\n",
            "Iteration 112, loss = 0.14072554\n",
            "Iteration 113, loss = 0.13985860\n",
            "Iteration 114, loss = 0.13897508\n",
            "Iteration 115, loss = 0.13912146\n",
            "Iteration 116, loss = 0.13914079\n",
            "Iteration 117, loss = 0.13889620\n",
            "Iteration 118, loss = 0.13568594\n",
            "Iteration 119, loss = 0.13788100\n",
            "Iteration 120, loss = 0.13676511\n",
            "Iteration 121, loss = 0.13544847\n",
            "Iteration 122, loss = 0.13301428\n",
            "Iteration 123, loss = 0.13581044\n",
            "Iteration 124, loss = 0.13166328\n",
            "Iteration 125, loss = 0.13556177\n",
            "Iteration 126, loss = 0.13061816\n",
            "Iteration 127, loss = 0.12774804\n",
            "Iteration 128, loss = 0.13414609\n",
            "Iteration 129, loss = 0.12788896\n",
            "Iteration 130, loss = 0.12703824\n",
            "Iteration 131, loss = 0.12845110\n",
            "Iteration 132, loss = 0.12680860\n",
            "Iteration 133, loss = 0.12745193\n",
            "Iteration 134, loss = 0.12698741\n",
            "Iteration 135, loss = 0.12842388\n",
            "Iteration 136, loss = 0.12634677\n",
            "Iteration 137, loss = 0.12352253\n",
            "Iteration 138, loss = 0.12330926\n",
            "Iteration 139, loss = 0.12610248\n",
            "Iteration 140, loss = 0.12203222\n",
            "Iteration 141, loss = 0.12216357\n",
            "Iteration 142, loss = 0.11924790\n",
            "Iteration 143, loss = 0.11957397\n",
            "Iteration 144, loss = 0.12033362\n",
            "Iteration 145, loss = 0.11740384\n",
            "Iteration 146, loss = 0.11871911\n",
            "Iteration 147, loss = 0.11659951\n",
            "Iteration 148, loss = 0.12022110\n",
            "Iteration 149, loss = 0.11646908\n",
            "Iteration 150, loss = 0.11516562\n",
            "Iteration 151, loss = 0.11565456\n",
            "Iteration 152, loss = 0.11418154\n",
            "Iteration 153, loss = 0.11264107\n",
            "Iteration 154, loss = 0.11497207\n",
            "Iteration 155, loss = 0.11319484\n",
            "Iteration 156, loss = 0.11410818\n",
            "Iteration 157, loss = 0.11406045\n",
            "Iteration 158, loss = 0.10999054\n",
            "Iteration 159, loss = 0.11248917\n",
            "Iteration 160, loss = 0.11442108\n",
            "Iteration 161, loss = 0.11135488\n",
            "Iteration 162, loss = 0.11127527\n",
            "Iteration 163, loss = 0.10752335\n",
            "Iteration 164, loss = 0.10901415\n",
            "Iteration 165, loss = 0.10863796\n",
            "Iteration 166, loss = 0.10790327\n",
            "Iteration 167, loss = 0.10961160\n",
            "Iteration 168, loss = 0.10851879\n",
            "Iteration 169, loss = 0.10602720\n",
            "Iteration 170, loss = 0.10630070\n",
            "Iteration 171, loss = 0.10501613\n",
            "Iteration 172, loss = 0.10583980\n",
            "Iteration 173, loss = 0.10541182\n",
            "Iteration 174, loss = 0.10096666\n",
            "Iteration 175, loss = 0.10404634\n",
            "Iteration 176, loss = 0.10221237\n",
            "Iteration 177, loss = 0.10075696\n",
            "Iteration 178, loss = 0.09931985\n",
            "Iteration 179, loss = 0.10203152\n",
            "Iteration 180, loss = 0.10096311\n",
            "Iteration 181, loss = 0.09975398\n",
            "Iteration 182, loss = 0.09955987\n",
            "Iteration 183, loss = 0.09993594\n",
            "Iteration 184, loss = 0.09770182\n",
            "Iteration 185, loss = 0.09802935\n",
            "Iteration 186, loss = 0.09803881\n",
            "Iteration 187, loss = 0.09618500\n",
            "Iteration 188, loss = 0.09616072\n",
            "Iteration 189, loss = 0.09800732\n",
            "Iteration 190, loss = 0.09534339\n",
            "Iteration 191, loss = 0.09352430\n",
            "Iteration 192, loss = 0.09372701\n",
            "Iteration 193, loss = 0.09739990\n",
            "Iteration 194, loss = 0.09370456\n",
            "Iteration 195, loss = 0.09311714\n",
            "Iteration 196, loss = 0.09235983\n",
            "Iteration 197, loss = 0.09294382\n",
            "Iteration 198, loss = 0.09261564\n",
            "Iteration 199, loss = 0.09151696\n",
            "Iteration 200, loss = 0.09206768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(90,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lLNA4D0qGxJi"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "02O8VTAoGqnG",
        "outputId": "11d1e8e2-b480-45f4-e4f7-b7856430d47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9710051546391752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "whn8u2m5iY7M"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pii8wXXSG1r7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Validation Accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SakclBGkGvI0",
        "outputId": "a014195e-4b62-48a1-8353-2738852501da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858001502629602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VbIkGX5gG5ZG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QLo_AzFVG3ca",
        "outputId": "f667df19-2b03-4fed-9dc2-30875b832bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "InLIF676HEES"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow model using weights initialized from numpy model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tcBNfKZNG9Pm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ortxRVBMH7W7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z7mWVCDVEgLm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hid_neuron = [90]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LR62GfKJv_6E",
        "outputId": "e041da39-02d4-4b64-c019-62d6d8caa48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EylNp0IJONbz"
      },
      "cell_type": "markdown",
      "source": [
        "#### Base NN model in tensor flow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VzJnI_o2xD5C"
      },
      "cell_type": "markdown",
      "source": [
        "#### 36 -> 90 -> 6"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "73Way2v2Pbys"
      },
      "cell_type": "markdown",
      "source": [
        "## Train baseline model in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L-hUDOm5xClH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IMHh0nROw5O-",
        "outputId": "d94fc321-17da-43e4-9b7d-0e4aaa472f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yV4xtxJLvyNj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Wj_W9eCBvyKy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKQ6nMqMvyJD",
        "outputId": "31b5f1bc-48ea-4152-ac9a-2aed66c4bf32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jy2mQcHAEn20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.train.GradientDescentOptimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eHe01FffvyEJ",
        "outputId": "6cd10ec8-1bd2-4e9b-abf9-6a7205d19e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "learning_rate = 0.001\n",
        "hid_neuron = [374]\n",
        "num_steps = 20000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "#     layer_2 = tf.matmul(layer_1, G_W2) + G_b2\n",
        "#     layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X), labels=Y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X), 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  ### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % 1000 == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            if step%1000 == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-45-4106bc23d37b>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 0.054217033, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1000, training loss= 0.06791636, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2000, training loss= 0.113990285, training acc= 94.9999988079071%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 3000, training loss= 0.05273371, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 4000, training loss= 0.08585536, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 5000, training loss= 0.08647766, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 6000, training loss= 0.07679716, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 7000, training loss= 0.063332275, training acc= 99.00000095367432%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 8000, training loss= 0.06664811, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 9000, training loss= 0.07144175, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 10000, training loss= 0.08180145, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 11000, training loss= 0.06436531, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 12000, training loss= 0.08577333, training acc= 98.50000143051147%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 13000, training loss= 0.078104615, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 14000, training loss= 0.08586474, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 15000, training loss= 0.081860274, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 16000, training loss= 0.092953704, training acc= 97.00000286102295%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 17000, training loss= 0.076337166, training acc= 97.50000238418579%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 18000, training loss= 0.11437439, training acc= 94.49999928474426%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 19000, training loss= 0.06445277, training acc= 98.00000190734863%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "Test acc= 89.600006 %\n",
            "Valid acc= 88.88054 %\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5A_PHV3bS7ui"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8RFK2bW4JZ7w"
      },
      "cell_type": "markdown",
      "source": [
        "#### My model with feedback"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "G5BxkTLzUAok"
      },
      "cell_type": "markdown",
      "source": [
        "## Divide valid in two parts for validation and validation-testÂ¶"
      ]
    },
    {
      "metadata": {
        "id": "mejHTwMYhEzu",
        "colab_type": "code",
        "outputId": "a540df9f-f5fb-47d1-9a8d-fc625f478872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(validation_data.shape)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1331, 36)\n",
            "(3104, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jVm6nWpSJn1l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_validation_data = validation_data[0:1000,:]\n",
        "valid_validation_data_label = validation_label_one_hot[0:1000,:]\n",
        "valid_test_data = validation_data[1000:,:]\n",
        "valid_test_data_label = validation_label_one_hot[1000:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wcT7Xaz1KNcU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape = train_label_one_hot.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydDcWHWsJcJ-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "num_hidden_neurons = 90\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "juudSyAz578t"
      },
      "cell_type": "markdown",
      "source": [
        "## Best Tuned, Use W1 = 5, W2 =4, W3 = 0 from best validation accuracy found below"
      ]
    },
    {
      "metadata": {
        "id": "UrVkojh_6eHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 100\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efqck-gfeuQZ",
        "colab_type": "code",
        "outputId": "25bcc025-8b3b-49e9-aa01-e5625f787d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255136
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [374]\n",
        "num_steps = 5000\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        " \n",
        "train_losses = []\n",
        "test_acc = []\n",
        "val_accuracy = []\n",
        "train_accuracy = []\n",
        "\n",
        "\n",
        "# for h in hid_neuron:\n",
        "#     num_hidden_neurons=h\n",
        "learning_rate = 0.001\n",
        "plot_every = 1\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "            train_accuracy.append(train_acc)\n",
        "            print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            train_losses.append(train_loss)\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "            val_accuracy.append(validation_accuracy)\n",
        "            if step%plot_every == 0:\n",
        "              print(\"Validation Accuracy {} ...\".format(validation_accuracy))\n",
        "              print()\n",
        "              if (validation_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#                     test_Accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "#         print(\"Test acc=\",str(test_Accuracy), \"%\")\n",
        "    print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "    ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "\n",
        "#     validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "#     ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "#     print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1 = {} ...\".format(wLoss1))\n",
        "    print(\"W2 = {} ...\".format(wLoss2))\n",
        "    print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "    print(\"*\"*50)\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss= 0.65273607, training acc= 96.9394326210022%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1, training loss= 0.44781587, training acc= 96.68170213699341%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2, training loss= 0.3298784, training acc= 96.35953903198242%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 3, training loss= 0.2652131, training acc= 96.00515365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 4, training loss= 0.23919326, training acc= 95.55412530899048%\n",
            "Validation Accuracy 89.03079986572266 ...\n",
            "\n",
            "step 5, training loss= 0.23553881, training acc= 95.10309100151062%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 6, training loss= 0.24323116, training acc= 94.68427896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 7, training loss= 0.25434718, training acc= 94.65206265449524%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 8, training loss= 0.26454765, training acc= 94.65206265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 9, training loss= 0.26904297, training acc= 94.71649527549744%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 10, training loss= 0.2658202, training acc= 94.74871158599854%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 11, training loss= 0.2559334, training acc= 94.87757682800293%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 12, training loss= 0.24190903, training acc= 95.00644207000732%\n",
            "Validation Accuracy 87.9038314819336 ...\n",
            "\n",
            "step 13, training loss= 0.22612709, training acc= 95.29638886451721%\n",
            "Validation Accuracy 87.9038314819336 ...\n",
            "\n",
            "step 14, training loss= 0.21031293, training acc= 95.55412530899048%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 15, training loss= 0.19565445, training acc= 95.74742317199707%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 16, training loss= 0.1832053, training acc= 96.06958627700806%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 17, training loss= 0.17332837, training acc= 96.19845151901245%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 18, training loss= 0.16568631, training acc= 96.29510045051575%\n",
            "Validation Accuracy 87.9038314819336 ...\n",
            "\n",
            "step 19, training loss= 0.15984806, training acc= 96.26288414001465%\n",
            "Validation Accuracy 87.9038314819336 ...\n",
            "\n",
            "step 20, training loss= 0.15549615, training acc= 96.29510045051575%\n",
            "Validation Accuracy 87.9038314819336 ...\n",
            "\n",
            "step 21, training loss= 0.1522062, training acc= 96.48840427398682%\n",
            "Validation Accuracy 87.75357055664062 ...\n",
            "\n",
            "step 22, training loss= 0.14944209, training acc= 96.61726951599121%\n",
            "Validation Accuracy 87.82870483398438 ...\n",
            "\n",
            "step 23, training loss= 0.14684926, training acc= 96.55283689498901%\n",
            "Validation Accuracy 87.67843627929688 ...\n",
            "\n",
            "step 24, training loss= 0.1443663, training acc= 96.58505320549011%\n",
            "Validation Accuracy 87.75357055664062 ...\n",
            "\n",
            "step 25, training loss= 0.14204776, training acc= 96.8105673789978%\n",
            "Validation Accuracy 87.82870483398438 ...\n",
            "\n",
            "step 26, training loss= 0.13995719, training acc= 96.7783510684967%\n",
            "Validation Accuracy 87.82870483398438 ...\n",
            "\n",
            "step 27, training loss= 0.13775527, training acc= 96.8105673789978%\n",
            "Validation Accuracy 87.82870483398438 ...\n",
            "\n",
            "step 28, training loss= 0.13477224, training acc= 96.7461347579956%\n",
            "Validation Accuracy 87.75357055664062 ...\n",
            "\n",
            "step 29, training loss= 0.13058834, training acc= 96.8105673789978%\n",
            "Validation Accuracy 87.75357055664062 ...\n",
            "\n",
            "step 30, training loss= 0.12562692, training acc= 96.8427836894989%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 31, training loss= 0.12092126, training acc= 96.9072163105011%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 32, training loss= 0.11735694, training acc= 96.9394326210022%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 33, training loss= 0.115240045, training acc= 96.9716489315033%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 34, training loss= 0.11433968, training acc= 96.9394326210022%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 35, training loss= 0.114163846, training acc= 97.10051417350769%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 36, training loss= 0.11415045, training acc= 97.13273048400879%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 37, training loss= 0.11382671, training acc= 97.13273048400879%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 38, training loss= 0.11290625, training acc= 97.26159572601318%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 39, training loss= 0.11133543, training acc= 97.26159572601318%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 40, training loss= 0.109273225, training acc= 97.26159572601318%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 41, training loss= 0.10702704, training acc= 97.19716310501099%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 42, training loss= 0.104964435, training acc= 97.26159572601318%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 43, training loss= 0.10337135, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 44, training loss= 0.10235831, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 45, training loss= 0.101824544, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 46, training loss= 0.10149725, training acc= 97.26159572601318%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 47, training loss= 0.10109424, training acc= 97.26159572601318%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 48, training loss= 0.10047999, training acc= 97.22937941551208%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 49, training loss= 0.09968152, training acc= 97.22937941551208%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 50, training loss= 0.09878796, training acc= 97.29381203651428%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 51, training loss= 0.09789795, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 52, training loss= 0.09711177, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 53, training loss= 0.0964905, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 54, training loss= 0.09603179, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 55, training loss= 0.09567509, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 56, training loss= 0.09535156, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 57, training loss= 0.09499868, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 58, training loss= 0.094575696, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 59, training loss= 0.09408056, training acc= 97.29381203651428%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 60, training loss= 0.09353961, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 61, training loss= 0.09299633, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 62, training loss= 0.09249258, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 63, training loss= 0.09205188, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 64, training loss= 0.09167318, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 65, training loss= 0.09133523, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 66, training loss= 0.09101203, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 67, training loss= 0.09068403, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 68, training loss= 0.090350054, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 69, training loss= 0.09002226, training acc= 97.32602834701538%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 70, training loss= 0.089716226, training acc= 97.32602834701538%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 71, training loss= 0.08943799, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 72, training loss= 0.08918449, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 73, training loss= 0.08894442, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 74, training loss= 0.0887056, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 75, training loss= 0.08845921, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 76, training loss= 0.08820361, training acc= 97.35824465751648%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 77, training loss= 0.08794345, training acc= 97.35824465751648%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 78, training loss= 0.08768808, training acc= 97.35824465751648%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 79, training loss= 0.087446384, training acc= 97.32602834701538%\n",
            "Validation Accuracy 87.97896575927734 ...\n",
            "\n",
            "step 80, training loss= 0.08722098, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 81, training loss= 0.087007694, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.0541000366211 ...\n",
            "\n",
            "step 82, training loss= 0.086798064, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 83, training loss= 0.08658623, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 84, training loss= 0.08637264, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.12922668457031 ...\n",
            "\n",
            "step 85, training loss= 0.08616201, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 86, training loss= 0.08595949, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 87, training loss= 0.0857676, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 88, training loss= 0.08558427, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 89, training loss= 0.0854058, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 90, training loss= 0.08522944, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 91, training loss= 0.08505471, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 92, training loss= 0.08488376, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 93, training loss= 0.08471845, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 94, training loss= 0.084558554, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 95, training loss= 0.084402785, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 96, training loss= 0.08424893, training acc= 97.32602834701538%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 97, training loss= 0.08409595, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 98, training loss= 0.08394566, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 99, training loss= 0.08379954, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 100, training loss= 0.08365848, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 101, training loss= 0.08352252, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 102, training loss= 0.08339106, training acc= 97.35824465751648%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 103, training loss= 0.08326216, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 104, training loss= 0.0831348, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 105, training loss= 0.083009794, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 106, training loss= 0.08288772, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 107, training loss= 0.082769305, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 108, training loss= 0.082654476, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 109, training loss= 0.0825424, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 110, training loss= 0.08243254, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 111, training loss= 0.0823245, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 112, training loss= 0.08221817, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 113, training loss= 0.08211391, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 114, training loss= 0.082011655, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 115, training loss= 0.08191166, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 116, training loss= 0.081814304, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 117, training loss= 0.08171863, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 118, training loss= 0.08162424, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 119, training loss= 0.081531525, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 120, training loss= 0.081440695, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 121, training loss= 0.0813522, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 122, training loss= 0.081264764, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 123, training loss= 0.081177786, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 124, training loss= 0.08109122, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 125, training loss= 0.08100505, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 126, training loss= 0.080919825, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 127, training loss= 0.08083521, training acc= 97.39046096801758%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 128, training loss= 0.08075085, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 129, training loss= 0.08066685, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 130, training loss= 0.080583446, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 131, training loss= 0.08050123, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 132, training loss= 0.080420494, training acc= 97.42268323898315%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 133, training loss= 0.08034147, training acc= 97.45489954948425%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 134, training loss= 0.08026425, training acc= 97.45489954948425%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 135, training loss= 0.08018906, training acc= 97.45489954948425%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 136, training loss= 0.08011548, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 137, training loss= 0.08004352, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 138, training loss= 0.07997301, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 139, training loss= 0.07990341, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 140, training loss= 0.07983431, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 141, training loss= 0.07976572, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 142, training loss= 0.079697445, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 143, training loss= 0.07962971, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 144, training loss= 0.07956285, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 145, training loss= 0.07949708, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 146, training loss= 0.07943201, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 147, training loss= 0.07936782, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 148, training loss= 0.079304144, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 149, training loss= 0.07924119, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 150, training loss= 0.07917895, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 151, training loss= 0.0791173, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 152, training loss= 0.07905605, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 153, training loss= 0.078995116, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 154, training loss= 0.07893431, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 155, training loss= 0.07887376, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 156, training loss= 0.078813314, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 157, training loss= 0.07875323, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 158, training loss= 0.07869356, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 159, training loss= 0.07863373, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 160, training loss= 0.07857384, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 161, training loss= 0.0785142, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 162, training loss= 0.07845467, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 163, training loss= 0.078395575, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 164, training loss= 0.07833702, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 165, training loss= 0.07827903, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 166, training loss= 0.0782218, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 167, training loss= 0.07816574, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 168, training loss= 0.078110576, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 169, training loss= 0.07805614, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 170, training loss= 0.0780037, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 171, training loss= 0.07795214, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 172, training loss= 0.07790123, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 173, training loss= 0.07785079, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 174, training loss= 0.0778011, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 175, training loss= 0.07775177, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 176, training loss= 0.077702515, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 177, training loss= 0.07765333, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 178, training loss= 0.077604175, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 179, training loss= 0.07755527, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 180, training loss= 0.07750666, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 181, training loss= 0.077458, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 182, training loss= 0.0774096, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 183, training loss= 0.07736139, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 184, training loss= 0.07731354, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 185, training loss= 0.0772664, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 186, training loss= 0.07721977, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 187, training loss= 0.07717344, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 188, training loss= 0.07712746, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 189, training loss= 0.077081695, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 190, training loss= 0.07703587, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 191, training loss= 0.07699007, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 192, training loss= 0.07694455, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 193, training loss= 0.07689922, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 194, training loss= 0.07685423, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 195, training loss= 0.07680959, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 196, training loss= 0.07676533, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 197, training loss= 0.07672139, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 198, training loss= 0.07667762, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 199, training loss= 0.07663424, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 200, training loss= 0.076590896, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 201, training loss= 0.07654778, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 202, training loss= 0.07650486, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 203, training loss= 0.076462016, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 204, training loss= 0.07641931, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 205, training loss= 0.076376885, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 206, training loss= 0.07633474, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 207, training loss= 0.07629276, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 208, training loss= 0.076251015, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 209, training loss= 0.07620952, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 210, training loss= 0.07616854, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 211, training loss= 0.07612764, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 212, training loss= 0.07608691, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 213, training loss= 0.07604624, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 214, training loss= 0.076005906, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 215, training loss= 0.07596569, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 216, training loss= 0.07592562, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 217, training loss= 0.07588586, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 218, training loss= 0.075846314, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 219, training loss= 0.07580679, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 220, training loss= 0.07576743, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 221, training loss= 0.07572831, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 222, training loss= 0.07568935, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 223, training loss= 0.07565027, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 224, training loss= 0.07561151, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 225, training loss= 0.075573325, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 226, training loss= 0.075535305, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 227, training loss= 0.07549751, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 228, training loss= 0.075459614, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 229, training loss= 0.075422004, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 230, training loss= 0.075384624, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 231, training loss= 0.075347364, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 232, training loss= 0.0753103, training acc= 97.48711585998535%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 233, training loss= 0.07527322, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 234, training loss= 0.075236306, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 235, training loss= 0.075199544, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 236, training loss= 0.07516274, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 237, training loss= 0.07512612, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 238, training loss= 0.07508953, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 239, training loss= 0.075053066, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 240, training loss= 0.075016886, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 241, training loss= 0.07498081, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 242, training loss= 0.07494473, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 243, training loss= 0.074908756, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 244, training loss= 0.074872784, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 245, training loss= 0.07483718, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 246, training loss= 0.07480167, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 247, training loss= 0.07476591, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 248, training loss= 0.07473033, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 249, training loss= 0.07469497, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 250, training loss= 0.074659765, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 251, training loss= 0.07462431, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 252, training loss= 0.07458931, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 253, training loss= 0.07455431, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 254, training loss= 0.0745194, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 255, training loss= 0.07448447, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 256, training loss= 0.07444947, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 257, training loss= 0.074414335, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 258, training loss= 0.07437912, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 259, training loss= 0.074343935, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 260, training loss= 0.07430896, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 261, training loss= 0.07427411, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 262, training loss= 0.07423909, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 263, training loss= 0.074204326, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 264, training loss= 0.07416978, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 265, training loss= 0.074135005, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 266, training loss= 0.074100144, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 267, training loss= 0.0740655, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 268, training loss= 0.074031286, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 269, training loss= 0.073996924, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 270, training loss= 0.07396248, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 271, training loss= 0.07392834, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 272, training loss= 0.07389388, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 273, training loss= 0.073859826, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 274, training loss= 0.07382581, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 275, training loss= 0.073791936, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 276, training loss= 0.07375809, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 277, training loss= 0.073723994, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 278, training loss= 0.073689744, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 279, training loss= 0.073655255, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 280, training loss= 0.07362081, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 281, training loss= 0.07358635, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 282, training loss= 0.073551804, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 283, training loss= 0.07351709, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 284, training loss= 0.07348228, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 285, training loss= 0.07344736, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 286, training loss= 0.07341221, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 287, training loss= 0.07337696, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 288, training loss= 0.073341295, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 289, training loss= 0.073305376, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 290, training loss= 0.07326945, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 291, training loss= 0.07323349, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 292, training loss= 0.073197566, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 293, training loss= 0.07316158, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 294, training loss= 0.07312545, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 295, training loss= 0.073089555, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 296, training loss= 0.07305347, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 297, training loss= 0.07301787, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 298, training loss= 0.07298197, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 299, training loss= 0.07294629, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 300, training loss= 0.07291071, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 301, training loss= 0.07287516, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 302, training loss= 0.07283956, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 303, training loss= 0.07280402, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 304, training loss= 0.07276879, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 305, training loss= 0.07273368, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 306, training loss= 0.072698675, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 307, training loss= 0.072663665, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 308, training loss= 0.07262879, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 309, training loss= 0.072594, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 310, training loss= 0.07255937, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 311, training loss= 0.07252489, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 312, training loss= 0.07249048, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 313, training loss= 0.07245611, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 314, training loss= 0.07242184, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 315, training loss= 0.072387606, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 316, training loss= 0.0723536, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 317, training loss= 0.072319664, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 318, training loss= 0.0722858, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 319, training loss= 0.07225209, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 320, training loss= 0.0722184, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 321, training loss= 0.07218464, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 322, training loss= 0.072150975, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 323, training loss= 0.07211728, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 324, training loss= 0.072083734, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 325, training loss= 0.072050005, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 326, training loss= 0.07201623, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 327, training loss= 0.07198258, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 328, training loss= 0.07194894, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 329, training loss= 0.07191531, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 330, training loss= 0.0718815, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 331, training loss= 0.07184769, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 332, training loss= 0.07181389, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 333, training loss= 0.07177996, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 334, training loss= 0.07174598, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 335, training loss= 0.071711846, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 336, training loss= 0.07167776, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 337, training loss= 0.071643434, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 338, training loss= 0.07160907, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 339, training loss= 0.07157481, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 340, training loss= 0.071540296, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 341, training loss= 0.07150585, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 342, training loss= 0.07147107, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 343, training loss= 0.071436554, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 344, training loss= 0.07140247, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 345, training loss= 0.0713684, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 346, training loss= 0.07133424, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 347, training loss= 0.07130031, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 348, training loss= 0.07126643, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 349, training loss= 0.071232475, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 350, training loss= 0.07119841, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 351, training loss= 0.07116433, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 352, training loss= 0.07113045, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 353, training loss= 0.07109663, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 354, training loss= 0.071063, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 355, training loss= 0.07102951, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 356, training loss= 0.07099593, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 357, training loss= 0.07096232, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 358, training loss= 0.07092931, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 359, training loss= 0.0708965, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 360, training loss= 0.07086369, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 361, training loss= 0.07083066, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 362, training loss= 0.07079819, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 363, training loss= 0.07076574, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 364, training loss= 0.07073347, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 365, training loss= 0.07070139, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 366, training loss= 0.07066966, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 367, training loss= 0.07063795, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 368, training loss= 0.0706063, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 369, training loss= 0.07057498, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 370, training loss= 0.07054323, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 371, training loss= 0.07051169, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 372, training loss= 0.070480555, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 373, training loss= 0.070449695, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 374, training loss= 0.070419006, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 375, training loss= 0.07038864, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 376, training loss= 0.07035851, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 377, training loss= 0.07032857, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 378, training loss= 0.0702987, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 379, training loss= 0.07026911, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 380, training loss= 0.070239544, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 381, training loss= 0.070210174, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 382, training loss= 0.07018076, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 383, training loss= 0.07015156, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 384, training loss= 0.070122436, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 385, training loss= 0.0700934, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 386, training loss= 0.07006449, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 387, training loss= 0.07003598, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 388, training loss= 0.070007615, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 389, training loss= 0.06997934, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 390, training loss= 0.0699509, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 391, training loss= 0.069922775, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 392, training loss= 0.06989493, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 393, training loss= 0.06986702, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 394, training loss= 0.06983908, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 395, training loss= 0.06981114, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 396, training loss= 0.069783345, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 397, training loss= 0.06975588, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 398, training loss= 0.069728404, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 399, training loss= 0.06970088, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 400, training loss= 0.06967326, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 401, training loss= 0.06964598, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 402, training loss= 0.069618754, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 403, training loss= 0.06959145, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 404, training loss= 0.06956438, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 405, training loss= 0.06953724, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 406, training loss= 0.06951009, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 407, training loss= 0.0694832, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 408, training loss= 0.06945625, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 409, training loss= 0.0694294, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 410, training loss= 0.06940262, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 411, training loss= 0.06937561, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 412, training loss= 0.06934887, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 413, training loss= 0.06932239, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 414, training loss= 0.06929575, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 415, training loss= 0.06926912, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 416, training loss= 0.069242425, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 417, training loss= 0.06921587, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 418, training loss= 0.06918964, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 419, training loss= 0.06916324, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 420, training loss= 0.069136806, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 421, training loss= 0.0691105, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 422, training loss= 0.06908434, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 423, training loss= 0.06905831, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 424, training loss= 0.06903223, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 425, training loss= 0.06900628, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 426, training loss= 0.068980314, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 427, training loss= 0.06895418, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 428, training loss= 0.068928234, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 429, training loss= 0.06890251, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 430, training loss= 0.06887657, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 431, training loss= 0.06885074, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 432, training loss= 0.06882493, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 433, training loss= 0.06879926, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 434, training loss= 0.06877351, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 435, training loss= 0.06874794, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 436, training loss= 0.068722405, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 437, training loss= 0.06869678, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 438, training loss= 0.06867112, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 439, training loss= 0.06864558, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 440, training loss= 0.06862017, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 441, training loss= 0.06859483, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 442, training loss= 0.06856948, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 443, training loss= 0.068544194, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 444, training loss= 0.06851895, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 445, training loss= 0.06849364, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 446, training loss= 0.06846842, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 447, training loss= 0.06844333, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 448, training loss= 0.068418264, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 449, training loss= 0.068393275, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 450, training loss= 0.06836829, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 451, training loss= 0.068343215, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 452, training loss= 0.068318106, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 453, training loss= 0.068292886, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 454, training loss= 0.06826806, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 455, training loss= 0.06824309, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 456, training loss= 0.068218105, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 457, training loss= 0.06819324, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 458, training loss= 0.068168305, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 459, training loss= 0.068143256, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 460, training loss= 0.0681185, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 461, training loss= 0.068093844, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 462, training loss= 0.06806898, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 463, training loss= 0.06804407, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 464, training loss= 0.06801929, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 465, training loss= 0.06799468, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 466, training loss= 0.067969956, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 467, training loss= 0.06794524, training acc= 97.51933217048645%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 468, training loss= 0.06792069, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 469, training loss= 0.06789609, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 470, training loss= 0.067871384, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 471, training loss= 0.0678467, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 472, training loss= 0.0678222, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 473, training loss= 0.0677977, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 474, training loss= 0.06777321, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 475, training loss= 0.067748494, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 476, training loss= 0.06772415, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 477, training loss= 0.067699924, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 478, training loss= 0.06767558, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 479, training loss= 0.06765136, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 480, training loss= 0.067627154, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 481, training loss= 0.06760296, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 482, training loss= 0.06757921, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 483, training loss= 0.06755525, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 484, training loss= 0.06753131, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 485, training loss= 0.06750743, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 486, training loss= 0.06748335, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 487, training loss= 0.06745945, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 488, training loss= 0.06743579, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 489, training loss= 0.067412205, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 490, training loss= 0.067388505, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 491, training loss= 0.06736481, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 492, training loss= 0.06734107, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 493, training loss= 0.06731744, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 494, training loss= 0.06729386, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 495, training loss= 0.0672704, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 496, training loss= 0.067246445, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 497, training loss= 0.06722279, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 498, training loss= 0.06719944, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 499, training loss= 0.06717601, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 500, training loss= 0.06715236, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 501, training loss= 0.067129076, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 502, training loss= 0.06710566, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 503, training loss= 0.06708208, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 504, training loss= 0.06705877, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 505, training loss= 0.067035414, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 506, training loss= 0.067011975, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 507, training loss= 0.066988654, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 508, training loss= 0.066965476, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 509, training loss= 0.06694239, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 510, training loss= 0.06691919, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 511, training loss= 0.066896014, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 512, training loss= 0.06687274, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 513, training loss= 0.06684982, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 514, training loss= 0.066826716, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 515, training loss= 0.066803895, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 516, training loss= 0.066780865, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 517, training loss= 0.06675789, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 518, training loss= 0.0667349, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 519, training loss= 0.066712216, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 520, training loss= 0.06668918, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 521, training loss= 0.06666621, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 522, training loss= 0.06664334, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 523, training loss= 0.06662067, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 524, training loss= 0.06659787, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 525, training loss= 0.06657502, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 526, training loss= 0.066552356, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 527, training loss= 0.066529885, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 528, training loss= 0.066507064, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 529, training loss= 0.066484295, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 530, training loss= 0.06646163, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 531, training loss= 0.06643903, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 532, training loss= 0.06641632, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 533, training loss= 0.066393405, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 534, training loss= 0.066370755, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 535, training loss= 0.066348165, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 536, training loss= 0.06632544, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 537, training loss= 0.06630288, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 538, training loss= 0.066280164, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 539, training loss= 0.06625725, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 540, training loss= 0.06623457, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 541, training loss= 0.066212066, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 542, training loss= 0.06618922, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 543, training loss= 0.06616655, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 544, training loss= 0.06614378, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 545, training loss= 0.06612081, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 546, training loss= 0.06609782, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 547, training loss= 0.0660751, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 548, training loss= 0.0660522, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 549, training loss= 0.06602961, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 550, training loss= 0.06600681, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 551, training loss= 0.06598404, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 552, training loss= 0.06596136, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 553, training loss= 0.065938495, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 554, training loss= 0.06591609, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 555, training loss= 0.0658933, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 556, training loss= 0.06587056, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 557, training loss= 0.065848045, training acc= 97.55154848098755%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 558, training loss= 0.06582546, training acc= 97.58376479148865%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 559, training loss= 0.06580268, training acc= 97.58376479148865%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 560, training loss= 0.06577993, training acc= 97.58376479148865%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 561, training loss= 0.06575748, training acc= 97.58376479148865%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 562, training loss= 0.06573495, training acc= 97.58376479148865%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 563, training loss= 0.065712444, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 564, training loss= 0.065689996, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 565, training loss= 0.065667264, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 566, training loss= 0.06564446, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 567, training loss= 0.06562189, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 568, training loss= 0.065598905, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 569, training loss= 0.065576114, training acc= 97.61598110198975%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 570, training loss= 0.06555372, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 571, training loss= 0.06553094, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 572, training loss= 0.06550805, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 573, training loss= 0.06548506, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 574, training loss= 0.065462515, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 575, training loss= 0.06543983, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 576, training loss= 0.0654172, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 577, training loss= 0.065394625, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 578, training loss= 0.06537202, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 579, training loss= 0.065349475, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 580, training loss= 0.06532713, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 581, training loss= 0.06530475, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 582, training loss= 0.065282434, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 583, training loss= 0.06526018, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 584, training loss= 0.065238, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 585, training loss= 0.065216035, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 586, training loss= 0.06519417, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 587, training loss= 0.06517257, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 588, training loss= 0.06515078, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 589, training loss= 0.06512904, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 590, training loss= 0.06510748, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 591, training loss= 0.065086104, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 592, training loss= 0.065064184, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 593, training loss= 0.06504281, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 594, training loss= 0.06502124, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 595, training loss= 0.06499943, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 596, training loss= 0.06497777, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 597, training loss= 0.06495638, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 598, training loss= 0.0649348, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 599, training loss= 0.06491317, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 600, training loss= 0.06489182, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 601, training loss= 0.064870566, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 602, training loss= 0.064848825, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 603, training loss= 0.06482747, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 604, training loss= 0.06480609, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 605, training loss= 0.06478456, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 606, training loss= 0.06476297, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 607, training loss= 0.0647416, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 608, training loss= 0.06472006, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 609, training loss= 0.0646987, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 610, training loss= 0.06467718, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 611, training loss= 0.06465566, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 612, training loss= 0.064634286, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 613, training loss= 0.06461288, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 614, training loss= 0.06459133, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 615, training loss= 0.06456991, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 616, training loss= 0.064548485, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 617, training loss= 0.06452712, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 618, training loss= 0.064505905, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 619, training loss= 0.06448439, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 620, training loss= 0.064462975, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 621, training loss= 0.0644416, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 622, training loss= 0.0644206, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 623, training loss= 0.06439925, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 624, training loss= 0.064377956, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 625, training loss= 0.06435662, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 626, training loss= 0.06433544, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 627, training loss= 0.06431428, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 628, training loss= 0.064293005, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 629, training loss= 0.06427192, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 630, training loss= 0.0642507, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 631, training loss= 0.064229876, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 632, training loss= 0.06420849, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 633, training loss= 0.064187534, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 634, training loss= 0.06416637, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 635, training loss= 0.064145155, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 636, training loss= 0.06412398, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 637, training loss= 0.064103015, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 638, training loss= 0.06408209, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 639, training loss= 0.064061, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 640, training loss= 0.064039975, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 641, training loss= 0.06401918, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 642, training loss= 0.063998, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 643, training loss= 0.06397707, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 644, training loss= 0.06395611, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 645, training loss= 0.06393553, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 646, training loss= 0.06391449, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 647, training loss= 0.06389344, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 648, training loss= 0.06387242, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 649, training loss= 0.0638513, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 650, training loss= 0.06383028, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 651, training loss= 0.06380945, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 652, training loss= 0.063788444, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 653, training loss= 0.06376763, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 654, training loss= 0.06374656, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 655, training loss= 0.0637255, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 656, training loss= 0.06370447, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 657, training loss= 0.06368383, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 658, training loss= 0.06366312, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 659, training loss= 0.063642226, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 660, training loss= 0.06362137, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 661, training loss= 0.06360043, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 662, training loss= 0.063579656, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 663, training loss= 0.0635589, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 664, training loss= 0.06353809, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 665, training loss= 0.06351715, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 666, training loss= 0.06349619, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 667, training loss= 0.063475266, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 668, training loss= 0.063454494, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 669, training loss= 0.06343319, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 670, training loss= 0.06341227, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 671, training loss= 0.06339144, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 672, training loss= 0.06337006, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 673, training loss= 0.06334873, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 674, training loss= 0.06332799, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 675, training loss= 0.06330657, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 676, training loss= 0.06328525, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 677, training loss= 0.06326427, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 678, training loss= 0.06324288, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 679, training loss= 0.06322132, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 680, training loss= 0.06319995, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 681, training loss= 0.063178934, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 682, training loss= 0.063157424, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 683, training loss= 0.063136056, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 684, training loss= 0.06311464, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 685, training loss= 0.06309332, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 686, training loss= 0.06307208, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 687, training loss= 0.06305086, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 688, training loss= 0.063029654, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 689, training loss= 0.063008316, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 690, training loss= 0.06298734, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 691, training loss= 0.06296634, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 692, training loss= 0.062945426, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 693, training loss= 0.062924445, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 694, training loss= 0.062903464, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 695, training loss= 0.062882885, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 696, training loss= 0.06286162, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 697, training loss= 0.06284082, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 698, training loss= 0.06282012, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 699, training loss= 0.0627992, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 700, training loss= 0.06277831, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 701, training loss= 0.06275728, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 702, training loss= 0.06273625, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 703, training loss= 0.06271572, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 704, training loss= 0.06269495, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 705, training loss= 0.062674426, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 706, training loss= 0.06265386, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 707, training loss= 0.06263354, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 708, training loss= 0.062613145, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 709, training loss= 0.062592454, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 710, training loss= 0.06257209, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 711, training loss= 0.06255156, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 712, training loss= 0.062531315, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 713, training loss= 0.0625106, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 714, training loss= 0.06248983, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 715, training loss= 0.062469494, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 716, training loss= 0.062448792, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 717, training loss= 0.062428076, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 718, training loss= 0.062407307, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 719, training loss= 0.062386777, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 720, training loss= 0.062366083, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 721, training loss= 0.06234562, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 722, training loss= 0.062324822, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 723, training loss= 0.06230439, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 724, training loss= 0.06228367, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 725, training loss= 0.062262915, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 726, training loss= 0.062242605, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 727, training loss= 0.062221773, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 728, training loss= 0.062201187, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 729, training loss= 0.06218075, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 730, training loss= 0.062160425, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 731, training loss= 0.062139288, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 732, training loss= 0.062118895, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 733, training loss= 0.062098328, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 734, training loss= 0.06207754, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 735, training loss= 0.06205734, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 736, training loss= 0.062036525, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 737, training loss= 0.062016305, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 738, training loss= 0.06199615, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 739, training loss= 0.061975654, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 740, training loss= 0.0619552, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 741, training loss= 0.061935306, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 742, training loss= 0.06191466, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 743, training loss= 0.06189422, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 744, training loss= 0.06187441, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 745, training loss= 0.061853994, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 746, training loss= 0.06183351, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 747, training loss= 0.061813425, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 748, training loss= 0.06179294, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 749, training loss= 0.061772905, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 750, training loss= 0.061752684, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 751, training loss= 0.061732266, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 752, training loss= 0.061712086, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 753, training loss= 0.061691895, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 754, training loss= 0.061671875, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 755, training loss= 0.06165175, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 756, training loss= 0.061631374, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 757, training loss= 0.061611366, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 758, training loss= 0.06159117, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 759, training loss= 0.061571296, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 760, training loss= 0.061551232, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 761, training loss= 0.06153083, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 762, training loss= 0.06151094, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 763, training loss= 0.061491143, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 764, training loss= 0.0614712, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 765, training loss= 0.06145107, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 766, training loss= 0.06143123, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 767, training loss= 0.06141129, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 768, training loss= 0.061391454, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 769, training loss= 0.06137166, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 770, training loss= 0.061351806, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 771, training loss= 0.061331674, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 772, training loss= 0.061311644, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 773, training loss= 0.06129228, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 774, training loss= 0.061272733, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 775, training loss= 0.061252855, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 776, training loss= 0.061232932, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 777, training loss= 0.061213024, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 778, training loss= 0.061193723, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 779, training loss= 0.061173026, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 780, training loss= 0.061153635, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 781, training loss= 0.061134025, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 782, training loss= 0.061114077, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 783, training loss= 0.061094064, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 784, training loss= 0.061074164, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 785, training loss= 0.061054982, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 786, training loss= 0.061034158, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 787, training loss= 0.061014257, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 788, training loss= 0.060994983, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 789, training loss= 0.06097498, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 790, training loss= 0.06095494, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 791, training loss= 0.06093519, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 792, training loss= 0.06091566, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 793, training loss= 0.060895853, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 794, training loss= 0.060875915, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 795, training loss= 0.060856413, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 796, training loss= 0.06083674, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 797, training loss= 0.060816877, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 798, training loss= 0.060797296, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 799, training loss= 0.060777646, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 800, training loss= 0.06075802, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 801, training loss= 0.060738083, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 802, training loss= 0.06071871, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 803, training loss= 0.060699023, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 804, training loss= 0.06067943, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 805, training loss= 0.060659807, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 806, training loss= 0.060640503, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 807, training loss= 0.06062094, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 808, training loss= 0.06060119, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 809, training loss= 0.0605816, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 810, training loss= 0.060562376, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 811, training loss= 0.060542613, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 812, training loss= 0.060523164, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 813, training loss= 0.060503546, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 814, training loss= 0.060483787, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 815, training loss= 0.06046449, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 816, training loss= 0.060444336, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 817, training loss= 0.06042495, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 818, training loss= 0.060405448, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 819, training loss= 0.060385447, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 820, training loss= 0.06036586, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 821, training loss= 0.060345966, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 822, training loss= 0.06032618, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 823, training loss= 0.06030656, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 824, training loss= 0.060286984, training acc= 97.64819741249084%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 825, training loss= 0.060267173, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 826, training loss= 0.06024737, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 827, training loss= 0.0602278, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 828, training loss= 0.060208134, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 829, training loss= 0.060188677, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 830, training loss= 0.060168635, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 831, training loss= 0.06014894, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 832, training loss= 0.060129426, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 833, training loss= 0.060109816, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 834, training loss= 0.060090147, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 835, training loss= 0.06007023, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 836, training loss= 0.060050264, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 837, training loss= 0.06003071, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 838, training loss= 0.06001123, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 839, training loss= 0.05999141, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 840, training loss= 0.059971962, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 841, training loss= 0.059953284, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 842, training loss= 0.059933014, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 843, training loss= 0.05991344, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 844, training loss= 0.059894692, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 845, training loss= 0.05987496, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 846, training loss= 0.05985614, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 847, training loss= 0.059836507, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 848, training loss= 0.05981778, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 849, training loss= 0.059798054, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 850, training loss= 0.05977967, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 851, training loss= 0.05976018, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 852, training loss= 0.05974073, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 853, training loss= 0.059722252, training acc= 97.68041372299194%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 854, training loss= 0.059702776, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 855, training loss= 0.059683863, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 856, training loss= 0.059664913, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 857, training loss= 0.05964593, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 858, training loss= 0.059626754, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 859, training loss= 0.05960775, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 860, training loss= 0.059588734, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 861, training loss= 0.059569664, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 862, training loss= 0.05955079, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 863, training loss= 0.05953128, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 864, training loss= 0.059512783, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 865, training loss= 0.059493992, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 866, training loss= 0.059474714, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 867, training loss= 0.059455648, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 868, training loss= 0.05943662, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 869, training loss= 0.059418026, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 870, training loss= 0.059399202, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 871, training loss= 0.05937999, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 872, training loss= 0.059361037, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 873, training loss= 0.059342522, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 874, training loss= 0.05932364, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 875, training loss= 0.05930477, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 876, training loss= 0.059285805, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 877, training loss= 0.05926729, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 878, training loss= 0.059248224, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 879, training loss= 0.05922949, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 880, training loss= 0.05921059, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 881, training loss= 0.05919208, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 882, training loss= 0.059172764, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 883, training loss= 0.05915413, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 884, training loss= 0.059135754, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 885, training loss= 0.059116364, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 886, training loss= 0.059098262, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 887, training loss= 0.059079096, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 888, training loss= 0.059060376, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 889, training loss= 0.05904197, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 890, training loss= 0.05902279, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 891, training loss= 0.05900461, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 892, training loss= 0.058985345, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 893, training loss= 0.05896688, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 894, training loss= 0.058947816, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 895, training loss= 0.058929592, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 896, training loss= 0.058910638, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 897, training loss= 0.05889222, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 898, training loss= 0.058873378, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 899, training loss= 0.058854394, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 900, training loss= 0.058835723, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 901, training loss= 0.058816995, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 902, training loss= 0.05879822, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 903, training loss= 0.05878, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 904, training loss= 0.058761317, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 905, training loss= 0.0587425, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 906, training loss= 0.058724042, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 907, training loss= 0.05870556, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 908, training loss= 0.058686394, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 909, training loss= 0.05866808, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 910, training loss= 0.058649115, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 911, training loss= 0.058630712, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 912, training loss= 0.05861275, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 913, training loss= 0.058593, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 914, training loss= 0.058575355, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 915, training loss= 0.05855672, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 916, training loss= 0.058537476, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 917, training loss= 0.058520082, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 918, training loss= 0.058499828, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 919, training loss= 0.058481634, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 920, training loss= 0.058462955, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 921, training loss= 0.058443945, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 922, training loss= 0.058425937, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 923, training loss= 0.05840648, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 924, training loss= 0.058388114, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 925, training loss= 0.05836965, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 926, training loss= 0.058350567, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 927, training loss= 0.05833167, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 928, training loss= 0.058312662, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 929, training loss= 0.058293484, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 930, training loss= 0.058275327, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 931, training loss= 0.058256295, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 932, training loss= 0.058237236, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 933, training loss= 0.058218107, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 934, training loss= 0.058198754, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 935, training loss= 0.05817916, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 936, training loss= 0.058159787, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 937, training loss= 0.058140617, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 938, training loss= 0.058120713, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 939, training loss= 0.058102205, training acc= 97.71263003349304%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 940, training loss= 0.058082376, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 941, training loss= 0.058062956, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 942, training loss= 0.05804336, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 943, training loss= 0.058024235, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 944, training loss= 0.05800517, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 945, training loss= 0.05798526, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 946, training loss= 0.057966504, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 947, training loss= 0.05794724, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 948, training loss= 0.05792757, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 949, training loss= 0.057909716, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 950, training loss= 0.05788976, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 951, training loss= 0.05787139, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 952, training loss= 0.057852633, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 953, training loss= 0.05783342, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 954, training loss= 0.057814978, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 955, training loss= 0.0577958, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 956, training loss= 0.057777602, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 957, training loss= 0.057758585, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 958, training loss= 0.057740442, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 959, training loss= 0.057721473, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 960, training loss= 0.057702746, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 961, training loss= 0.057683975, training acc= 97.74484634399414%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 962, training loss= 0.057665486, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 963, training loss= 0.05764669, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 964, training loss= 0.05762817, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 965, training loss= 0.05760928, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 966, training loss= 0.057590283, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 967, training loss= 0.05757274, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 968, training loss= 0.057553332, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 969, training loss= 0.057535004, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 970, training loss= 0.057516478, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 971, training loss= 0.057498015, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 972, training loss= 0.057479274, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 973, training loss= 0.057461083, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 974, training loss= 0.057442654, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 975, training loss= 0.057423823, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 976, training loss= 0.057405263, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 977, training loss= 0.057386782, training acc= 97.77706265449524%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 978, training loss= 0.05736804, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 979, training loss= 0.057349205, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 980, training loss= 0.057331767, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 981, training loss= 0.05731248, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 982, training loss= 0.05729459, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 983, training loss= 0.05727654, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 984, training loss= 0.057258047, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 985, training loss= 0.057239365, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 986, training loss= 0.05722065, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 987, training loss= 0.05720292, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 988, training loss= 0.057184577, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 989, training loss= 0.05716601, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 990, training loss= 0.057147227, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 991, training loss= 0.057129268, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 992, training loss= 0.05711132, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 993, training loss= 0.057093397, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 994, training loss= 0.05707544, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 995, training loss= 0.057056934, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 996, training loss= 0.057037633, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 997, training loss= 0.05702138, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 998, training loss= 0.05700205, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 999, training loss= 0.05698505, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1000, training loss= 0.05696704, training acc= 97.84149527549744%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1001, training loss= 0.05694861, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1002, training loss= 0.05693044, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1003, training loss= 0.056911588, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1004, training loss= 0.05689313, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1005, training loss= 0.056874685, training acc= 97.80927896499634%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1006, training loss= 0.056855988, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1007, training loss= 0.056838363, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1008, training loss= 0.056819938, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1009, training loss= 0.05680231, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1010, training loss= 0.05678338, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1011, training loss= 0.05676507, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1012, training loss= 0.0567472, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1013, training loss= 0.056729063, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1014, training loss= 0.056710996, training acc= 97.87371158599854%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1015, training loss= 0.056692634, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1016, training loss= 0.056675106, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1017, training loss= 0.056656286, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1018, training loss= 0.056639034, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1019, training loss= 0.05662061, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1020, training loss= 0.056602135, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1021, training loss= 0.056584246, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1022, training loss= 0.05656612, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1023, training loss= 0.05654881, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1024, training loss= 0.05653061, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1025, training loss= 0.056512173, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1026, training loss= 0.056494296, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1027, training loss= 0.056476805, training acc= 97.90592789649963%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1028, training loss= 0.056459256, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1029, training loss= 0.056441285, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1030, training loss= 0.05642264, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1031, training loss= 0.05640548, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1032, training loss= 0.056386605, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1033, training loss= 0.056368902, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1034, training loss= 0.05635051, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1035, training loss= 0.056334596, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1036, training loss= 0.056315195, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1037, training loss= 0.056298662, training acc= 97.93814420700073%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1038, training loss= 0.056280777, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1039, training loss= 0.056262635, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1040, training loss= 0.05624468, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1041, training loss= 0.05622562, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1042, training loss= 0.056209225, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1043, training loss= 0.056189958, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1044, training loss= 0.056172695, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1045, training loss= 0.056154862, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1046, training loss= 0.056137037, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1047, training loss= 0.0561181, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1048, training loss= 0.056100424, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1049, training loss= 0.056082644, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1050, training loss= 0.056064304, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1051, training loss= 0.056045722, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1052, training loss= 0.05602783, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1053, training loss= 0.05601009, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1054, training loss= 0.055992134, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1055, training loss= 0.055973846, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1056, training loss= 0.05595624, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1057, training loss= 0.055938426, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1058, training loss= 0.05591973, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1059, training loss= 0.055903193, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1060, training loss= 0.055883944, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1061, training loss= 0.055867087, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1062, training loss= 0.055849414, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1063, training loss= 0.055830915, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1064, training loss= 0.055814, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1065, training loss= 0.055794977, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1066, training loss= 0.055777624, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1067, training loss= 0.05576014, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1068, training loss= 0.05574217, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1069, training loss= 0.05572416, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1070, training loss= 0.05570614, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1071, training loss= 0.05568867, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1072, training loss= 0.055670965, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1073, training loss= 0.055652786, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1074, training loss= 0.05563625, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1075, training loss= 0.055617094, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1076, training loss= 0.055600237, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1077, training loss= 0.055582736, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1078, training loss= 0.055564106, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1079, training loss= 0.055548154, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1080, training loss= 0.055529334, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1081, training loss= 0.055512942, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1082, training loss= 0.055496316, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1083, training loss= 0.055478368, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1084, training loss= 0.055460367, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1085, training loss= 0.05544212, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1086, training loss= 0.055424005, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1087, training loss= 0.05540617, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1088, training loss= 0.05538863, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1089, training loss= 0.055371024, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1090, training loss= 0.05535376, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1091, training loss= 0.05533594, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1092, training loss= 0.055317678, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1093, training loss= 0.055300966, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1094, training loss= 0.05528319, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1095, training loss= 0.05526533, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1096, training loss= 0.055248097, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1097, training loss= 0.055231053, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1098, training loss= 0.05521415, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1099, training loss= 0.055196475, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1100, training loss= 0.055177838, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1101, training loss= 0.055161167, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1102, training loss= 0.055143584, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1103, training loss= 0.05512586, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1104, training loss= 0.055107526, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1105, training loss= 0.05509124, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1106, training loss= 0.05507268, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1107, training loss= 0.055056583, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1108, training loss= 0.055039745, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1109, training loss= 0.05502238, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1110, training loss= 0.05500356, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1111, training loss= 0.05498556, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1112, training loss= 0.054969553, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1113, training loss= 0.054951183, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1114, training loss= 0.05493346, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1115, training loss= 0.054916173, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1116, training loss= 0.054899458, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1117, training loss= 0.054880414, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1118, training loss= 0.05486366, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1119, training loss= 0.054846108, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1120, training loss= 0.054828342, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1121, training loss= 0.05481046, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1122, training loss= 0.05479413, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1123, training loss= 0.054777466, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1124, training loss= 0.054759018, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1125, training loss= 0.0547406, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1126, training loss= 0.054726094, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1127, training loss= 0.054707598, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1128, training loss= 0.054688666, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1129, training loss= 0.054672, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1130, training loss= 0.05465375, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1131, training loss= 0.054637246, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1132, training loss= 0.05461906, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1133, training loss= 0.05460271, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1134, training loss= 0.054585624, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1135, training loss= 0.05456721, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1136, training loss= 0.054549616, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1137, training loss= 0.054532144, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1138, training loss= 0.054514494, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1139, training loss= 0.05449786, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1140, training loss= 0.054479722, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1141, training loss= 0.054463293, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1142, training loss= 0.054445427, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1143, training loss= 0.05442843, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1144, training loss= 0.054411594, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1145, training loss= 0.054393604, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1146, training loss= 0.054375846, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1147, training loss= 0.054359294, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1148, training loss= 0.05434146, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1149, training loss= 0.05432464, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1150, training loss= 0.0543066, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1151, training loss= 0.054289944, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1152, training loss= 0.05427238, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1153, training loss= 0.054255176, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1154, training loss= 0.054237723, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1155, training loss= 0.054219913, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1156, training loss= 0.054203857, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1157, training loss= 0.054186326, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1158, training loss= 0.054168846, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1159, training loss= 0.054152053, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1160, training loss= 0.05413478, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1161, training loss= 0.054117877, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1162, training loss= 0.05410041, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1163, training loss= 0.05408402, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1164, training loss= 0.054065835, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1165, training loss= 0.05404937, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1166, training loss= 0.054031733, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1167, training loss= 0.05401485, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1168, training loss= 0.0539977, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1169, training loss= 0.053979855, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1170, training loss= 0.053963467, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1171, training loss= 0.05394584, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1172, training loss= 0.053929247, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1173, training loss= 0.05391238, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1174, training loss= 0.053895213, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1175, training loss= 0.053877637, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1176, training loss= 0.05385977, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1177, training loss= 0.05384301, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1178, training loss= 0.053825695, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1179, training loss= 0.053808503, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1180, training loss= 0.053791076, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1181, training loss= 0.053774565, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1182, training loss= 0.053757247, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1183, training loss= 0.053739894, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1184, training loss= 0.053723432, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1185, training loss= 0.053705912, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1186, training loss= 0.05368891, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1187, training loss= 0.053671468, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1188, training loss= 0.053654958, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1189, training loss= 0.053638566, training acc= 97.97036051750183%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1190, training loss= 0.053621266, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1191, training loss= 0.05360371, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1192, training loss= 0.0535864, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1193, training loss= 0.05356929, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1194, training loss= 0.053553328, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1195, training loss= 0.05353602, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1196, training loss= 0.05351945, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1197, training loss= 0.05350206, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1198, training loss= 0.053485274, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1199, training loss= 0.05346818, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1200, training loss= 0.053451933, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1201, training loss= 0.053434987, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1202, training loss= 0.053417318, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1203, training loss= 0.053400736, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1204, training loss= 0.0533841, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1205, training loss= 0.053366613, training acc= 98.00257682800293%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1206, training loss= 0.05335003, training acc= 98.03479313850403%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1207, training loss= 0.053333536, training acc= 98.03479313850403%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1208, training loss= 0.05331511, training acc= 98.03479313850403%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1209, training loss= 0.05329956, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1210, training loss= 0.053281743, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1211, training loss= 0.0532649, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1212, training loss= 0.053248268, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1213, training loss= 0.053231716, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1214, training loss= 0.053214043, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1215, training loss= 0.053197373, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1216, training loss= 0.053181488, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1217, training loss= 0.053163383, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1218, training loss= 0.05314827, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1219, training loss= 0.053131387, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1220, training loss= 0.05311336, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1221, training loss= 0.053097986, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1222, training loss= 0.05308025, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1223, training loss= 0.053064447, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1224, training loss= 0.05304734, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1225, training loss= 0.05302935, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1226, training loss= 0.053012528, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1227, training loss= 0.05299662, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1228, training loss= 0.052979466, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1229, training loss= 0.052962393, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1230, training loss= 0.052945368, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1231, training loss= 0.05292854, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1232, training loss= 0.05291277, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1233, training loss= 0.052895747, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1234, training loss= 0.05287857, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1235, training loss= 0.0528622, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1236, training loss= 0.05284501, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1237, training loss= 0.05282926, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1238, training loss= 0.052811664, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1239, training loss= 0.052795682, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1240, training loss= 0.052779194, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1241, training loss= 0.052761525, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1242, training loss= 0.05274554, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1243, training loss= 0.052727394, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1244, training loss= 0.052712608, training acc= 98.06700944900513%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1245, training loss= 0.05269408, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1246, training loss= 0.05267896, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1247, training loss= 0.052661594, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1248, training loss= 0.052644733, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1249, training loss= 0.052627932, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1250, training loss= 0.052610874, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1251, training loss= 0.05259393, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1252, training loss= 0.052576967, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1253, training loss= 0.052560706, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1254, training loss= 0.05254347, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1255, training loss= 0.052526526, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1256, training loss= 0.05251092, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1257, training loss= 0.05249324, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1258, training loss= 0.05247861, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1259, training loss= 0.05246189, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1260, training loss= 0.052443314, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1261, training loss= 0.052428592, training acc= 98.09922575950623%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1262, training loss= 0.052411027, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1263, training loss= 0.05239381, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1264, training loss= 0.052377637, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1265, training loss= 0.052360214, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1266, training loss= 0.052344143, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1267, training loss= 0.052326526, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1268, training loss= 0.052309573, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1269, training loss= 0.05229366, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1270, training loss= 0.052276324, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1271, training loss= 0.05225954, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1272, training loss= 0.052244212, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1273, training loss= 0.052226413, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1274, training loss= 0.052212268, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1275, training loss= 0.052194342, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1276, training loss= 0.052176975, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1277, training loss= 0.052160554, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1278, training loss= 0.052143622, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1279, training loss= 0.05212674, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1280, training loss= 0.052110154, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1281, training loss= 0.052093923, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1282, training loss= 0.052076306, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1283, training loss= 0.05206072, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1284, training loss= 0.05204397, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1285, training loss= 0.05202721, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1286, training loss= 0.05200972, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1287, training loss= 0.05199392, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1288, training loss= 0.05197723, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1289, training loss= 0.051961273, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1290, training loss= 0.05194471, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1291, training loss= 0.05192649, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1292, training loss= 0.05191176, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1293, training loss= 0.051895544, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1294, training loss= 0.051877864, training acc= 98.13144207000732%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1295, training loss= 0.05186049, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1296, training loss= 0.05184568, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1297, training loss= 0.051828176, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1298, training loss= 0.051811375, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1299, training loss= 0.051796544, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1300, training loss= 0.0517795, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1301, training loss= 0.051761318, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1302, training loss= 0.05174531, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1303, training loss= 0.0517293, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1304, training loss= 0.05171165, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1305, training loss= 0.051695444, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1306, training loss= 0.051677894, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1307, training loss= 0.0516628, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1308, training loss= 0.05164571, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1309, training loss= 0.05162826, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1310, training loss= 0.051612403, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1311, training loss= 0.05159532, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1312, training loss= 0.05157948, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1313, training loss= 0.051563762, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1314, training loss= 0.051545553, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1315, training loss= 0.051529754, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1316, training loss= 0.051512584, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1317, training loss= 0.051497135, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1318, training loss= 0.05148045, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1319, training loss= 0.05146403, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1320, training loss= 0.051447235, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1321, training loss= 0.05143093, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1322, training loss= 0.051414832, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1323, training loss= 0.051398367, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1324, training loss= 0.051381756, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1325, training loss= 0.051365394, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1326, training loss= 0.051349033, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1327, training loss= 0.0513326, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1328, training loss= 0.051316895, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1329, training loss= 0.051299766, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1330, training loss= 0.051283885, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1331, training loss= 0.051268194, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1332, training loss= 0.051250912, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1333, training loss= 0.051236022, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1334, training loss= 0.051218905, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1335, training loss= 0.05120388, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1336, training loss= 0.051187266, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1337, training loss= 0.051171683, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1338, training loss= 0.051153842, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1339, training loss= 0.05113974, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1340, training loss= 0.051123183, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1341, training loss= 0.051105812, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1342, training loss= 0.05109032, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1343, training loss= 0.05107355, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1344, training loss= 0.051057313, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1345, training loss= 0.051041022, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1346, training loss= 0.051025204, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1347, training loss= 0.051008172, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1348, training loss= 0.05099301, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1349, training loss= 0.050976638, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1350, training loss= 0.050960265, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1351, training loss= 0.050944865, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1352, training loss= 0.050927714, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1353, training loss= 0.050912134, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1354, training loss= 0.050895903, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1355, training loss= 0.050879735, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1356, training loss= 0.05086278, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1357, training loss= 0.05084761, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1358, training loss= 0.05083114, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1359, training loss= 0.05081481, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1360, training loss= 0.050799295, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1361, training loss= 0.050782446, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1362, training loss= 0.050766777, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1363, training loss= 0.050750624, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 1364, training loss= 0.050733995, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1365, training loss= 0.050718423, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1366, training loss= 0.05070208, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1367, training loss= 0.050684962, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1368, training loss= 0.050669428, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1369, training loss= 0.05065401, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1370, training loss= 0.050636828, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1371, training loss= 0.05062107, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1372, training loss= 0.05060549, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1373, training loss= 0.050588917, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1374, training loss= 0.050572798, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1375, training loss= 0.050557334, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1376, training loss= 0.050540376, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1377, training loss= 0.050524786, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1378, training loss= 0.050508343, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1379, training loss= 0.05049184, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1380, training loss= 0.050475687, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1381, training loss= 0.050459616, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 1382, training loss= 0.050443985, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1383, training loss= 0.050427385, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1384, training loss= 0.050411366, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1385, training loss= 0.050395127, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1386, training loss= 0.050379287, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1387, training loss= 0.050362885, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1388, training loss= 0.05034741, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1389, training loss= 0.050331816, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1390, training loss= 0.050314832, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1391, training loss= 0.050298627, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1392, training loss= 0.050282434, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1393, training loss= 0.050266452, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1394, training loss= 0.05025011, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1395, training loss= 0.050234437, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1396, training loss= 0.050218362, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1397, training loss= 0.0502021, training acc= 98.16365838050842%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1398, training loss= 0.050187126, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1399, training loss= 0.050170653, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1400, training loss= 0.050155368, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1401, training loss= 0.050138406, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1402, training loss= 0.050122708, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1403, training loss= 0.050107166, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1404, training loss= 0.05009024, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1405, training loss= 0.050073948, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1406, training loss= 0.05005865, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1407, training loss= 0.05004247, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1408, training loss= 0.05002613, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1409, training loss= 0.050009917, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1410, training loss= 0.049994044, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1411, training loss= 0.04997807, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1412, training loss= 0.049962785, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1413, training loss= 0.049946237, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1414, training loss= 0.049929943, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1415, training loss= 0.04991429, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1416, training loss= 0.049898285, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1417, training loss= 0.049881693, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1418, training loss= 0.04986583, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1419, training loss= 0.04984968, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1420, training loss= 0.04983454, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1421, training loss= 0.04981814, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1422, training loss= 0.04980347, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1423, training loss= 0.049786188, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1424, training loss= 0.049771342, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1425, training loss= 0.04975499, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1426, training loss= 0.04973917, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1427, training loss= 0.04972324, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1428, training loss= 0.049707174, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1429, training loss= 0.04969208, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1430, training loss= 0.04967571, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1431, training loss= 0.04965901, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1432, training loss= 0.049644385, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1433, training loss= 0.04962772, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1434, training loss= 0.049611215, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1435, training loss= 0.049595848, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1436, training loss= 0.0495798, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1437, training loss= 0.049563635, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1438, training loss= 0.049547672, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1439, training loss= 0.04953233, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1440, training loss= 0.049515795, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1441, training loss= 0.049499925, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1442, training loss= 0.049484536, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1443, training loss= 0.049468223, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1444, training loss= 0.04945258, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1445, training loss= 0.049436245, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1446, training loss= 0.049420822, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1447, training loss= 0.049404595, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1448, training loss= 0.04938909, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1449, training loss= 0.049372744, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1450, training loss= 0.049357317, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1451, training loss= 0.04934171, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1452, training loss= 0.049325015, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1453, training loss= 0.049310405, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1454, training loss= 0.049294412, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1455, training loss= 0.049278457, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1456, training loss= 0.04926196, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1457, training loss= 0.049246874, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1458, training loss= 0.04923029, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1459, training loss= 0.049215015, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1460, training loss= 0.049198795, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1461, training loss= 0.04918303, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1462, training loss= 0.049167532, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1463, training loss= 0.049150605, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1464, training loss= 0.04913631, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1465, training loss= 0.049119145, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1466, training loss= 0.049104, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1467, training loss= 0.04908868, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1468, training loss= 0.049071558, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1469, training loss= 0.049056415, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1470, training loss= 0.0490407, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1471, training loss= 0.04902387, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1472, training loss= 0.0490082, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1473, training loss= 0.048992194, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1474, training loss= 0.048975464, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1475, training loss= 0.048960492, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1476, training loss= 0.04894361, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1477, training loss= 0.048927993, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1478, training loss= 0.048911244, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1479, training loss= 0.048895583, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1480, training loss= 0.04887967, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1481, training loss= 0.048863173, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1482, training loss= 0.048847094, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1483, training loss= 0.04883128, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1484, training loss= 0.04881523, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1485, training loss= 0.048799314, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1486, training loss= 0.04878295, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1487, training loss= 0.0487667, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1488, training loss= 0.048750333, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1489, training loss= 0.04873432, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1490, training loss= 0.04871825, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1491, training loss= 0.048702013, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1492, training loss= 0.048686735, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1493, training loss= 0.048670672, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1494, training loss= 0.04865438, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1495, training loss= 0.048638802, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1496, training loss= 0.048623305, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1497, training loss= 0.048606846, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1498, training loss= 0.048590783, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1499, training loss= 0.048574865, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1500, training loss= 0.04855876, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1501, training loss= 0.04854278, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1502, training loss= 0.04852676, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1503, training loss= 0.048510283, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1504, training loss= 0.04849447, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1505, training loss= 0.048478253, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1506, training loss= 0.048461713, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1507, training loss= 0.04844541, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1508, training loss= 0.04842928, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1509, training loss= 0.048413295, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1510, training loss= 0.048396815, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1511, training loss= 0.048381124, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1512, training loss= 0.048364557, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1513, training loss= 0.048349455, training acc= 98.19587469100952%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1514, training loss= 0.048332874, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1515, training loss= 0.04831717, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1516, training loss= 0.04830133, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1517, training loss= 0.048284613, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1518, training loss= 0.04826878, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1519, training loss= 0.048253108, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1520, training loss= 0.048236594, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1521, training loss= 0.048220042, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1522, training loss= 0.048204485, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1523, training loss= 0.0481886, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1524, training loss= 0.048172273, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1525, training loss= 0.04815602, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1526, training loss= 0.048140094, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1527, training loss= 0.04812476, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1528, training loss= 0.048108563, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1529, training loss= 0.048091896, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1530, training loss= 0.04807611, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1531, training loss= 0.048060287, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1532, training loss= 0.04804416, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1533, training loss= 0.0480289, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1534, training loss= 0.048012473, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1535, training loss= 0.04799661, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1536, training loss= 0.047980893, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1537, training loss= 0.047964912, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1538, training loss= 0.047949012, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1539, training loss= 0.047933303, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1540, training loss= 0.047917053, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1541, training loss= 0.047901254, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1542, training loss= 0.047886178, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1543, training loss= 0.047870226, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1544, training loss= 0.04785374, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1545, training loss= 0.04783868, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1546, training loss= 0.04782303, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1547, training loss= 0.047806904, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1548, training loss= 0.047792334, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1549, training loss= 0.04777609, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1550, training loss= 0.047760867, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1551, training loss= 0.04774535, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1552, training loss= 0.047729276, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1553, training loss= 0.047713295, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1554, training loss= 0.047697898, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1555, training loss= 0.047682587, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1556, training loss= 0.0476664, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1557, training loss= 0.047650646, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1558, training loss= 0.047635235, training acc= 98.22809100151062%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1559, training loss= 0.047619604, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1560, training loss= 0.04760363, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1561, training loss= 0.047588136, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1562, training loss= 0.047571946, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1563, training loss= 0.04755669, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1564, training loss= 0.04754037, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1565, training loss= 0.047525734, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1566, training loss= 0.0475095, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1567, training loss= 0.04749393, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1568, training loss= 0.047478333, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1569, training loss= 0.047462553, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1570, training loss= 0.047446724, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1571, training loss= 0.0474308, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1572, training loss= 0.04741512, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1573, training loss= 0.047399707, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1574, training loss= 0.047384102, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1575, training loss= 0.047368493, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1576, training loss= 0.047352728, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1577, training loss= 0.04733724, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1578, training loss= 0.047321405, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 1579, training loss= 0.047305997, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1580, training loss= 0.047290124, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1581, training loss= 0.04727436, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1582, training loss= 0.04725887, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1583, training loss= 0.04724348, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1584, training loss= 0.047228, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1585, training loss= 0.04721221, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1586, training loss= 0.047196615, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1587, training loss= 0.047181293, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1588, training loss= 0.047165416, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1589, training loss= 0.047150128, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1590, training loss= 0.047133554, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1591, training loss= 0.047118496, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1592, training loss= 0.047103453, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1593, training loss= 0.047087293, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1594, training loss= 0.047071934, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1595, training loss= 0.047056124, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1596, training loss= 0.04704101, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1597, training loss= 0.04702502, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1598, training loss= 0.047008954, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1599, training loss= 0.046993345, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1600, training loss= 0.04697842, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1601, training loss= 0.046962697, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1602, training loss= 0.04694665, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1603, training loss= 0.046931352, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1604, training loss= 0.046915606, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1605, training loss= 0.04690073, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1606, training loss= 0.04688488, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1607, training loss= 0.046869252, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1608, training loss= 0.04685424, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1609, training loss= 0.04683883, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1610, training loss= 0.046823032, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1611, training loss= 0.04680708, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1612, training loss= 0.04679192, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1613, training loss= 0.046776466, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1614, training loss= 0.046761315, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1615, training loss= 0.04674615, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1616, training loss= 0.046730336, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1617, training loss= 0.046714887, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1618, training loss= 0.04670032, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1619, training loss= 0.0466842, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1620, training loss= 0.04666844, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1621, training loss= 0.046653192, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1622, training loss= 0.046638142, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1623, training loss= 0.046621893, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1624, training loss= 0.046606455, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1625, training loss= 0.046591222, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1626, training loss= 0.046575353, training acc= 98.29252362251282%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1627, training loss= 0.04656013, training acc= 98.29252362251282%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1628, training loss= 0.04654449, training acc= 98.26030731201172%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1629, training loss= 0.046528377, training acc= 98.29252362251282%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1630, training loss= 0.04651261, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1631, training loss= 0.046497453, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1632, training loss= 0.04648147, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1633, training loss= 0.046465296, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1634, training loss= 0.046450183, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1635, training loss= 0.04643437, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1636, training loss= 0.046418533, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1637, training loss= 0.046403337, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1638, training loss= 0.046387427, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1639, training loss= 0.04637144, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1640, training loss= 0.046355866, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1641, training loss= 0.046340525, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1642, training loss= 0.046324566, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1643, training loss= 0.046308678, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1644, training loss= 0.046293084, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1645, training loss= 0.046277612, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1646, training loss= 0.046261754, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1647, training loss= 0.046245802, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1648, training loss= 0.046230394, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1649, training loss= 0.04621524, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1650, training loss= 0.046199333, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1651, training loss= 0.046183765, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1652, training loss= 0.046168018, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1653, training loss= 0.046152063, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1654, training loss= 0.04613654, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1655, training loss= 0.046120916, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1656, training loss= 0.046104297, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1657, training loss= 0.04608895, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1658, training loss= 0.04607349, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1659, training loss= 0.046057712, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1660, training loss= 0.046041895, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1661, training loss= 0.04602658, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1662, training loss= 0.04601023, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1663, training loss= 0.04599504, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1664, training loss= 0.045979034, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1665, training loss= 0.04596287, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1666, training loss= 0.045947615, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1667, training loss= 0.045931432, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1668, training loss= 0.045916133, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1669, training loss= 0.04589946, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1670, training loss= 0.045884356, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1671, training loss= 0.04586856, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1672, training loss= 0.045852024, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1673, training loss= 0.04583661, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1674, training loss= 0.045821194, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1675, training loss= 0.045804806, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1676, training loss= 0.045788936, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1677, training loss= 0.045773104, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1678, training loss= 0.04575757, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1679, training loss= 0.045741793, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1680, training loss= 0.04572584, training acc= 98.32473993301392%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1681, training loss= 0.045709774, training acc= 98.35695624351501%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1682, training loss= 0.0456946, training acc= 98.35695624351501%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1683, training loss= 0.04567846, training acc= 98.35695624351501%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1684, training loss= 0.045662593, training acc= 98.35695624351501%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1685, training loss= 0.04564694, training acc= 98.35695624351501%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1686, training loss= 0.045631435, training acc= 98.35695624351501%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1687, training loss= 0.045615394, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1688, training loss= 0.045599736, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1689, training loss= 0.045584116, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1690, training loss= 0.04556842, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1691, training loss= 0.045552697, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1692, training loss= 0.045537047, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1693, training loss= 0.045521036, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1694, training loss= 0.04550569, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1695, training loss= 0.045489535, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1696, training loss= 0.045474082, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1697, training loss= 0.045458548, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1698, training loss= 0.045442645, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1699, training loss= 0.04542655, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1700, training loss= 0.04541101, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1701, training loss= 0.04539507, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1702, training loss= 0.045379803, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1703, training loss= 0.045363784, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1704, training loss= 0.045348033, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1705, training loss= 0.045333188, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1706, training loss= 0.045316927, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1707, training loss= 0.045301866, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1708, training loss= 0.045285933, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1709, training loss= 0.045270033, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1710, training loss= 0.04525465, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1711, training loss= 0.04523898, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1712, training loss= 0.045223054, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1713, training loss= 0.04520761, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1714, training loss= 0.045191888, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1715, training loss= 0.045175873, training acc= 98.38917255401611%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1716, training loss= 0.04516043, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1717, training loss= 0.04514478, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1718, training loss= 0.045128923, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1719, training loss= 0.045113668, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1720, training loss= 0.04509776, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1721, training loss= 0.04508195, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1722, training loss= 0.045066368, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1723, training loss= 0.04505072, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1724, training loss= 0.04503508, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1725, training loss= 0.045019224, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1726, training loss= 0.045004196, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1727, training loss= 0.044988215, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1728, training loss= 0.044972654, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1729, training loss= 0.044957727, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1730, training loss= 0.04494135, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1731, training loss= 0.044926498, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1732, training loss= 0.04491054, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1733, training loss= 0.044894457, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1734, training loss= 0.044878792, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1735, training loss= 0.04486367, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1736, training loss= 0.044848002, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1737, training loss= 0.04483154, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1738, training loss= 0.044816416, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1739, training loss= 0.04480095, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1740, training loss= 0.04478528, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1741, training loss= 0.044769138, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1742, training loss= 0.04475403, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1743, training loss= 0.044738427, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1744, training loss= 0.044722684, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1745, training loss= 0.04470699, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1746, training loss= 0.04469139, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1747, training loss= 0.044675943, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1748, training loss= 0.044660997, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1749, training loss= 0.044644814, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1750, training loss= 0.044630606, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1751, training loss= 0.044614058, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1752, training loss= 0.04459876, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1753, training loss= 0.044583615, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1754, training loss= 0.044567797, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1755, training loss= 0.044552397, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1756, training loss= 0.04453734, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1757, training loss= 0.044521414, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1758, training loss= 0.044505928, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1759, training loss= 0.044490978, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1760, training loss= 0.044475287, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1761, training loss= 0.044458553, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1762, training loss= 0.044443455, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1763, training loss= 0.044428352, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1764, training loss= 0.044411767, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1765, training loss= 0.044396427, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1766, training loss= 0.044381566, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1767, training loss= 0.04436523, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1768, training loss= 0.04434972, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1769, training loss= 0.044334687, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 1770, training loss= 0.044318635, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1771, training loss= 0.044302844, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1772, training loss= 0.04428731, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1773, training loss= 0.04427134, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1774, training loss= 0.04425639, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1775, training loss= 0.044240307, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1776, training loss= 0.044224866, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1777, training loss= 0.044209402, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1778, training loss= 0.044193838, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1779, training loss= 0.044178285, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1780, training loss= 0.04416255, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1781, training loss= 0.044146966, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1782, training loss= 0.04413157, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1783, training loss= 0.044116173, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1784, training loss= 0.044101045, training acc= 98.42138886451721%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1785, training loss= 0.04408553, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1786, training loss= 0.044070575, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1787, training loss= 0.044054966, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1788, training loss= 0.044039194, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1789, training loss= 0.044024672, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1790, training loss= 0.044008847, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1791, training loss= 0.0439932, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1792, training loss= 0.04397852, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1793, training loss= 0.04396296, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1794, training loss= 0.043947414, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1795, training loss= 0.043931525, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1796, training loss= 0.04391666, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1797, training loss= 0.043900877, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1798, training loss= 0.043885384, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1799, training loss= 0.043870013, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1800, training loss= 0.043855093, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1801, training loss= 0.043839503, training acc= 98.45361113548279%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1802, training loss= 0.043823972, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1803, training loss= 0.043808665, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1804, training loss= 0.04379312, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1805, training loss= 0.04377815, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1806, training loss= 0.043762304, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1807, training loss= 0.043746732, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1808, training loss= 0.04373162, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1809, training loss= 0.04371616, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1810, training loss= 0.043701444, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1811, training loss= 0.043685842, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1812, training loss= 0.043670513, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1813, training loss= 0.043655187, training acc= 98.48582744598389%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1814, training loss= 0.043640096, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1815, training loss= 0.04362427, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1816, training loss= 0.043610092, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1817, training loss= 0.043593846, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1818, training loss= 0.04357902, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1819, training loss= 0.043563846, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1820, training loss= 0.043548062, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1821, training loss= 0.04353299, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1822, training loss= 0.0435172, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1823, training loss= 0.043502543, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1824, training loss= 0.043487076, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1825, training loss= 0.04347146, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1826, training loss= 0.043456264, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1827, training loss= 0.043440826, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1828, training loss= 0.043425888, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1829, training loss= 0.043410495, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1830, training loss= 0.043395575, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1831, training loss= 0.043380465, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1832, training loss= 0.043364707, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1833, training loss= 0.04334955, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1834, training loss= 0.043334216, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1835, training loss= 0.043318976, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1836, training loss= 0.043303546, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1837, training loss= 0.043287992, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1838, training loss= 0.043272853, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1839, training loss= 0.04325748, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1840, training loss= 0.043242835, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1841, training loss= 0.04322712, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1842, training loss= 0.04321224, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1843, training loss= 0.043196116, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1844, training loss= 0.043181647, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1845, training loss= 0.04316641, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1846, training loss= 0.043151416, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1847, training loss= 0.043136034, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1848, training loss= 0.043120526, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1849, training loss= 0.043105092, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1850, training loss= 0.043089777, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1851, training loss= 0.04307453, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1852, training loss= 0.04305957, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1853, training loss= 0.043044645, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1854, training loss= 0.043028, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1855, training loss= 0.043013442, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1856, training loss= 0.0429986, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1857, training loss= 0.04298215, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1858, training loss= 0.042967327, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1859, training loss= 0.04295241, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1860, training loss= 0.042936802, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1861, training loss= 0.042921264, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1862, training loss= 0.042906456, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1863, training loss= 0.04289045, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1864, training loss= 0.042875648, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1865, training loss= 0.04286055, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1866, training loss= 0.042844657, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1867, training loss= 0.042829208, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1868, training loss= 0.04281387, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1869, training loss= 0.042798817, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1870, training loss= 0.04278292, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1871, training loss= 0.042767167, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1872, training loss= 0.04275264, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1873, training loss= 0.042736623, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1874, training loss= 0.04272129, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1875, training loss= 0.04270629, training acc= 98.51804375648499%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1876, training loss= 0.042690195, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1877, training loss= 0.04267553, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1878, training loss= 0.04266017, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1879, training loss= 0.042644918, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1880, training loss= 0.042628884, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1881, training loss= 0.042613663, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1882, training loss= 0.042598326, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1883, training loss= 0.042582244, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1884, training loss= 0.042567316, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1885, training loss= 0.042552408, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1886, training loss= 0.04253599, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1887, training loss= 0.042521063, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1888, training loss= 0.04250613, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1889, training loss= 0.04248955, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1890, training loss= 0.04247444, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1891, training loss= 0.042459197, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1892, training loss= 0.042443153, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1893, training loss= 0.042428095, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1894, training loss= 0.042412806, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1895, training loss= 0.042397838, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1896, training loss= 0.042381603, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1897, training loss= 0.042365637, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1898, training loss= 0.04235115, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1899, training loss= 0.042335328, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1900, training loss= 0.04231992, training acc= 98.55026006698608%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1901, training loss= 0.042304836, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1902, training loss= 0.04228906, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1903, training loss= 0.04227388, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1904, training loss= 0.042258054, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1905, training loss= 0.04224249, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1906, training loss= 0.042227075, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1907, training loss= 0.04221103, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1908, training loss= 0.042196613, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1909, training loss= 0.042181324, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1910, training loss= 0.042164728, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1911, training loss= 0.04214966, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1912, training loss= 0.042134352, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1913, training loss= 0.04211856, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1914, training loss= 0.042103413, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1915, training loss= 0.04208838, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1916, training loss= 0.04207247, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1917, training loss= 0.042057358, training acc= 98.58247637748718%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1918, training loss= 0.042042144, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1919, training loss= 0.04202568, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1920, training loss= 0.04201046, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1921, training loss= 0.04199512, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1922, training loss= 0.041980155, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1923, training loss= 0.04196392, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1924, training loss= 0.04194856, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1925, training loss= 0.041933555, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1926, training loss= 0.041917484, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1927, training loss= 0.0419025, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1928, training loss= 0.041887257, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1929, training loss= 0.04187096, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1930, training loss= 0.04185603, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1931, training loss= 0.041841377, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1932, training loss= 0.041825682, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1933, training loss= 0.041809384, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1934, training loss= 0.041794416, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 1935, training loss= 0.04177865, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1936, training loss= 0.04176347, training acc= 98.61469268798828%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1937, training loss= 0.041748375, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1938, training loss= 0.041731838, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1939, training loss= 0.041716915, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1940, training loss= 0.041701484, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1941, training loss= 0.041685615, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1942, training loss= 0.041670393, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1943, training loss= 0.041654587, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1944, training loss= 0.04163983, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1945, training loss= 0.0416244, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1946, training loss= 0.041608583, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1947, training loss= 0.04159288, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1948, training loss= 0.041577607, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1949, training loss= 0.041561794, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1950, training loss= 0.041546874, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1951, training loss= 0.041531324, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1952, training loss= 0.04151605, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1953, training loss= 0.041500095, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1954, training loss= 0.04148465, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1955, training loss= 0.041469164, training acc= 98.64690899848938%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1956, training loss= 0.041454155, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1957, training loss= 0.04143875, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1958, training loss= 0.04142235, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1959, training loss= 0.04140795, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1960, training loss= 0.04139258, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1961, training loss= 0.041376192, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1962, training loss= 0.0413613, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1963, training loss= 0.041345757, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1964, training loss= 0.04133009, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1965, training loss= 0.041315023, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1966, training loss= 0.04129875, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1967, training loss= 0.041284643, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1968, training loss= 0.041268855, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1969, training loss= 0.041252982, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1970, training loss= 0.04123822, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1971, training loss= 0.04122364, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1972, training loss= 0.04120731, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1973, training loss= 0.04119159, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1974, training loss= 0.04117687, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1975, training loss= 0.041160975, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1976, training loss= 0.04114447, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1977, training loss= 0.041129585, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1978, training loss= 0.041114554, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1979, training loss= 0.04109905, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1980, training loss= 0.041082717, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1981, training loss= 0.041067764, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1982, training loss= 0.041052807, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1983, training loss= 0.041037068, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1984, training loss= 0.041020587, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1985, training loss= 0.041005626, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1986, training loss= 0.040990636, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1987, training loss= 0.040974803, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1988, training loss= 0.040958583, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1989, training loss= 0.040943686, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1990, training loss= 0.040928733, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1991, training loss= 0.04091224, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1992, training loss= 0.04089713, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1993, training loss= 0.04088183, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1994, training loss= 0.040866133, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1995, training loss= 0.04085009, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1996, training loss= 0.040834952, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1997, training loss= 0.040819447, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1998, training loss= 0.040804047, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 1999, training loss= 0.040788013, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2000, training loss= 0.040773313, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2001, training loss= 0.040757608, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2002, training loss= 0.040742222, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2003, training loss= 0.040726747, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2004, training loss= 0.040711515, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2005, training loss= 0.040696107, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2006, training loss= 0.04068076, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2007, training loss= 0.04066542, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2008, training loss= 0.04064985, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2009, training loss= 0.04063431, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2010, training loss= 0.04061866, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2011, training loss= 0.04060311, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2012, training loss= 0.040587746, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2013, training loss= 0.04057215, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2014, training loss= 0.04055699, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2015, training loss= 0.040541533, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2016, training loss= 0.040526245, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2017, training loss= 0.040510416, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2018, training loss= 0.040494855, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2019, training loss= 0.04047988, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2020, training loss= 0.040463902, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2021, training loss= 0.040448602, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2022, training loss= 0.040433127, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2023, training loss= 0.040417615, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2024, training loss= 0.040402114, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2025, training loss= 0.04038666, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2026, training loss= 0.040371634, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2027, training loss= 0.040356055, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2028, training loss= 0.040340573, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2029, training loss= 0.04032544, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2030, training loss= 0.040309772, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2031, training loss= 0.04029422, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2032, training loss= 0.040278446, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2033, training loss= 0.040263403, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2034, training loss= 0.040247727, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2035, training loss= 0.040232133, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2036, training loss= 0.04021699, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2037, training loss= 0.040201437, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2038, training loss= 0.040185936, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2039, training loss= 0.04017022, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2040, training loss= 0.040154647, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2041, training loss= 0.04013949, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2042, training loss= 0.040124096, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2043, training loss= 0.040108968, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2044, training loss= 0.040093243, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2045, training loss= 0.040077697, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2046, training loss= 0.04006184, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2047, training loss= 0.04004623, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2048, training loss= 0.04003063, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2049, training loss= 0.040015288, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2050, training loss= 0.040000115, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2051, training loss= 0.03998498, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2052, training loss= 0.039968614, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2053, training loss= 0.039953373, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2054, training loss= 0.039938193, training acc= 98.67912530899048%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2055, training loss= 0.03992192, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2056, training loss= 0.039907023, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2057, training loss= 0.039891813, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2058, training loss= 0.039875813, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2059, training loss= 0.03986108, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2060, training loss= 0.039845705, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2061, training loss= 0.039830692, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2062, training loss= 0.039814547, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2063, training loss= 0.03979909, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2064, training loss= 0.039784033, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2065, training loss= 0.03976853, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2066, training loss= 0.039752256, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2067, training loss= 0.03973801, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2068, training loss= 0.03972231, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2069, training loss= 0.039706573, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2070, training loss= 0.039691467, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2071, training loss= 0.039675996, training acc= 98.71134161949158%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2072, training loss= 0.039660573, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2073, training loss= 0.039644912, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2074, training loss= 0.039629504, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2075, training loss= 0.039614636, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2076, training loss= 0.03959877, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2077, training loss= 0.039583165, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2078, training loss= 0.03956803, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2079, training loss= 0.03955266, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2080, training loss= 0.03953755, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2081, training loss= 0.03952204, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2082, training loss= 0.039506268, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2083, training loss= 0.039490875, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2084, training loss= 0.039475393, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2085, training loss= 0.0394604, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2086, training loss= 0.03944487, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2087, training loss= 0.039430194, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2088, training loss= 0.039414484, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2089, training loss= 0.03939937, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2090, training loss= 0.039384026, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2091, training loss= 0.039368924, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2092, training loss= 0.039353892, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2093, training loss= 0.039338134, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2094, training loss= 0.039322406, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2095, training loss= 0.03930709, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2096, training loss= 0.039292593, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2097, training loss= 0.03927746, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2098, training loss= 0.039261807, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2099, training loss= 0.039246466, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2100, training loss= 0.03923185, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2101, training loss= 0.039215535, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2102, training loss= 0.039200183, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2103, training loss= 0.039184283, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2104, training loss= 0.03916949, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2105, training loss= 0.039153967, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2106, training loss= 0.039137524, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2107, training loss= 0.03912303, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2108, training loss= 0.03910753, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2109, training loss= 0.039092872, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2110, training loss= 0.039076515, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2111, training loss= 0.039061587, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2112, training loss= 0.039045647, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2113, training loss= 0.03903001, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2114, training loss= 0.03901507, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2115, training loss= 0.038998976, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2116, training loss= 0.038984243, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2117, training loss= 0.038968716, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2118, training loss= 0.038952615, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2119, training loss= 0.03893726, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2120, training loss= 0.03892257, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2121, training loss= 0.03890609, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2122, training loss= 0.038890854, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2123, training loss= 0.03887584, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2124, training loss= 0.038859855, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2125, training loss= 0.03884495, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2126, training loss= 0.03882919, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2127, training loss= 0.038814012, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2128, training loss= 0.03879863, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2129, training loss= 0.0387829, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2130, training loss= 0.03876805, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2131, training loss= 0.03875291, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2132, training loss= 0.038736746, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2133, training loss= 0.038722772, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2134, training loss= 0.038707487, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2135, training loss= 0.03869068, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2136, training loss= 0.03867662, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2137, training loss= 0.038661506, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2138, training loss= 0.03864555, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2139, training loss= 0.038628742, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2140, training loss= 0.03861407, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2141, training loss= 0.038598165, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2142, training loss= 0.03858364, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2143, training loss= 0.03856859, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2144, training loss= 0.03855257, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2145, training loss= 0.038536955, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2146, training loss= 0.038521804, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2147, training loss= 0.03850602, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2148, training loss= 0.03849041, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2149, training loss= 0.038475662, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2150, training loss= 0.038460407, training acc= 98.74355792999268%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2151, training loss= 0.038443655, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2152, training loss= 0.03842931, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2153, training loss= 0.03841485, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2154, training loss= 0.03839845, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2155, training loss= 0.03838265, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2156, training loss= 0.03836734, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2157, training loss= 0.038352717, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2158, training loss= 0.038336914, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2159, training loss= 0.038321678, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2160, training loss= 0.038306445, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2161, training loss= 0.03829075, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2162, training loss= 0.038275123, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2163, training loss= 0.038259882, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2164, training loss= 0.038244795, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2165, training loss= 0.038229287, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2166, training loss= 0.0382145, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2167, training loss= 0.038198646, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2168, training loss= 0.03818297, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2169, training loss= 0.03816742, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2170, training loss= 0.038153075, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2171, training loss= 0.038137272, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2172, training loss= 0.03812153, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2173, training loss= 0.038106848, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2174, training loss= 0.0380925, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2175, training loss= 0.038075697, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2176, training loss= 0.038060334, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2177, training loss= 0.03804526, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2178, training loss= 0.03802981, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2179, training loss= 0.038015045, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2180, training loss= 0.037999254, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2181, training loss= 0.037983943, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2182, training loss= 0.037968952, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2183, training loss= 0.03795323, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2184, training loss= 0.037937846, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2185, training loss= 0.037922077, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2186, training loss= 0.03790677, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2187, training loss= 0.03789228, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2188, training loss= 0.037876375, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2189, training loss= 0.037861016, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2190, training loss= 0.037845872, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2191, training loss= 0.037830684, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2192, training loss= 0.037814878, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2193, training loss= 0.03780011, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2194, training loss= 0.037784874, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2195, training loss= 0.037769247, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2196, training loss= 0.037754897, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2197, training loss= 0.037738226, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2198, training loss= 0.037724078, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2199, training loss= 0.037708063, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2200, training loss= 0.03769249, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2201, training loss= 0.037678298, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2202, training loss= 0.037662495, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2203, training loss= 0.037646666, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2204, training loss= 0.03763267, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2205, training loss= 0.037617117, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2206, training loss= 0.037601966, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2207, training loss= 0.03758685, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2208, training loss= 0.037571684, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2209, training loss= 0.037555322, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2210, training loss= 0.037540898, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2211, training loss= 0.03752616, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2212, training loss= 0.03751, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2213, training loss= 0.037494563, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2214, training loss= 0.037479825, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2215, training loss= 0.037464797, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2216, training loss= 0.037449244, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2217, training loss= 0.03743409, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2218, training loss= 0.037418794, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2219, training loss= 0.0374037, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2220, training loss= 0.03738839, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2221, training loss= 0.037372354, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2222, training loss= 0.037356816, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2223, training loss= 0.037342448, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2224, training loss= 0.03732653, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2225, training loss= 0.037310984, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2226, training loss= 0.037295684, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2227, training loss= 0.03728025, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2228, training loss= 0.037264448, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2229, training loss= 0.037248842, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2230, training loss= 0.037234414, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2231, training loss= 0.037218396, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2232, training loss= 0.037203886, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2233, training loss= 0.03718796, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2234, training loss= 0.037173267, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2235, training loss= 0.03715709, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2236, training loss= 0.03714151, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2237, training loss= 0.037126273, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2238, training loss= 0.03711129, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2239, training loss= 0.037095487, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2240, training loss= 0.037080113, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2241, training loss= 0.03706613, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2242, training loss= 0.037049778, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2243, training loss= 0.03703321, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2244, training loss= 0.03701946, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2245, training loss= 0.03700419, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2246, training loss= 0.03698834, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2247, training loss= 0.03697323, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2248, training loss= 0.036957953, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2249, training loss= 0.036942616, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2250, training loss= 0.03692759, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2251, training loss= 0.03691201, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2252, training loss= 0.036895685, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2253, training loss= 0.036881737, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2254, training loss= 0.03686679, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2255, training loss= 0.03685079, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2256, training loss= 0.03683514, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2257, training loss= 0.036820933, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2258, training loss= 0.036805198, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2259, training loss= 0.036788553, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2260, training loss= 0.036774587, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2261, training loss= 0.03675926, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2262, training loss= 0.036743656, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2263, training loss= 0.036728855, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2264, training loss= 0.03671319, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2265, training loss= 0.03669831, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2266, training loss= 0.036682446, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2267, training loss= 0.036666855, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2268, training loss= 0.03665229, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2269, training loss= 0.036636867, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2270, training loss= 0.036621705, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2271, training loss= 0.036606286, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2272, training loss= 0.036591377, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2273, training loss= 0.036576677, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2274, training loss= 0.03656068, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2275, training loss= 0.036546007, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2276, training loss= 0.036531325, training acc= 98.77577424049377%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2277, training loss= 0.03651519, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2278, training loss= 0.036500074, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2279, training loss= 0.03648525, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2280, training loss= 0.03646983, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2281, training loss= 0.03645568, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2282, training loss= 0.036439303, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2283, training loss= 0.036424622, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2284, training loss= 0.036409292, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2285, training loss= 0.03639374, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2286, training loss= 0.036379047, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2287, training loss= 0.036363937, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2288, training loss= 0.036349546, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2289, training loss= 0.036333743, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2290, training loss= 0.03631854, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2291, training loss= 0.036302973, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2292, training loss= 0.03628857, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2293, training loss= 0.036273424, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2294, training loss= 0.036257423, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2295, training loss= 0.036243007, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2296, training loss= 0.036228158, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2297, training loss= 0.0362122, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2298, training loss= 0.036197767, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2299, training loss= 0.03618227, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2300, training loss= 0.036168486, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2301, training loss= 0.036151536, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2302, training loss= 0.036137365, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2303, training loss= 0.036122072, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2304, training loss= 0.03610643, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2305, training loss= 0.036091715, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2306, training loss= 0.036077037, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2307, training loss= 0.036061343, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2308, training loss= 0.03604603, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2309, training loss= 0.036030546, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2310, training loss= 0.03601542, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2311, training loss= 0.03600132, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2312, training loss= 0.035985377, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2313, training loss= 0.0359707, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2314, training loss= 0.035955504, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2315, training loss= 0.03594085, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2316, training loss= 0.035924807, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2317, training loss= 0.035910297, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2318, training loss= 0.035894807, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2319, training loss= 0.035879448, training acc= 98.84020686149597%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2320, training loss= 0.035865396, training acc= 98.84020686149597%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2321, training loss= 0.035849474, training acc= 98.84020686149597%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2322, training loss= 0.03583508, training acc= 98.80799055099487%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2323, training loss= 0.035820134, training acc= 98.84020686149597%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2324, training loss= 0.03580388, training acc= 98.84020686149597%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2325, training loss= 0.035789296, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2326, training loss= 0.03577429, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2327, training loss= 0.035758507, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2328, training loss= 0.035744514, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2329, training loss= 0.03572897, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2330, training loss= 0.035714503, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2331, training loss= 0.035698492, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2332, training loss= 0.035684362, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2333, training loss= 0.03567063, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2334, training loss= 0.03565354, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2335, training loss= 0.035638396, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2336, training loss= 0.035623796, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2337, training loss= 0.03560767, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2338, training loss= 0.03559301, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2339, training loss= 0.035578452, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2340, training loss= 0.035562076, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2341, training loss= 0.03554722, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2342, training loss= 0.035532564, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2343, training loss= 0.03551642, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2344, training loss= 0.03550189, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2345, training loss= 0.035487384, training acc= 98.87242317199707%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2346, training loss= 0.035472065, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2347, training loss= 0.03545729, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2348, training loss= 0.03544138, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2349, training loss= 0.035426363, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2350, training loss= 0.035411227, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2351, training loss= 0.035395402, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2352, training loss= 0.035381496, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2353, training loss= 0.035365734, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2354, training loss= 0.035350934, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2355, training loss= 0.03533626, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2356, training loss= 0.035320856, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2357, training loss= 0.03530519, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2358, training loss= 0.03528994, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2359, training loss= 0.035275392, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2360, training loss= 0.03526016, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2361, training loss= 0.035244882, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2362, training loss= 0.0352294, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2363, training loss= 0.035214502, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2364, training loss= 0.03519987, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2365, training loss= 0.035184838, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2366, training loss= 0.035169438, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2367, training loss= 0.035154354, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2368, training loss= 0.035140388, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2369, training loss= 0.035124123, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2370, training loss= 0.035108868, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2371, training loss= 0.03509388, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2372, training loss= 0.035078663, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2373, training loss= 0.035064112, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2374, training loss= 0.035048354, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2375, training loss= 0.03503318, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2376, training loss= 0.035018478, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2377, training loss= 0.03500247, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2378, training loss= 0.03498801, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2379, training loss= 0.03497353, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2380, training loss= 0.034958567, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2381, training loss= 0.034941815, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2382, training loss= 0.034929175, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2383, training loss= 0.034913864, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2384, training loss= 0.03489679, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2385, training loss= 0.034881588, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2386, training loss= 0.034866527, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2387, training loss= 0.03485131, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2388, training loss= 0.034837116, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2389, training loss= 0.034820765, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2390, training loss= 0.034806225, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2391, training loss= 0.034790892, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2392, training loss= 0.03477482, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2393, training loss= 0.03476138, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2394, training loss= 0.034745276, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2395, training loss= 0.03473026, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2396, training loss= 0.034715798, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2397, training loss= 0.0346991, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2398, training loss= 0.034684524, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2399, training loss= 0.034669366, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2400, training loss= 0.034652736, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2401, training loss= 0.034639195, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2402, training loss= 0.034622114, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2403, training loss= 0.03460734, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2404, training loss= 0.034593213, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2405, training loss= 0.03457628, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2406, training loss= 0.034560293, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2407, training loss= 0.03454597, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2408, training loss= 0.034530737, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2409, training loss= 0.034513753, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2410, training loss= 0.03449851, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2411, training loss= 0.034484327, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2412, training loss= 0.034467738, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2413, training loss= 0.034451406, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2414, training loss= 0.034437623, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2415, training loss= 0.03442178, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2416, training loss= 0.034405515, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2417, training loss= 0.03438974, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2418, training loss= 0.03437515, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2419, training loss= 0.034359388, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2420, training loss= 0.034342777, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2421, training loss= 0.034328587, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2422, training loss= 0.034313697, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2423, training loss= 0.03429698, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2424, training loss= 0.034281187, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2425, training loss= 0.03426573, training acc= 98.90463948249817%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2426, training loss= 0.03425046, training acc= 98.93685579299927%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2427, training loss= 0.034234945, training acc= 98.93685579299927%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2428, training loss= 0.034219265, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2429, training loss= 0.034204055, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2430, training loss= 0.034188334, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2431, training loss= 0.03417311, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2432, training loss= 0.03415773, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2433, training loss= 0.03414258, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2434, training loss= 0.034127004, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2435, training loss= 0.034110982, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2436, training loss= 0.034095798, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2437, training loss= 0.034080405, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2438, training loss= 0.03406616, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2439, training loss= 0.034050077, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2440, training loss= 0.034034114, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2441, training loss= 0.03401981, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2442, training loss= 0.034004167, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2443, training loss= 0.03398838, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2444, training loss= 0.03397287, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2445, training loss= 0.033957183, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2446, training loss= 0.033943225, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2447, training loss= 0.033927865, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2448, training loss= 0.033912014, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2449, training loss= 0.03389639, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2450, training loss= 0.033881765, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2451, training loss= 0.033865556, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2452, training loss= 0.033849753, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2453, training loss= 0.03383496, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2454, training loss= 0.033819173, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2455, training loss= 0.03380474, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2456, training loss= 0.033789046, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2457, training loss= 0.03377404, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2458, training loss= 0.033758957, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2459, training loss= 0.03374274, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2460, training loss= 0.03372795, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2461, training loss= 0.033712596, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2462, training loss= 0.033697337, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2463, training loss= 0.0336823, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2464, training loss= 0.033667218, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2465, training loss= 0.033652052, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2466, training loss= 0.03363632, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2467, training loss= 0.03362176, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2468, training loss= 0.033607196, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2469, training loss= 0.033591468, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2470, training loss= 0.033576842, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2471, training loss= 0.033561584, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2472, training loss= 0.033545963, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2473, training loss= 0.033530105, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2474, training loss= 0.033516083, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2475, training loss= 0.033499736, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2476, training loss= 0.033485647, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2477, training loss= 0.03347057, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2478, training loss= 0.03345524, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2479, training loss= 0.033439435, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2480, training loss= 0.03342494, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2481, training loss= 0.03341054, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2482, training loss= 0.033395026, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2483, training loss= 0.033379436, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2484, training loss= 0.03336456, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2485, training loss= 0.03334915, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2486, training loss= 0.033335306, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2487, training loss= 0.033319198, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2488, training loss= 0.033305075, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2489, training loss= 0.033289958, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2490, training loss= 0.03327435, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2491, training loss= 0.03325998, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2492, training loss= 0.033244636, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2493, training loss= 0.033228137, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2494, training loss= 0.033214487, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2495, training loss= 0.03319907, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2496, training loss= 0.033183847, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2497, training loss= 0.033169046, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2498, training loss= 0.033154562, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2499, training loss= 0.03313925, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2500, training loss= 0.033123337, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2501, training loss= 0.033109497, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2502, training loss= 0.03309429, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2503, training loss= 0.03307835, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2504, training loss= 0.033062976, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2505, training loss= 0.033049542, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2506, training loss= 0.03303353, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2507, training loss= 0.033017956, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2508, training loss= 0.03300313, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2509, training loss= 0.032988787, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2510, training loss= 0.032972656, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2511, training loss= 0.032958176, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2512, training loss= 0.032944072, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2513, training loss= 0.032928072, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2514, training loss= 0.032912645, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2515, training loss= 0.032898087, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2516, training loss= 0.03288366, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2517, training loss= 0.0328686, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2518, training loss= 0.032853235, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2519, training loss= 0.032838453, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2520, training loss= 0.03282302, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2521, training loss= 0.03280772, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2522, training loss= 0.032792747, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2523, training loss= 0.032777943, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2524, training loss= 0.032762293, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2525, training loss= 0.03274721, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2526, training loss= 0.032732364, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2527, training loss= 0.032717437, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2528, training loss= 0.03270169, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2529, training loss= 0.03268706, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2530, training loss= 0.032671936, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2531, training loss= 0.032657124, training acc= 98.96907210350037%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2532, training loss= 0.032642018, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2533, training loss= 0.03262723, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2534, training loss= 0.032611858, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2535, training loss= 0.032597017, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2536, training loss= 0.03258212, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2537, training loss= 0.032566775, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2538, training loss= 0.03255164, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2539, training loss= 0.03253749, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2540, training loss= 0.03252152, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2541, training loss= 0.032507278, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2542, training loss= 0.03249208, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2543, training loss= 0.032476794, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2544, training loss= 0.03246229, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2545, training loss= 0.032447133, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2546, training loss= 0.032431334, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2547, training loss= 0.03241697, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2548, training loss= 0.032401696, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2549, training loss= 0.032387428, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2550, training loss= 0.032370877, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2551, training loss= 0.03235531, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2552, training loss= 0.032340907, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2553, training loss= 0.03232512, training acc= 99.03350472450256%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2554, training loss= 0.03231038, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2555, training loss= 0.03229518, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2556, training loss= 0.032280132, training acc= 99.00128841400146%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2557, training loss= 0.032265346, training acc= 99.03350472450256%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2558, training loss= 0.03224959, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2559, training loss= 0.03223501, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2560, training loss= 0.03221964, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2561, training loss= 0.032204106, training acc= 99.03350472450256%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2562, training loss= 0.03218988, training acc= 99.03350472450256%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2563, training loss= 0.032174107, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2564, training loss= 0.0321585, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2565, training loss= 0.032144625, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2566, training loss= 0.032128595, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2567, training loss= 0.032113433, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2568, training loss= 0.032099754, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2569, training loss= 0.032083772, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2570, training loss= 0.03206799, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2571, training loss= 0.032053497, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2572, training loss= 0.032038536, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2573, training loss= 0.032022737, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2574, training loss= 0.032008376, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2575, training loss= 0.031993207, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2576, training loss= 0.03197803, training acc= 99.09793734550476%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2577, training loss= 0.03196367, training acc= 99.09793734550476%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2578, training loss= 0.031948384, training acc= 99.09793734550476%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2579, training loss= 0.031932227, training acc= 99.06572103500366%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2580, training loss= 0.031918146, training acc= 99.09793734550476%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2581, training loss= 0.03190226, training acc= 99.09793734550476%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2582, training loss= 0.031887107, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2583, training loss= 0.031872675, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2584, training loss= 0.031857464, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2585, training loss= 0.03184205, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2586, training loss= 0.031827338, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2587, training loss= 0.031811837, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2588, training loss= 0.031797294, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2589, training loss= 0.031781785, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2590, training loss= 0.031767055, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2591, training loss= 0.031751264, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2592, training loss= 0.03173697, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2593, training loss= 0.031721108, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2594, training loss= 0.031705737, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2595, training loss= 0.031691298, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2596, training loss= 0.0316763, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2597, training loss= 0.03166086, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2598, training loss= 0.031645223, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2599, training loss= 0.03163049, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2600, training loss= 0.031614356, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2601, training loss= 0.03159856, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2602, training loss= 0.031585038, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2603, training loss= 0.031568658, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2604, training loss= 0.031553745, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2605, training loss= 0.031539693, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2606, training loss= 0.03152307, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2607, training loss= 0.031507388, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2608, training loss= 0.03149226, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2609, training loss= 0.031476747, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2610, training loss= 0.031461056, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2611, training loss= 0.031445768, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2612, training loss= 0.031431068, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.88053894042969 ...\n",
            "\n",
            "step 2613, training loss= 0.0314153, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2614, training loss= 0.031399615, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2615, training loss= 0.031384706, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2616, training loss= 0.03136971, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2617, training loss= 0.0313544, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2618, training loss= 0.031339474, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2619, training loss= 0.03132461, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2620, training loss= 0.031309165, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2621, training loss= 0.031293582, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2622, training loss= 0.031278193, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2623, training loss= 0.03126397, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2624, training loss= 0.031248571, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2625, training loss= 0.031232757, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2626, training loss= 0.031218072, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2627, training loss= 0.031202994, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2628, training loss= 0.031188253, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2629, training loss= 0.031172644, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2630, training loss= 0.031157792, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2631, training loss= 0.031142479, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2632, training loss= 0.031127574, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2633, training loss= 0.031112049, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2634, training loss= 0.031097101, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2635, training loss= 0.03108265, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2636, training loss= 0.031067632, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2637, training loss= 0.031051632, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2638, training loss= 0.031036764, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2639, training loss= 0.031022394, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2640, training loss= 0.031006237, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2641, training loss= 0.030992297, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2642, training loss= 0.030976884, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2643, training loss= 0.030961165, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2644, training loss= 0.030946853, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2645, training loss= 0.030931197, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2646, training loss= 0.030916378, training acc= 99.13015365600586%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2647, training loss= 0.030901534, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2648, training loss= 0.030885646, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2649, training loss= 0.030871335, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2650, training loss= 0.030855868, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2651, training loss= 0.030840958, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2652, training loss= 0.030825734, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2653, training loss= 0.030810649, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2654, training loss= 0.030795716, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2655, training loss= 0.030780822, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2656, training loss= 0.030766392, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2657, training loss= 0.0307517, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2658, training loss= 0.030735623, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2659, training loss= 0.030722009, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2660, training loss= 0.030707207, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2661, training loss= 0.030691212, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2662, training loss= 0.030677171, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2663, training loss= 0.030662116, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2664, training loss= 0.030647391, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2665, training loss= 0.0306309, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2666, training loss= 0.03061682, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2667, training loss= 0.030601608, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2668, training loss= 0.030585783, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2669, training loss= 0.030572355, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2670, training loss= 0.0305575, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2671, training loss= 0.030541116, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2672, training loss= 0.030525647, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2673, training loss= 0.030511083, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2674, training loss= 0.030496607, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2675, training loss= 0.03048065, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2676, training loss= 0.030466216, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2677, training loss= 0.030451618, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2678, training loss= 0.03043656, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2679, training loss= 0.030421387, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2680, training loss= 0.030407377, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2681, training loss= 0.03039296, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2682, training loss= 0.030376721, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2683, training loss= 0.030361652, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2684, training loss= 0.030347018, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2685, training loss= 0.030331967, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2686, training loss= 0.030316757, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2687, training loss= 0.030302964, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2688, training loss= 0.030287808, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2689, training loss= 0.030273432, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2690, training loss= 0.030257465, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2691, training loss= 0.030242696, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2692, training loss= 0.030227931, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2693, training loss= 0.030213298, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2694, training loss= 0.030197669, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2695, training loss= 0.03018355, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2696, training loss= 0.030167831, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2697, training loss= 0.030152557, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2698, training loss= 0.030137451, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2699, training loss= 0.030122515, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2700, training loss= 0.030107899, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2701, training loss= 0.03009232, training acc= 99.16236996650696%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2702, training loss= 0.030077998, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2703, training loss= 0.030063817, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2704, training loss= 0.030048052, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2705, training loss= 0.030033644, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2706, training loss= 0.030019743, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2707, training loss= 0.030002123, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2708, training loss= 0.029988857, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2709, training loss= 0.029973133, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2710, training loss= 0.029957911, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2711, training loss= 0.029943468, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2712, training loss= 0.029927889, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2713, training loss= 0.029914277, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2714, training loss= 0.02989873, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2715, training loss= 0.029883519, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2716, training loss= 0.029868798, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2717, training loss= 0.029854076, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2718, training loss= 0.029838849, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2719, training loss= 0.029823933, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2720, training loss= 0.029810088, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2721, training loss= 0.029793201, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2722, training loss= 0.029779261, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2723, training loss= 0.029764967, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2724, training loss= 0.029748656, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2725, training loss= 0.029734636, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2726, training loss= 0.029719038, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2727, training loss= 0.029703997, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2728, training loss= 0.029688675, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2729, training loss= 0.02967404, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2730, training loss= 0.02965871, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2731, training loss= 0.029644372, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2732, training loss= 0.029629143, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2733, training loss= 0.029614605, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2734, training loss= 0.029599082, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2735, training loss= 0.02958364, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2736, training loss= 0.029569656, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2737, training loss= 0.029554125, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2738, training loss= 0.029539933, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2739, training loss= 0.029525, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2740, training loss= 0.029510228, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2741, training loss= 0.02949519, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2742, training loss= 0.029481376, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2743, training loss= 0.029465612, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2744, training loss= 0.029451136, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2745, training loss= 0.029437473, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2746, training loss= 0.02942111, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2747, training loss= 0.02940667, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2748, training loss= 0.029392634, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2749, training loss= 0.029376134, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2750, training loss= 0.029362578, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2751, training loss= 0.029347565, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2752, training loss= 0.029332167, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2753, training loss= 0.029317554, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2754, training loss= 0.029303057, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2755, training loss= 0.029287912, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2756, training loss= 0.02927309, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2757, training loss= 0.029258218, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2758, training loss= 0.02924287, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2759, training loss= 0.029228661, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2760, training loss= 0.029213598, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2761, training loss= 0.029198823, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2762, training loss= 0.029183399, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2763, training loss= 0.029169558, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2764, training loss= 0.02915464, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2765, training loss= 0.02913903, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2766, training loss= 0.02912506, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2767, training loss= 0.029109953, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2768, training loss= 0.029094921, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2769, training loss= 0.029081475, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2770, training loss= 0.029065985, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2771, training loss= 0.029051065, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2772, training loss= 0.029037122, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2773, training loss= 0.02902221, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2774, training loss= 0.029008277, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2775, training loss= 0.028991515, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2776, training loss= 0.028979473, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2777, training loss= 0.02896356, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2778, training loss= 0.028948098, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2779, training loss= 0.028934805, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2780, training loss= 0.02891812, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2781, training loss= 0.028904896, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2782, training loss= 0.028891062, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2783, training loss= 0.02887451, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2784, training loss= 0.028861685, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2785, training loss= 0.028846715, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2786, training loss= 0.028830646, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2787, training loss= 0.028816972, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2788, training loss= 0.028801912, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2789, training loss= 0.028786408, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2790, training loss= 0.028772742, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2791, training loss= 0.028757237, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2792, training loss= 0.028742975, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2793, training loss= 0.028728355, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2794, training loss= 0.02871231, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2795, training loss= 0.028699173, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2796, training loss= 0.028683987, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2797, training loss= 0.028668514, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2798, training loss= 0.028655015, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2799, training loss= 0.028639466, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2800, training loss= 0.02862487, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2801, training loss= 0.02861109, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2802, training loss= 0.028594902, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2803, training loss= 0.02858191, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2804, training loss= 0.02856655, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2805, training loss= 0.028552767, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2806, training loss= 0.028538838, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2807, training loss= 0.028522655, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2808, training loss= 0.028508918, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2809, training loss= 0.028493311, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2810, training loss= 0.028479373, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2811, training loss= 0.028464967, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2812, training loss= 0.028449407, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2813, training loss= 0.028436054, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2814, training loss= 0.02841977, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2815, training loss= 0.028407302, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2816, training loss= 0.02839249, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2817, training loss= 0.028376024, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2818, training loss= 0.028362786, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2819, training loss= 0.028348895, training acc= 99.19458627700806%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2820, training loss= 0.02833262, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2821, training loss= 0.028320326, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2822, training loss= 0.028305076, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2823, training loss= 0.028289706, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2824, training loss= 0.028275415, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2825, training loss= 0.028260205, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2826, training loss= 0.028245592, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2827, training loss= 0.028232355, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2828, training loss= 0.028216781, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2829, training loss= 0.028202372, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2830, training loss= 0.02818783, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2831, training loss= 0.028173175, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2832, training loss= 0.028159952, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2833, training loss= 0.028144863, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2834, training loss= 0.028129112, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2835, training loss= 0.028115397, training acc= 99.22680258750916%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2836, training loss= 0.0281011, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2837, training loss= 0.02808625, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2838, training loss= 0.028071264, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2839, training loss= 0.028056504, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2840, training loss= 0.028042184, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2841, training loss= 0.028027931, training acc= 99.25901889801025%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2842, training loss= 0.028012618, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2843, training loss= 0.027998444, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2844, training loss= 0.02798407, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2845, training loss= 0.027969345, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2846, training loss= 0.027954297, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2847, training loss= 0.027940316, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2848, training loss= 0.027925014, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2849, training loss= 0.027911188, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2850, training loss= 0.027896792, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2851, training loss= 0.027881796, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2852, training loss= 0.027867686, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2853, training loss= 0.027854009, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2854, training loss= 0.02783866, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2855, training loss= 0.027824154, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2856, training loss= 0.02781055, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2857, training loss= 0.027795583, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2858, training loss= 0.027781138, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2859, training loss= 0.027767034, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2860, training loss= 0.027753102, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2861, training loss= 0.027738044, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2862, training loss= 0.027723733, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2863, training loss= 0.027709603, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2864, training loss= 0.027694898, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2865, training loss= 0.027679898, training acc= 99.29123520851135%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2866, training loss= 0.027666396, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2867, training loss= 0.027651684, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2868, training loss= 0.027637143, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2869, training loss= 0.027622888, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2870, training loss= 0.02760914, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2871, training loss= 0.02759383, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2872, training loss= 0.027579956, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2873, training loss= 0.027565647, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2874, training loss= 0.027551163, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2875, training loss= 0.027537098, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2876, training loss= 0.027523935, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2877, training loss= 0.027509049, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2878, training loss= 0.027495025, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2879, training loss= 0.027480742, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2880, training loss= 0.02746804, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2881, training loss= 0.027453277, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2882, training loss= 0.027437367, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2883, training loss= 0.027424384, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2884, training loss= 0.027408732, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2885, training loss= 0.027395727, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2886, training loss= 0.027381266, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2887, training loss= 0.027366258, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2888, training loss= 0.027352823, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.80540466308594 ...\n",
            "\n",
            "step 2889, training loss= 0.02733766, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2890, training loss= 0.027323494, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2891, training loss= 0.027308833, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2892, training loss= 0.027294613, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2893, training loss= 0.027280752, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2894, training loss= 0.027266014, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2895, training loss= 0.027251812, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2896, training loss= 0.027237786, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2897, training loss= 0.027223304, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2898, training loss= 0.027209453, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2899, training loss= 0.027194463, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2900, training loss= 0.02717987, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2901, training loss= 0.027165918, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2902, training loss= 0.027150895, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2903, training loss= 0.027137075, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2904, training loss= 0.027123475, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2905, training loss= 0.027107576, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2906, training loss= 0.027093945, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2907, training loss= 0.027079264, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2908, training loss= 0.027065324, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2909, training loss= 0.027051182, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2910, training loss= 0.027035806, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2911, training loss= 0.027023908, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2912, training loss= 0.02700864, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2913, training loss= 0.026993299, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2914, training loss= 0.02698053, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2915, training loss= 0.026966317, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2916, training loss= 0.026950488, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2917, training loss= 0.026937477, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2918, training loss= 0.026922405, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2919, training loss= 0.026907237, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2920, training loss= 0.026894597, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2921, training loss= 0.026879216, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2922, training loss= 0.026864987, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2923, training loss= 0.026851192, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2924, training loss= 0.026835604, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2925, training loss= 0.026823064, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2926, training loss= 0.026808733, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2927, training loss= 0.026792798, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2928, training loss= 0.026779715, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2929, training loss= 0.026764732, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2930, training loss= 0.026749562, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2931, training loss= 0.026737267, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2932, training loss= 0.026721757, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2933, training loss= 0.02670761, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2934, training loss= 0.026694596, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2935, training loss= 0.026679164, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2936, training loss= 0.026666015, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2937, training loss= 0.026653448, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2938, training loss= 0.026637139, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2939, training loss= 0.026624855, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2940, training loss= 0.02661113, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2941, training loss= 0.026595032, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2942, training loss= 0.02658131, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2943, training loss= 0.02656772, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2944, training loss= 0.026552431, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2945, training loss= 0.026537761, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2946, training loss= 0.026524369, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2947, training loss= 0.02650908, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2948, training loss= 0.026495162, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2949, training loss= 0.026481103, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2950, training loss= 0.026465636, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2951, training loss= 0.026452469, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2952, training loss= 0.026437284, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2953, training loss= 0.026423741, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2954, training loss= 0.026409356, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2955, training loss= 0.026395183, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2956, training loss= 0.026381152, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2957, training loss= 0.02636673, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2958, training loss= 0.02635285, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2959, training loss= 0.026338266, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2960, training loss= 0.026323844, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2961, training loss= 0.026309581, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2962, training loss= 0.02629633, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2963, training loss= 0.026281804, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2964, training loss= 0.026267115, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2965, training loss= 0.026252788, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2966, training loss= 0.026239095, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2967, training loss= 0.026225017, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2968, training loss= 0.02620995, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2969, training loss= 0.026196748, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2970, training loss= 0.02618194, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2971, training loss= 0.02616828, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2972, training loss= 0.026154423, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2973, training loss= 0.02613981, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2974, training loss= 0.026126422, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2975, training loss= 0.026111845, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2976, training loss= 0.026098086, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 2977, training loss= 0.026083667, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2978, training loss= 0.026069593, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2979, training loss= 0.026056258, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2980, training loss= 0.026041174, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2981, training loss= 0.026027912, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2982, training loss= 0.026013495, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2983, training loss= 0.025998631, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2984, training loss= 0.025984252, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2985, training loss= 0.025971193, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2986, training loss= 0.025956504, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2987, training loss= 0.02594256, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2988, training loss= 0.025928987, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2989, training loss= 0.025914775, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2990, training loss= 0.02590036, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2991, training loss= 0.025886305, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2992, training loss= 0.025872804, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2993, training loss= 0.025858764, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2994, training loss= 0.025845483, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2995, training loss= 0.025830893, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2996, training loss= 0.025817188, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2997, training loss= 0.025802776, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2998, training loss= 0.025788326, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 2999, training loss= 0.025774794, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3000, training loss= 0.025761282, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3001, training loss= 0.025746353, training acc= 99.32345151901245%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3002, training loss= 0.025731735, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3003, training loss= 0.025718523, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3004, training loss= 0.02570322, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3005, training loss= 0.02569061, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3006, training loss= 0.02567622, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3007, training loss= 0.0256616, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3008, training loss= 0.02564758, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3009, training loss= 0.025634065, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3010, training loss= 0.02561948, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3011, training loss= 0.025605049, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3012, training loss= 0.025591686, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3013, training loss= 0.025578396, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3014, training loss= 0.025564898, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3015, training loss= 0.025549717, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3016, training loss= 0.02553831, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3017, training loss= 0.025523482, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3018, training loss= 0.025508326, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3019, training loss= 0.025494905, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3020, training loss= 0.025480028, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3021, training loss= 0.025467368, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3022, training loss= 0.025453636, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3023, training loss= 0.025439752, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3024, training loss= 0.025425328, training acc= 99.35566782951355%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3025, training loss= 0.025410613, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3026, training loss= 0.025398014, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3027, training loss= 0.025383826, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3028, training loss= 0.025369788, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3029, training loss= 0.025356464, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3030, training loss= 0.025341451, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3031, training loss= 0.025327666, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3032, training loss= 0.025313472, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3033, training loss= 0.025299367, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3034, training loss= 0.025287163, training acc= 99.38788414001465%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3035, training loss= 0.025271496, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3036, training loss= 0.025258122, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3037, training loss= 0.025245812, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3038, training loss= 0.02522979, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3039, training loss= 0.025216283, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3040, training loss= 0.025203379, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3041, training loss= 0.025188144, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3042, training loss= 0.025175203, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3043, training loss= 0.025162505, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3044, training loss= 0.025146278, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3045, training loss= 0.025134986, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3046, training loss= 0.025120346, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3047, training loss= 0.025105512, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3048, training loss= 0.02509224, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3049, training loss= 0.025077777, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3050, training loss= 0.025063805, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3051, training loss= 0.025050651, training acc= 99.42010045051575%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3052, training loss= 0.025036724, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3053, training loss= 0.025022447, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3054, training loss= 0.025009532, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3055, training loss= 0.024995266, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3056, training loss= 0.024981577, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3057, training loss= 0.024968067, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3058, training loss= 0.024954263, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3059, training loss= 0.024940116, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3060, training loss= 0.024926074, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3061, training loss= 0.024912188, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3062, training loss= 0.02489879, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3063, training loss= 0.024884718, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3064, training loss= 0.024870815, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3065, training loss= 0.024857933, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3066, training loss= 0.024843987, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3067, training loss= 0.024830718, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3068, training loss= 0.024816649, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3069, training loss= 0.024803078, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3070, training loss= 0.024788324, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3071, training loss= 0.02477501, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3072, training loss= 0.02476123, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3073, training loss= 0.024748288, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3074, training loss= 0.024733702, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3075, training loss= 0.02471993, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3076, training loss= 0.024706569, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3077, training loss= 0.024692526, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3078, training loss= 0.02467816, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3079, training loss= 0.024664663, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3080, training loss= 0.024651095, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3081, training loss= 0.024636947, training acc= 99.45231676101685%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3082, training loss= 0.024623046, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3083, training loss= 0.024609411, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3084, training loss= 0.02459569, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3085, training loss= 0.024581775, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3086, training loss= 0.024567273, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3087, training loss= 0.024554195, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3088, training loss= 0.02454098, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3089, training loss= 0.024525952, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3090, training loss= 0.024512902, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3091, training loss= 0.024498854, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3092, training loss= 0.024484795, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3093, training loss= 0.024470743, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3094, training loss= 0.024457462, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3095, training loss= 0.024442814, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3096, training loss= 0.024428809, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3097, training loss= 0.024415566, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3098, training loss= 0.024401447, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3099, training loss= 0.024386704, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3100, training loss= 0.024373597, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3101, training loss= 0.024358787, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3102, training loss= 0.024345133, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3103, training loss= 0.024330802, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3104, training loss= 0.02431794, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3105, training loss= 0.02430275, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3106, training loss= 0.024290329, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3107, training loss= 0.024274819, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3108, training loss= 0.024262674, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3109, training loss= 0.024246939, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3110, training loss= 0.024231898, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3111, training loss= 0.024219811, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3112, training loss= 0.02420407, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3113, training loss= 0.02419127, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3114, training loss= 0.02417623, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3115, training loss= 0.024161892, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3116, training loss= 0.024148092, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3117, training loss= 0.024133509, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3118, training loss= 0.024118694, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3119, training loss= 0.02410441, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3120, training loss= 0.02409225, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3121, training loss= 0.024075998, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3122, training loss= 0.024061525, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3123, training loss= 0.024049392, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3124, training loss= 0.024033815, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3125, training loss= 0.024018573, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3126, training loss= 0.024004271, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3127, training loss= 0.023990653, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3128, training loss= 0.023975676, training acc= 99.51675534248352%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3129, training loss= 0.023961416, training acc= 99.51675534248352%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3130, training loss= 0.023946948, training acc= 99.51675534248352%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3131, training loss= 0.023933463, training acc= 99.48453903198242%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3132, training loss= 0.023918327, training acc= 99.51675534248352%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3133, training loss= 0.023903908, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3134, training loss= 0.023890093, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3135, training loss= 0.023875417, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3136, training loss= 0.023861265, training acc= 99.51675534248352%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3137, training loss= 0.02384643, training acc= 99.51675534248352%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3138, training loss= 0.023832252, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3139, training loss= 0.02381842, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3140, training loss= 0.023804229, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3141, training loss= 0.023790179, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3142, training loss= 0.023775699, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3143, training loss= 0.023761092, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3144, training loss= 0.023747407, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3145, training loss= 0.023732886, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3146, training loss= 0.023718536, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3147, training loss= 0.023704488, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3148, training loss= 0.02369078, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3149, training loss= 0.023676734, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3150, training loss= 0.023663191, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3151, training loss= 0.023650426, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3152, training loss= 0.023635361, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3153, training loss= 0.023621975, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3154, training loss= 0.023608435, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3155, training loss= 0.023594454, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3156, training loss= 0.023580194, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3157, training loss= 0.023566905, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3158, training loss= 0.02355324, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3159, training loss= 0.023539316, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3160, training loss= 0.023526633, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3161, training loss= 0.023512037, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3162, training loss= 0.023500374, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3163, training loss= 0.023484347, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3164, training loss= 0.023470711, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3165, training loss= 0.023458181, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3166, training loss= 0.023443548, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3167, training loss= 0.023429643, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3168, training loss= 0.02341634, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3169, training loss= 0.023402968, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3170, training loss= 0.023388475, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3171, training loss= 0.023376253, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3172, training loss= 0.023361128, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3173, training loss= 0.02334785, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3174, training loss= 0.023335788, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3175, training loss= 0.023320673, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3176, training loss= 0.02330774, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3177, training loss= 0.023293337, training acc= 99.54897165298462%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3178, training loss= 0.023279756, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3179, training loss= 0.02326633, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3180, training loss= 0.023252344, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3181, training loss= 0.023238689, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3182, training loss= 0.023225876, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3183, training loss= 0.023213277, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3184, training loss= 0.023199715, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3185, training loss= 0.023186192, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3186, training loss= 0.023170989, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3187, training loss= 0.023158789, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3188, training loss= 0.023144022, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3189, training loss= 0.023132699, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3190, training loss= 0.02311747, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3191, training loss= 0.023105355, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3192, training loss= 0.02309083, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3193, training loss= 0.023077652, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3194, training loss= 0.0230637, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3195, training loss= 0.023050768, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3196, training loss= 0.023037475, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3197, training loss= 0.023023074, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3198, training loss= 0.02301041, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3199, training loss= 0.022996895, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3200, training loss= 0.022983294, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3201, training loss= 0.02296939, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3202, training loss= 0.022956315, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3203, training loss= 0.022942882, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3204, training loss= 0.022929408, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3205, training loss= 0.022915926, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3206, training loss= 0.022902265, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3207, training loss= 0.022889713, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3208, training loss= 0.02287541, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3209, training loss= 0.022861721, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3210, training loss= 0.022848962, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3211, training loss= 0.022835061, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3212, training loss= 0.022821825, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3213, training loss= 0.02280891, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3214, training loss= 0.022795772, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3215, training loss= 0.022782259, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3216, training loss= 0.022769513, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3217, training loss= 0.022755126, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3218, training loss= 0.022742923, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3219, training loss= 0.022730319, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3220, training loss= 0.022716213, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3221, training loss= 0.022702783, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3222, training loss= 0.022689398, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3223, training loss= 0.022676216, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3224, training loss= 0.022663075, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3225, training loss= 0.022650156, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3226, training loss= 0.022636969, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3227, training loss= 0.022624603, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3228, training loss= 0.02261066, training acc= 99.58118796348572%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3229, training loss= 0.022596605, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3230, training loss= 0.022586346, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3231, training loss= 0.022572137, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3232, training loss= 0.022557825, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3233, training loss= 0.022543414, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3234, training loss= 0.022531169, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3235, training loss= 0.022519296, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3236, training loss= 0.022504186, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3237, training loss= 0.022491861, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3238, training loss= 0.022478836, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3239, training loss= 0.022467986, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3240, training loss= 0.022451075, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3241, training loss= 0.022438968, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3242, training loss= 0.0224268, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3243, training loss= 0.022412194, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3244, training loss= 0.022399131, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3245, training loss= 0.022386083, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3246, training loss= 0.022373483, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3247, training loss= 0.02235893, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3248, training loss= 0.022346644, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3249, training loss= 0.02233336, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3250, training loss= 0.022320101, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3251, training loss= 0.022306144, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3252, training loss= 0.022293553, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3253, training loss= 0.022279967, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3254, training loss= 0.022266796, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3255, training loss= 0.022253955, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3256, training loss= 0.022240829, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3257, training loss= 0.022227649, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3258, training loss= 0.022214474, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3259, training loss= 0.022201532, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3260, training loss= 0.022189032, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3261, training loss= 0.022175698, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3262, training loss= 0.022162205, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3263, training loss= 0.022149932, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3264, training loss= 0.02213647, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3265, training loss= 0.02212385, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3266, training loss= 0.022109948, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3267, training loss= 0.022097278, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3268, training loss= 0.022084445, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3269, training loss= 0.022070806, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3270, training loss= 0.022058217, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3271, training loss= 0.022045216, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3272, training loss= 0.022032289, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3273, training loss= 0.02202015, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3274, training loss= 0.022006521, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3275, training loss= 0.021996008, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3276, training loss= 0.021980526, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3277, training loss= 0.021970216, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3278, training loss= 0.021956693, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3279, training loss= 0.021941567, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3280, training loss= 0.02193172, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3281, training loss= 0.021915793, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3282, training loss= 0.021905227, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3283, training loss= 0.02189196, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3284, training loss= 0.021876628, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3285, training loss= 0.021867812, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3286, training loss= 0.021851253, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3287, training loss= 0.021840679, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3288, training loss= 0.02182769, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3289, training loss= 0.021813152, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3290, training loss= 0.021802623, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3291, training loss= 0.021786459, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3292, training loss= 0.021774722, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3293, training loss= 0.021762319, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3294, training loss= 0.021749133, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3295, training loss= 0.021736495, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3296, training loss= 0.021722855, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3297, training loss= 0.021711273, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3298, training loss= 0.021698823, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3299, training loss= 0.021684682, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3300, training loss= 0.021670643, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3301, training loss= 0.021658862, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3302, training loss= 0.021644896, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3303, training loss= 0.021632254, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3304, training loss= 0.021618726, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3305, training loss= 0.021606468, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3306, training loss= 0.021593036, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3307, training loss= 0.02158026, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3308, training loss= 0.021567725, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3309, training loss= 0.021554863, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3310, training loss= 0.021541456, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3311, training loss= 0.021528596, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3312, training loss= 0.02151606, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3313, training loss= 0.021502811, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3314, training loss= 0.021489942, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3315, training loss= 0.021477995, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3316, training loss= 0.021464897, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3317, training loss= 0.021453101, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3318, training loss= 0.021439865, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3319, training loss= 0.021426804, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3320, training loss= 0.021414887, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3321, training loss= 0.021401756, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3322, training loss= 0.021389961, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3323, training loss= 0.02137585, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3324, training loss= 0.021362882, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3325, training loss= 0.02135098, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3326, training loss= 0.021338332, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3327, training loss= 0.021325273, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3328, training loss= 0.021311441, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3329, training loss= 0.021299507, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3330, training loss= 0.02128548, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3331, training loss= 0.021274056, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3332, training loss= 0.021260504, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3333, training loss= 0.021247983, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3334, training loss= 0.021235427, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3335, training loss= 0.021222217, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3336, training loss= 0.02121011, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3337, training loss= 0.021196615, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3338, training loss= 0.021184454, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3339, training loss= 0.021171112, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3340, training loss= 0.021158433, training acc= 99.61340427398682%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3341, training loss= 0.021146083, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3342, training loss= 0.021132998, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3343, training loss= 0.021120422, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3344, training loss= 0.0211078, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3345, training loss= 0.021095805, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3346, training loss= 0.021083409, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3347, training loss= 0.021069357, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3348, training loss= 0.021058118, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3349, training loss= 0.02104329, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3350, training loss= 0.021031816, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3351, training loss= 0.021018026, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3352, training loss= 0.021005202, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3353, training loss= 0.020992335, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3354, training loss= 0.020979784, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3355, training loss= 0.020966368, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3356, training loss= 0.020953624, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3357, training loss= 0.02094095, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3358, training loss= 0.020927494, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3359, training loss= 0.020915966, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3360, training loss= 0.020902772, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3361, training loss= 0.020890014, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3362, training loss= 0.02087847, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3363, training loss= 0.020864418, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3364, training loss= 0.020852588, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3365, training loss= 0.020839648, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3366, training loss= 0.020825874, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3367, training loss= 0.020815633, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3368, training loss= 0.020803107, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3369, training loss= 0.020789621, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3370, training loss= 0.02077715, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3371, training loss= 0.020769008, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3372, training loss= 0.020752754, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3373, training loss= 0.020740261, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3374, training loss= 0.02072953, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3375, training loss= 0.020714158, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3376, training loss= 0.020701896, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3377, training loss= 0.020689145, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3378, training loss= 0.020676406, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3379, training loss= 0.02066518, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3380, training loss= 0.02065108, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3381, training loss= 0.020637533, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3382, training loss= 0.020625904, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3383, training loss= 0.020613568, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.73027801513672 ...\n",
            "\n",
            "step 3384, training loss= 0.02060032, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3385, training loss= 0.020587549, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3386, training loss= 0.020575576, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3387, training loss= 0.020561725, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3388, training loss= 0.020550644, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3389, training loss= 0.020538209, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3390, training loss= 0.020524949, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3391, training loss= 0.02051246, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3392, training loss= 0.02050123, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3393, training loss= 0.020488655, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3394, training loss= 0.020473946, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3395, training loss= 0.020463351, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3396, training loss= 0.02044944, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3397, training loss= 0.020437093, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3398, training loss= 0.020424066, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3399, training loss= 0.02041142, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3400, training loss= 0.020398939, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3401, training loss= 0.020386701, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3402, training loss= 0.020373682, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3403, training loss= 0.020361306, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3404, training loss= 0.020349262, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3405, training loss= 0.020336632, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3406, training loss= 0.020324446, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3407, training loss= 0.02031342, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3408, training loss= 0.02030171, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3409, training loss= 0.020287137, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3410, training loss= 0.020277632, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3411, training loss= 0.020262964, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3412, training loss= 0.020251984, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3413, training loss= 0.020238876, training acc= 99.64562058448792%\n",
            "Validation Accuracy 88.65514373779297 ...\n",
            "\n",
            "step 3414, training loss= 0.02022528, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3415, training loss= 0.020215018, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3416, training loss= 0.020200659, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3417, training loss= 0.020189706, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3418, training loss= 0.020175852, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3419, training loss= 0.020166108, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3420, training loss= 0.020151537, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3421, training loss= 0.020140685, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3422, training loss= 0.020128263, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3423, training loss= 0.020115562, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3424, training loss= 0.02010399, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3425, training loss= 0.020089773, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3426, training loss= 0.020079864, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3427, training loss= 0.020067247, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3428, training loss= 0.020053782, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3429, training loss= 0.020042751, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3430, training loss= 0.02002958, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3431, training loss= 0.020017842, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3432, training loss= 0.020004446, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3433, training loss= 0.019993523, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3434, training loss= 0.0199801, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3435, training loss= 0.019968407, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3436, training loss= 0.01995606, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3437, training loss= 0.01994397, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3438, training loss= 0.019931247, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3439, training loss= 0.019919008, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3440, training loss= 0.019907953, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3441, training loss= 0.019894505, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3442, training loss= 0.019882526, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3443, training loss= 0.019870002, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3444, training loss= 0.019858276, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3445, training loss= 0.019845795, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3446, training loss= 0.019833885, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3447, training loss= 0.019821102, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3448, training loss= 0.019809902, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3449, training loss= 0.019797416, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3450, training loss= 0.019785043, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3451, training loss= 0.019773472, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3452, training loss= 0.019761246, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3453, training loss= 0.019749472, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3454, training loss= 0.019736437, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3455, training loss= 0.01972434, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3456, training loss= 0.019712284, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3457, training loss= 0.0197011, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3458, training loss= 0.019687934, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3459, training loss= 0.01967573, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3460, training loss= 0.019663842, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3461, training loss= 0.019651957, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3462, training loss= 0.019639973, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3463, training loss= 0.019627402, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3464, training loss= 0.019615972, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3465, training loss= 0.01960379, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3466, training loss= 0.019591894, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3467, training loss= 0.019579649, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3468, training loss= 0.019568503, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3469, training loss= 0.01955554, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3470, training loss= 0.019543288, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3471, training loss= 0.019531006, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3472, training loss= 0.019521138, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3473, training loss= 0.019506512, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3474, training loss= 0.019495616, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3475, training loss= 0.019484116, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3476, training loss= 0.01947164, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3477, training loss= 0.019457918, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3478, training loss= 0.019446094, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3479, training loss= 0.019435465, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3480, training loss= 0.019422757, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3481, training loss= 0.019410446, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3482, training loss= 0.019398, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3483, training loss= 0.019387936, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3484, training loss= 0.019374589, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3485, training loss= 0.019363357, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3486, training loss= 0.019350786, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3487, training loss= 0.01934044, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3488, training loss= 0.019326512, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3489, training loss= 0.019315613, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3490, training loss= 0.019302985, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3491, training loss= 0.019291319, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3492, training loss= 0.019278737, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3493, training loss= 0.019267844, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3494, training loss= 0.019255118, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3495, training loss= 0.019243117, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3496, training loss= 0.019230938, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3497, training loss= 0.019218808, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3498, training loss= 0.019206755, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3499, training loss= 0.01919546, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3500, training loss= 0.019183338, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3501, training loss= 0.019171173, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3502, training loss= 0.019159853, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3503, training loss= 0.01914721, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3504, training loss= 0.01913625, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3505, training loss= 0.019122714, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3506, training loss= 0.019111775, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3507, training loss= 0.019099504, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3508, training loss= 0.01908703, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3509, training loss= 0.019074803, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3510, training loss= 0.019063689, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3511, training loss= 0.019051991, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3512, training loss= 0.01903927, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3513, training loss= 0.01902735, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3514, training loss= 0.019015808, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3515, training loss= 0.019003743, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3516, training loss= 0.018991379, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3517, training loss= 0.01897995, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3518, training loss= 0.018968731, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3519, training loss= 0.018956386, training acc= 99.67783689498901%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3520, training loss= 0.018944263, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3521, training loss= 0.018932993, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3522, training loss= 0.018920941, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3523, training loss= 0.018910056, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3524, training loss= 0.018896896, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3525, training loss= 0.018885205, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3526, training loss= 0.018873744, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3527, training loss= 0.018861903, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3528, training loss= 0.018849274, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3529, training loss= 0.018837104, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3530, training loss= 0.018825544, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3531, training loss= 0.018814297, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3532, training loss= 0.018800795, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3533, training loss= 0.018791435, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3534, training loss= 0.018777085, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3535, training loss= 0.018766325, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3536, training loss= 0.0187549, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3537, training loss= 0.018741915, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3538, training loss= 0.018732566, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3539, training loss= 0.018717224, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3540, training loss= 0.018707097, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3541, training loss= 0.01869537, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3542, training loss= 0.018682819, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3543, training loss= 0.018671334, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3544, training loss= 0.018659452, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3545, training loss= 0.018647624, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3546, training loss= 0.018634688, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3547, training loss= 0.018624686, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3548, training loss= 0.0186111, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3549, training loss= 0.018601023, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3550, training loss= 0.018589279, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3551, training loss= 0.018575633, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3552, training loss= 0.018565455, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3553, training loss= 0.018552065, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3554, training loss= 0.018541336, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3555, training loss= 0.018528508, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3556, training loss= 0.01851828, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3557, training loss= 0.018504962, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3558, training loss= 0.018494302, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3559, training loss= 0.018481543, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3560, training loss= 0.018469807, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3561, training loss= 0.018458921, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3562, training loss= 0.018447135, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3563, training loss= 0.018435484, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3564, training loss= 0.018422935, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3565, training loss= 0.018412504, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3566, training loss= 0.018399213, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3567, training loss= 0.018388445, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3568, training loss= 0.018376656, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3569, training loss= 0.018364832, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3570, training loss= 0.018353265, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3571, training loss= 0.01834133, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3572, training loss= 0.018330045, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3573, training loss= 0.018318154, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3574, training loss= 0.01830673, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3575, training loss= 0.018295243, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3576, training loss= 0.018283, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3577, training loss= 0.0182724, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3578, training loss= 0.018261185, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3579, training loss= 0.018249534, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3580, training loss= 0.018236605, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3581, training loss= 0.018225513, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3582, training loss= 0.018215135, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3583, training loss= 0.018203652, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3584, training loss= 0.01819062, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3585, training loss= 0.018180821, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3586, training loss= 0.018168181, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3587, training loss= 0.0181566, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3588, training loss= 0.018144816, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3589, training loss= 0.018133745, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3590, training loss= 0.01812205, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3591, training loss= 0.01811036, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3592, training loss= 0.018098962, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3593, training loss= 0.01808696, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3594, training loss= 0.018075971, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3595, training loss= 0.01806459, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3596, training loss= 0.018053144, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3597, training loss= 0.01804122, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3598, training loss= 0.018029293, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3599, training loss= 0.01801815, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3600, training loss= 0.018006029, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3601, training loss= 0.017995264, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3602, training loss= 0.017984165, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3603, training loss= 0.017972048, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3604, training loss= 0.017960688, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3605, training loss= 0.017949553, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3606, training loss= 0.01793808, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3607, training loss= 0.017926533, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3608, training loss= 0.017915422, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3609, training loss= 0.017904297, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3610, training loss= 0.017892586, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3611, training loss= 0.0178813, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3612, training loss= 0.01787041, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3613, training loss= 0.017859532, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3614, training loss= 0.017847817, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3615, training loss= 0.017835733, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3616, training loss= 0.017826468, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3617, training loss= 0.017812436, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3618, training loss= 0.017802835, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3619, training loss= 0.017790865, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3620, training loss= 0.017779354, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3621, training loss= 0.017770078, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3622, training loss= 0.017755734, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3623, training loss= 0.017746724, training acc= 99.71005320549011%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3624, training loss= 0.01773563, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3625, training loss= 0.017721899, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3626, training loss= 0.017715517, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3627, training loss= 0.01770163, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3628, training loss= 0.017689934, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3629, training loss= 0.017681833, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3630, training loss= 0.017667, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3631, training loss= 0.017656721, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3632, training loss= 0.017645884, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3633, training loss= 0.017633833, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3634, training loss= 0.017622316, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3635, training loss= 0.01761122, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3636, training loss= 0.017598256, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3637, training loss= 0.017589081, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3638, training loss= 0.0175759, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3639, training loss= 0.017565208, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3640, training loss= 0.01755349, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3641, training loss= 0.017542263, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3642, training loss= 0.017530795, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3643, training loss= 0.017520113, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3644, training loss= 0.017508306, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3645, training loss= 0.017497454, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3646, training loss= 0.017486347, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3647, training loss= 0.017475136, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3648, training loss= 0.017463492, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3649, training loss= 0.017452253, training acc= 99.74226951599121%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3650, training loss= 0.017441226, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3651, training loss= 0.01743074, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3652, training loss= 0.01741828, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3653, training loss= 0.01740721, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3654, training loss= 0.017396472, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3655, training loss= 0.017384226, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3656, training loss= 0.017372895, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3657, training loss= 0.017361442, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3658, training loss= 0.017350717, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3659, training loss= 0.017339537, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3660, training loss= 0.01732792, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3661, training loss= 0.017316096, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3662, training loss= 0.017306307, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3663, training loss= 0.017293924, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3664, training loss= 0.017284403, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3665, training loss= 0.01727178, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3666, training loss= 0.017260842, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3667, training loss= 0.017249586, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3668, training loss= 0.017237699, training acc= 99.77448582649231%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3669, training loss= 0.017226905, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3670, training loss= 0.017216237, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3671, training loss= 0.017205091, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3672, training loss= 0.017192708, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3673, training loss= 0.017182462, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3674, training loss= 0.01717106, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3675, training loss= 0.017159568, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3676, training loss= 0.01714872, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3677, training loss= 0.017138321, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3678, training loss= 0.017126713, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3679, training loss= 0.017115317, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3680, training loss= 0.017103983, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3681, training loss= 0.017094564, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3682, training loss= 0.01708169, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3683, training loss= 0.01707164, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3684, training loss= 0.017059239, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3685, training loss= 0.017048908, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3686, training loss= 0.017037837, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3687, training loss= 0.017026478, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3688, training loss= 0.017015874, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3689, training loss= 0.017005254, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3690, training loss= 0.01699494, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3691, training loss= 0.01698412, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3692, training loss= 0.016972514, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3693, training loss= 0.01695933, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3694, training loss= 0.016949728, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3695, training loss= 0.016938135, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3696, training loss= 0.016926885, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3697, training loss= 0.01691598, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3698, training loss= 0.016905041, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3699, training loss= 0.016894791, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3700, training loss= 0.016882386, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3701, training loss= 0.016871633, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3702, training loss= 0.016860507, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3703, training loss= 0.016850265, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3704, training loss= 0.016838197, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3705, training loss= 0.016827267, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3706, training loss= 0.016816271, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3707, training loss= 0.016804682, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3708, training loss= 0.01679501, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3709, training loss= 0.016785761, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3710, training loss= 0.016773984, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3711, training loss= 0.016763115, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3712, training loss= 0.01675106, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3713, training loss= 0.016740637, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3714, training loss= 0.016729841, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3715, training loss= 0.016718838, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3716, training loss= 0.016709486, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3717, training loss= 0.016695151, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3718, training loss= 0.016688181, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3719, training loss= 0.016675616, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3720, training loss= 0.016664503, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3721, training loss= 0.016652007, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3722, training loss= 0.016642895, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3723, training loss= 0.016631963, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3724, training loss= 0.016621985, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3725, training loss= 0.016609482, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3726, training loss= 0.016600942, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3727, training loss= 0.01659139, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3728, training loss= 0.01657673, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3729, training loss= 0.01656884, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3730, training loss= 0.0165588, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3731, training loss= 0.016543746, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3732, training loss= 0.016533963, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3733, training loss= 0.016522788, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3734, training loss= 0.016511358, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3735, training loss= 0.01650107, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3736, training loss= 0.016488824, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3737, training loss= 0.016479144, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3738, training loss= 0.016468376, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3739, training loss= 0.016456658, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3740, training loss= 0.016446438, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3741, training loss= 0.016435213, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3742, training loss= 0.016424617, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3743, training loss= 0.016412763, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3744, training loss= 0.016402235, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3745, training loss= 0.016391328, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3746, training loss= 0.016380608, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3747, training loss= 0.016369455, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3748, training loss= 0.01635942, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3749, training loss= 0.016348189, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3750, training loss= 0.01633835, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3751, training loss= 0.016327936, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3752, training loss= 0.016316598, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3753, training loss= 0.016307004, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3754, training loss= 0.01629458, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3755, training loss= 0.016285276, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3756, training loss= 0.01627323, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3757, training loss= 0.016262662, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3758, training loss= 0.01625298, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3759, training loss= 0.016240627, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3760, training loss= 0.016230902, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3761, training loss= 0.01621951, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3762, training loss= 0.016208515, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3763, training loss= 0.016198153, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3764, training loss= 0.01618782, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3765, training loss= 0.016177272, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3766, training loss= 0.016167868, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3767, training loss= 0.016155321, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3768, training loss= 0.016146338, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3769, training loss= 0.016134119, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3770, training loss= 0.016124012, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3771, training loss= 0.016111916, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3772, training loss= 0.016101671, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3773, training loss= 0.016090937, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3774, training loss= 0.016080929, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3775, training loss= 0.016069323, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3776, training loss= 0.016059324, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3777, training loss= 0.016048148, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3778, training loss= 0.016038725, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3779, training loss= 0.016027402, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3780, training loss= 0.01601684, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3781, training loss= 0.01600627, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3782, training loss= 0.015994973, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3783, training loss= 0.01598509, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3784, training loss= 0.01597494, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3785, training loss= 0.015964337, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3786, training loss= 0.015953569, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3787, training loss= 0.015943194, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3788, training loss= 0.015932757, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3789, training loss= 0.015921993, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3790, training loss= 0.015911216, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3791, training loss= 0.015900588, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3792, training loss= 0.015889337, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3793, training loss= 0.015879499, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3794, training loss= 0.01586931, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3795, training loss= 0.015858304, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3796, training loss= 0.015847774, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3797, training loss= 0.015837584, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3798, training loss= 0.015827574, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3799, training loss= 0.015816761, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3800, training loss= 0.015806101, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3801, training loss= 0.015794791, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3802, training loss= 0.015785271, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3803, training loss= 0.015774054, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3804, training loss= 0.015763853, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3805, training loss= 0.015753835, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3806, training loss= 0.015742192, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3807, training loss= 0.015733067, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3808, training loss= 0.015722468, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3809, training loss= 0.015712613, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3810, training loss= 0.015700925, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3811, training loss= 0.015692307, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3812, training loss= 0.015679656, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3813, training loss= 0.015671128, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3814, training loss= 0.015660532, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3815, training loss= 0.0156507, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3816, training loss= 0.015639864, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3817, training loss= 0.015629422, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3818, training loss= 0.015620058, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3819, training loss= 0.015608811, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3820, training loss= 0.015599452, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3821, training loss= 0.015587579, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3822, training loss= 0.0155788595, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3823, training loss= 0.015569707, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3824, training loss= 0.015556438, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3825, training loss= 0.015548253, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3826, training loss= 0.0155371735, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3827, training loss= 0.015526472, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3828, training loss= 0.015517281, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3829, training loss= 0.015505543, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3830, training loss= 0.015494997, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3831, training loss= 0.015485592, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3832, training loss= 0.015473814, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3833, training loss= 0.015464454, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3834, training loss= 0.0154537195, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3835, training loss= 0.015445192, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3836, training loss= 0.015432171, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3837, training loss= 0.015423336, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3838, training loss= 0.01541247, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3839, training loss= 0.015401257, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3840, training loss= 0.015391456, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3841, training loss= 0.015380787, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3842, training loss= 0.015371101, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3843, training loss= 0.015359884, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3844, training loss= 0.015350821, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3845, training loss= 0.015339869, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3846, training loss= 0.015328852, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3847, training loss= 0.015318734, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3848, training loss= 0.015309139, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3849, training loss= 0.015298587, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3850, training loss= 0.015288079, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3851, training loss= 0.015277929, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3852, training loss= 0.015267365, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3853, training loss= 0.015256979, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3854, training loss= 0.015246233, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3855, training loss= 0.015236834, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3856, training loss= 0.015225626, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3857, training loss= 0.015216329, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3858, training loss= 0.015205442, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3859, training loss= 0.015195681, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3860, training loss= 0.015185806, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3861, training loss= 0.015175227, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3862, training loss= 0.015165213, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3863, training loss= 0.01515676, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3864, training loss= 0.015144806, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3865, training loss= 0.015135565, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3866, training loss= 0.015125246, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3867, training loss= 0.015114845, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3868, training loss= 0.01510488, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3869, training loss= 0.015094093, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3870, training loss= 0.015085709, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3871, training loss= 0.015074677, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3872, training loss= 0.015066745, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3873, training loss= 0.015055207, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3874, training loss= 0.015046512, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3875, training loss= 0.015036512, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3876, training loss= 0.015025723, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3877, training loss= 0.015016971, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3878, training loss= 0.01500548, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3879, training loss= 0.014996845, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3880, training loss= 0.014987348, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3881, training loss= 0.014975321, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3882, training loss= 0.014965071, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3883, training loss= 0.014955526, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3884, training loss= 0.014946031, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3885, training loss= 0.014935822, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3886, training loss= 0.014926499, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3887, training loss= 0.01491767, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3888, training loss= 0.014905464, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3889, training loss= 0.014898394, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3890, training loss= 0.014887018, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3891, training loss= 0.014876312, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3892, training loss= 0.014868852, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3893, training loss= 0.01485672, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3894, training loss= 0.014847083, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3895, training loss= 0.014837804, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3896, training loss= 0.014825946, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3897, training loss= 0.014818949, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3898, training loss= 0.014806546, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3899, training loss= 0.014797743, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3900, training loss= 0.014787293, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3901, training loss= 0.0147771975, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3902, training loss= 0.014766528, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3903, training loss= 0.014757444, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3904, training loss= 0.014747635, training acc= 99.80670213699341%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3905, training loss= 0.014736673, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3906, training loss= 0.014726596, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3907, training loss= 0.014716184, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3908, training loss= 0.014707522, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3909, training loss= 0.0146968, training acc= 99.8389184474945%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3910, training loss= 0.014685729, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3911, training loss= 0.014677592, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3912, training loss= 0.014666942, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3913, training loss= 0.014656237, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3914, training loss= 0.014647941, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3915, training loss= 0.014638156, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3916, training loss= 0.014626069, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3917, training loss= 0.0146183185, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3918, training loss= 0.01460801, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3919, training loss= 0.014597871, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3920, training loss= 0.014587035, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3921, training loss= 0.0145777, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3922, training loss= 0.014567191, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3923, training loss= 0.014558111, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3924, training loss= 0.014547835, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3925, training loss= 0.014538182, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3926, training loss= 0.014530318, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3927, training loss= 0.014519347, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3928, training loss= 0.0145105785, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3929, training loss= 0.014500929, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3930, training loss= 0.014492694, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3931, training loss= 0.014482842, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3932, training loss= 0.014471827, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3933, training loss= 0.014463596, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3934, training loss= 0.014452148, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3935, training loss= 0.0144428415, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3936, training loss= 0.014433364, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3937, training loss= 0.014422623, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3938, training loss= 0.014412161, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3939, training loss= 0.014402705, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3940, training loss= 0.014393824, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3941, training loss= 0.014384485, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3942, training loss= 0.01437381, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3943, training loss= 0.0143637145, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 3944, training loss= 0.014354755, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3945, training loss= 0.014345641, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3946, training loss= 0.014334968, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3947, training loss= 0.014325016, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3948, training loss= 0.0143158315, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3949, training loss= 0.014305374, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3950, training loss= 0.014295928, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3951, training loss= 0.014285789, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3952, training loss= 0.0142765, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3953, training loss= 0.014266368, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3954, training loss= 0.014257012, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3955, training loss= 0.014247204, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3956, training loss= 0.014237642, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3957, training loss= 0.014227973, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3958, training loss= 0.01421778, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3959, training loss= 0.014208638, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3960, training loss= 0.014198519, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3961, training loss= 0.014188638, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3962, training loss= 0.014179111, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3963, training loss= 0.0141696315, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3964, training loss= 0.014159655, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3965, training loss= 0.014150386, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3966, training loss= 0.014140867, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3967, training loss= 0.014130823, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3968, training loss= 0.014121328, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3969, training loss= 0.01411265, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3970, training loss= 0.014100933, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3971, training loss= 0.014092749, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3972, training loss= 0.014082831, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3973, training loss= 0.014072897, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3974, training loss= 0.014063019, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3975, training loss= 0.014053355, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3976, training loss= 0.0140437875, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3977, training loss= 0.014034141, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3978, training loss= 0.014024017, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3979, training loss= 0.014014626, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3980, training loss= 0.014005117, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3981, training loss= 0.013994951, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3982, training loss= 0.013985853, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3983, training loss= 0.013975946, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3984, training loss= 0.013966137, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3985, training loss= 0.013956603, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3986, training loss= 0.013947743, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3987, training loss= 0.013938283, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3988, training loss= 0.01392797, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3989, training loss= 0.01391988, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3990, training loss= 0.013910159, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3991, training loss= 0.013900372, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3992, training loss= 0.0138901025, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 3993, training loss= 0.013880635, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 3994, training loss= 0.013871492, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 3995, training loss= 0.013861763, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 3996, training loss= 0.013852108, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 3997, training loss= 0.013842772, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 3998, training loss= 0.01383275, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 3999, training loss= 0.013825018, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4000, training loss= 0.013816178, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4001, training loss= 0.013804827, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4002, training loss= 0.013797166, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4003, training loss= 0.013786679, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4004, training loss= 0.01377799, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4005, training loss= 0.013769494, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4006, training loss= 0.0137592815, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4007, training loss= 0.013748668, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4008, training loss= 0.01374121, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4009, training loss= 0.013731915, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4010, training loss= 0.013719607, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4011, training loss= 0.013711192, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4012, training loss= 0.0137028815, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4013, training loss= 0.013692436, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4014, training loss= 0.013682254, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4015, training loss= 0.013673692, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4016, training loss= 0.013663967, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4017, training loss= 0.013655532, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4018, training loss= 0.0136457225, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4019, training loss= 0.01363544, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4020, training loss= 0.013626547, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4021, training loss= 0.013616127, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4022, training loss= 0.0136081055, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4023, training loss= 0.013597817, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4024, training loss= 0.013588842, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4025, training loss= 0.013579767, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4026, training loss= 0.013569173, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4027, training loss= 0.013560969, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4028, training loss= 0.013550997, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4029, training loss= 0.013542587, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4030, training loss= 0.013532742, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4031, training loss= 0.013523747, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4032, training loss= 0.013514371, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4033, training loss= 0.013505922, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4034, training loss= 0.013496912, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4035, training loss= 0.013485986, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4036, training loss= 0.013477614, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4037, training loss= 0.0134673435, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4038, training loss= 0.013458583, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4039, training loss= 0.013448938, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4040, training loss= 0.013440121, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4041, training loss= 0.013431062, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4042, training loss= 0.013421334, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4043, training loss= 0.013411367, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4044, training loss= 0.013402714, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4045, training loss= 0.01339326, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4046, training loss= 0.013383515, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4047, training loss= 0.013374583, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4048, training loss= 0.013366537, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4049, training loss= 0.01335592, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4050, training loss= 0.013347292, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4051, training loss= 0.013337724, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4052, training loss= 0.013327638, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4053, training loss= 0.013319196, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4054, training loss= 0.013311256, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4055, training loss= 0.013299624, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4056, training loss= 0.013290774, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4057, training loss= 0.013282217, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4058, training loss= 0.013272235, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4059, training loss= 0.01326316, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4060, training loss= 0.013254326, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4061, training loss= 0.013244788, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4062, training loss= 0.013236408, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4063, training loss= 0.013226195, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4064, training loss= 0.013219299, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4065, training loss= 0.013209263, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4066, training loss= 0.013199694, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4067, training loss= 0.01319029, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4068, training loss= 0.013180997, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4069, training loss= 0.013171718, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4070, training loss= 0.013161556, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4071, training loss= 0.013153612, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4072, training loss= 0.013146665, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4073, training loss= 0.0131366495, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4074, training loss= 0.013128079, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4075, training loss= 0.013117093, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4076, training loss= 0.013112267, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4077, training loss= 0.013104627, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4078, training loss= 0.013091842, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4079, training loss= 0.013085566, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4080, training loss= 0.013077611, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4081, training loss= 0.01306304, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4082, training loss= 0.013059806, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4083, training loss= 0.013053695, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4084, training loss= 0.013044068, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4085, training loss= 0.013028521, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4086, training loss= 0.013023605, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4087, training loss= 0.013018253, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4088, training loss= 0.01300568, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4089, training loss= 0.012992905, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4090, training loss= 0.01298813, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4091, training loss= 0.012978978, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4092, training loss= 0.012967452, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4093, training loss= 0.01295723, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4094, training loss= 0.01295341, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4095, training loss= 0.012941953, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4096, training loss= 0.012929552, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4097, training loss= 0.012923018, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4098, training loss= 0.012915122, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4099, training loss= 0.012903255, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4100, training loss= 0.012893139, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4101, training loss= 0.012887645, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4102, training loss= 0.012876925, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4103, training loss= 0.012866739, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4104, training loss= 0.012859736, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4105, training loss= 0.012850543, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4106, training loss= 0.012840986, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4107, training loss= 0.0128319245, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4108, training loss= 0.012823576, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4109, training loss= 0.012814676, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4110, training loss= 0.012805958, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4111, training loss= 0.012799077, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4112, training loss= 0.012788399, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4113, training loss= 0.012778744, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4114, training loss= 0.0127718225, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4115, training loss= 0.012762712, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4116, training loss= 0.012752499, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4117, training loss= 0.012743124, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4118, training loss= 0.012734719, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4119, training loss= 0.012725385, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4120, training loss= 0.0127158575, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4121, training loss= 0.012707352, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4122, training loss= 0.012699855, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4123, training loss= 0.012690435, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4124, training loss= 0.012681273, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4125, training loss= 0.012671687, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4126, training loss= 0.012663214, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4127, training loss= 0.012653773, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4128, training loss= 0.012645085, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4129, training loss= 0.012635918, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4130, training loss= 0.012627817, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4131, training loss= 0.012619506, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4132, training loss= 0.012609928, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4133, training loss= 0.0126012545, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4134, training loss= 0.012592831, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4135, training loss= 0.012583587, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4136, training loss= 0.012575062, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4137, training loss= 0.012566798, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4138, training loss= 0.012556786, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4139, training loss= 0.012549233, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4140, training loss= 0.012540475, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4141, training loss= 0.012530596, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4142, training loss= 0.012522677, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4143, training loss= 0.01251421, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4144, training loss= 0.012504962, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4145, training loss= 0.012495765, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4146, training loss= 0.012487494, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4147, training loss= 0.012479027, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4148, training loss= 0.012469894, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4149, training loss= 0.012461333, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4150, training loss= 0.012453423, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4151, training loss= 0.01244365, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4152, training loss= 0.01243513, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4153, training loss= 0.012427261, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4154, training loss= 0.012418319, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4155, training loss= 0.01241027, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4156, training loss= 0.012400717, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4157, training loss= 0.012392641, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4158, training loss= 0.012382676, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4159, training loss= 0.01237543, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4160, training loss= 0.012366648, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4161, training loss= 0.012356365, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4162, training loss= 0.01234927, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4163, training loss= 0.012340169, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4164, training loss= 0.012331891, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4165, training loss= 0.012323431, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4166, training loss= 0.012313432, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4167, training loss= 0.012306864, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4168, training loss= 0.012296718, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4169, training loss= 0.012289546, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4170, training loss= 0.0122802025, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4171, training loss= 0.012272517, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4172, training loss= 0.012263901, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4173, training loss= 0.012257385, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4174, training loss= 0.012246566, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4175, training loss= 0.012239417, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4176, training loss= 0.012230331, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4177, training loss= 0.012220356, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4178, training loss= 0.012213007, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4179, training loss= 0.012203241, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4180, training loss= 0.012195004, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4181, training loss= 0.012185245, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4182, training loss= 0.01217731, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4183, training loss= 0.012169206, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4184, training loss= 0.012160866, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4185, training loss= 0.012151437, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4186, training loss= 0.012142931, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4187, training loss= 0.012134451, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4188, training loss= 0.012127332, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4189, training loss= 0.012117317, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4190, training loss= 0.012107975, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4191, training loss= 0.012099872, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4192, training loss= 0.01209182, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4193, training loss= 0.012083095, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4194, training loss= 0.012074423, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4195, training loss= 0.012066422, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4196, training loss= 0.012058523, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4197, training loss= 0.012049113, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4198, training loss= 0.012041348, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4199, training loss= 0.012032008, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4200, training loss= 0.012024055, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4201, training loss= 0.012014646, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4202, training loss= 0.0120063005, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4203, training loss= 0.011997664, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4204, training loss= 0.011989621, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4205, training loss= 0.011981377, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4206, training loss= 0.011972747, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4207, training loss= 0.011964126, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4208, training loss= 0.011954961, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4209, training loss= 0.011946833, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4210, training loss= 0.011938917, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4211, training loss= 0.011929608, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4212, training loss= 0.0119220875, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4213, training loss= 0.011912879, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4214, training loss= 0.011905889, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4215, training loss= 0.011896951, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4216, training loss= 0.011889033, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4217, training loss= 0.01188025, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4218, training loss= 0.011871548, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4219, training loss= 0.011863412, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4220, training loss= 0.011855342, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4221, training loss= 0.011846304, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4222, training loss= 0.011838874, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4223, training loss= 0.011830749, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4224, training loss= 0.0118207345, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4225, training loss= 0.011813532, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4226, training loss= 0.011805781, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4227, training loss= 0.011796142, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4228, training loss= 0.011787931, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4229, training loss= 0.011780112, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4230, training loss= 0.011770843, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4231, training loss= 0.011762795, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4232, training loss= 0.011754066, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4233, training loss= 0.011747238, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4234, training loss= 0.011737236, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4235, training loss= 0.011730429, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4236, training loss= 0.011721686, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4237, training loss= 0.011715027, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4238, training loss= 0.0117053585, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4239, training loss= 0.011697636, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 4240, training loss= 0.011689079, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.20436096191406 ...\n",
            "\n",
            "step 4241, training loss= 0.01168117, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4242, training loss= 0.011671009, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4243, training loss= 0.011663845, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4244, training loss= 0.011656823, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4245, training loss= 0.011647956, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4246, training loss= 0.011640914, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4247, training loss= 0.011633821, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4248, training loss= 0.011623145, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4249, training loss= 0.01161572, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4250, training loss= 0.011606197, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4251, training loss= 0.011598892, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4252, training loss= 0.011591813, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4253, training loss= 0.011581207, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4254, training loss= 0.011573823, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4255, training loss= 0.0115644755, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4256, training loss= 0.011558221, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4257, training loss= 0.011549688, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4258, training loss= 0.011540395, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4259, training loss= 0.011533539, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4260, training loss= 0.0115247825, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4261, training loss= 0.011515561, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4262, training loss= 0.0115092555, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4263, training loss= 0.011501007, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4264, training loss= 0.011491617, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4265, training loss= 0.011483173, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4266, training loss= 0.011475536, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4267, training loss= 0.011467458, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4268, training loss= 0.011459514, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4269, training loss= 0.011452161, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4270, training loss= 0.011442966, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4271, training loss= 0.011434146, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4272, training loss= 0.011425623, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4273, training loss= 0.011419119, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4274, training loss= 0.011411088, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4275, training loss= 0.011401356, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4276, training loss= 0.011393809, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4277, training loss= 0.011385154, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4278, training loss= 0.011377492, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4279, training loss= 0.011369277, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4280, training loss= 0.011360997, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4281, training loss= 0.011352903, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4282, training loss= 0.011344294, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4283, training loss= 0.011336798, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4284, training loss= 0.011328869, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4285, training loss= 0.011320784, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4286, training loss= 0.011312291, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4287, training loss= 0.011305299, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4288, training loss= 0.011296459, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4289, training loss= 0.0112898415, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4290, training loss= 0.011280375, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4291, training loss= 0.011273058, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4292, training loss= 0.011263888, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4293, training loss= 0.011255893, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4294, training loss= 0.011248464, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4295, training loss= 0.011239165, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4296, training loss= 0.011231304, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4297, training loss= 0.011224509, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4298, training loss= 0.011215632, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4299, training loss= 0.0112074, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4300, training loss= 0.011200161, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4301, training loss= 0.011191913, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4302, training loss= 0.011184332, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4303, training loss= 0.01117632, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4304, training loss= 0.011167805, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4305, training loss= 0.01116096, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4306, training loss= 0.011152164, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4307, training loss= 0.01114411, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4308, training loss= 0.011138076, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4309, training loss= 0.011129247, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4310, training loss= 0.011120567, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4311, training loss= 0.011112677, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4312, training loss= 0.011104746, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4313, training loss= 0.0110964, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4314, training loss= 0.011088099, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4315, training loss= 0.011080242, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4316, training loss= 0.011073184, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4317, training loss= 0.0110657, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4318, training loss= 0.011056645, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4319, training loss= 0.01104936, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4320, training loss= 0.011040796, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4321, training loss= 0.011032759, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4322, training loss= 0.01102565, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4323, training loss= 0.0110185435, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4324, training loss= 0.0110097835, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4325, training loss= 0.01100149, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4326, training loss= 0.010995056, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4327, training loss= 0.010985525, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4328, training loss= 0.010979279, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4329, training loss= 0.010970944, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4330, training loss= 0.010962398, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4331, training loss= 0.010955694, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4332, training loss= 0.010946943, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4333, training loss= 0.010939284, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4334, training loss= 0.010931765, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4335, training loss= 0.010922595, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4336, training loss= 0.010915376, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4337, training loss= 0.01090651, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4338, training loss= 0.010900083, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4339, training loss= 0.010892132, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4340, training loss= 0.010882698, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4341, training loss= 0.010878449, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4342, training loss= 0.010868191, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4343, training loss= 0.010861113, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4344, training loss= 0.0108530875, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4345, training loss= 0.010845864, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4346, training loss= 0.010837049, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4347, training loss= 0.010829433, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4348, training loss= 0.010822073, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4349, training loss= 0.010813279, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4350, training loss= 0.010805543, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4351, training loss= 0.01079792, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4352, training loss= 0.010789837, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4353, training loss= 0.010782698, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4354, training loss= 0.010774126, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4355, training loss= 0.010767284, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4356, training loss= 0.010759549, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4357, training loss= 0.010751658, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4358, training loss= 0.0107445335, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4359, training loss= 0.010736176, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4360, training loss= 0.01072793, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4361, training loss= 0.010721552, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4362, training loss= 0.010713561, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4363, training loss= 0.01070603, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4364, training loss= 0.010697609, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4365, training loss= 0.0106915, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4366, training loss= 0.010684943, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4367, training loss= 0.010676358, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4368, training loss= 0.010668378, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4369, training loss= 0.010661263, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4370, training loss= 0.010651856, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4371, training loss= 0.010645518, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4372, training loss= 0.010637288, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4373, training loss= 0.010629384, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4374, training loss= 0.01062265, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4375, training loss= 0.010615113, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4376, training loss= 0.010608393, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4377, training loss= 0.010600416, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4378, training loss= 0.0105914045, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4379, training loss= 0.0105849225, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4380, training loss= 0.010577612, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4381, training loss= 0.010567919, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4382, training loss= 0.010561629, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4383, training loss= 0.010553904, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4384, training loss= 0.010544843, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4385, training loss= 0.010538506, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4386, training loss= 0.010531025, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4387, training loss= 0.010522197, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4388, training loss= 0.010515492, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4389, training loss= 0.010506778, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4390, training loss= 0.010500956, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4391, training loss= 0.010492188, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4392, training loss= 0.010485315, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4393, training loss= 0.010478483, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4394, training loss= 0.010470558, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4395, training loss= 0.0104623595, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4396, training loss= 0.010455642, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4397, training loss= 0.01044801, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4398, training loss= 0.010441234, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4399, training loss= 0.010433158, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4400, training loss= 0.010424827, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4401, training loss= 0.010417896, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4402, training loss= 0.01040936, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4403, training loss= 0.010402767, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4404, training loss= 0.010394157, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4405, training loss= 0.010388085, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4406, training loss= 0.0103795165, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4407, training loss= 0.010372075, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4408, training loss= 0.010365639, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4409, training loss= 0.010357704, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4410, training loss= 0.010350245, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4411, training loss= 0.010342474, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4412, training loss= 0.010335355, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4413, training loss= 0.010327758, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4414, training loss= 0.010320162, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4415, training loss= 0.010312365, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4416, training loss= 0.010306042, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4417, training loss= 0.010298312, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4418, training loss= 0.010290594, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4419, training loss= 0.010284981, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4420, training loss= 0.010277485, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4421, training loss= 0.010269388, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4422, training loss= 0.010261999, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4423, training loss= 0.010254771, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4424, training loss= 0.010246845, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4425, training loss= 0.01024012, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4426, training loss= 0.010233036, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4427, training loss= 0.010224783, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4428, training loss= 0.010218699, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.27949523925781 ...\n",
            "\n",
            "step 4429, training loss= 0.010212464, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4430, training loss= 0.010203783, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4431, training loss= 0.010197318, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4432, training loss= 0.010189915, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4433, training loss= 0.0101824, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4434, training loss= 0.010174501, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4435, training loss= 0.010167228, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4436, training loss= 0.010159506, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4437, training loss= 0.010152996, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4438, training loss= 0.0101461215, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4439, training loss= 0.01013736, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4440, training loss= 0.010130215, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4441, training loss= 0.010123358, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4442, training loss= 0.010115497, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4443, training loss= 0.010108349, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4444, training loss= 0.010100674, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4445, training loss= 0.010094045, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4446, training loss= 0.010087108, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4447, training loss= 0.0100805415, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4448, training loss= 0.010072499, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4449, training loss= 0.010066661, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4450, training loss= 0.010059038, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4451, training loss= 0.010050794, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4452, training loss= 0.010044287, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4453, training loss= 0.010036502, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4454, training loss= 0.010029354, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4455, training loss= 0.010021629, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4456, training loss= 0.010014909, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4457, training loss= 0.010007867, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4458, training loss= 0.010001011, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4459, training loss= 0.009993223, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4460, training loss= 0.009987554, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4461, training loss= 0.009980075, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4462, training loss= 0.009972962, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4463, training loss= 0.00996646, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4464, training loss= 0.009959041, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4465, training loss= 0.009950612, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4466, training loss= 0.009945472, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4467, training loss= 0.009937471, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4468, training loss= 0.009929602, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4469, training loss= 0.009923529, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4470, training loss= 0.009916377, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4471, training loss= 0.009909542, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4472, training loss= 0.009901498, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4473, training loss= 0.009895046, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4474, training loss= 0.009887309, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4475, training loss= 0.009881614, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4476, training loss= 0.009872816, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4477, training loss= 0.009865756, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4478, training loss= 0.009859179, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4479, training loss= 0.009852771, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4480, training loss= 0.0098448, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4481, training loss= 0.009837215, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4482, training loss= 0.009831226, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4483, training loss= 0.009823981, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4484, training loss= 0.009816546, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4485, training loss= 0.009809684, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4486, training loss= 0.009802959, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4487, training loss= 0.009795593, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4488, training loss= 0.009789277, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4489, training loss= 0.009782309, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4490, training loss= 0.00977544, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4491, training loss= 0.009767992, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4492, training loss= 0.009761482, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4493, training loss= 0.00975334, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4494, training loss= 0.009747425, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4495, training loss= 0.009739877, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4496, training loss= 0.00973382, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4497, training loss= 0.009727808, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4498, training loss= 0.0097194435, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4499, training loss= 0.009712024, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4500, training loss= 0.009705082, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4501, training loss= 0.009697458, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4502, training loss= 0.009691746, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4503, training loss= 0.009686153, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4504, training loss= 0.009677129, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4505, training loss= 0.009672596, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4506, training loss= 0.009665023, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4507, training loss= 0.009656363, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4508, training loss= 0.009651136, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4509, training loss= 0.009642653, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4510, training loss= 0.009636222, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4511, training loss= 0.009628683, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4512, training loss= 0.00962184, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4513, training loss= 0.009615863, training acc= 99.8711347579956%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4514, training loss= 0.009609122, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4515, training loss= 0.00960257, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4516, training loss= 0.009593787, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4517, training loss= 0.009587755, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4518, training loss= 0.009581515, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4519, training loss= 0.009573617, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4520, training loss= 0.00956778, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4521, training loss= 0.009560655, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4522, training loss= 0.009552331, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4523, training loss= 0.009547482, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4524, training loss= 0.009539977, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4525, training loss= 0.009534149, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4526, training loss= 0.009528026, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4527, training loss= 0.0095202485, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4528, training loss= 0.00951317, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4529, training loss= 0.00950832, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4530, training loss= 0.009500293, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4531, training loss= 0.009492383, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4532, training loss= 0.009487038, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4533, training loss= 0.009479405, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4534, training loss= 0.009472548, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4535, training loss= 0.009466058, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4536, training loss= 0.009458932, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4537, training loss= 0.009451662, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4538, training loss= 0.00944501, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4539, training loss= 0.009438184, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4540, training loss= 0.009431251, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4541, training loss= 0.009424967, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4542, training loss= 0.009417669, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4543, training loss= 0.009411665, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4544, training loss= 0.0094047515, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4545, training loss= 0.009397949, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4546, training loss= 0.009392092, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4547, training loss= 0.009384465, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4548, training loss= 0.009376698, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4549, training loss= 0.00937237, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4550, training loss= 0.009364626, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4551, training loss= 0.009357827, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4552, training loss= 0.009351082, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4553, training loss= 0.009344153, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4554, training loss= 0.009337661, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4555, training loss= 0.009331575, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4556, training loss= 0.00932417, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4557, training loss= 0.009317528, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4558, training loss= 0.009311615, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4559, training loss= 0.009303609, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4560, training loss= 0.009297933, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4561, training loss= 0.009290998, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4562, training loss= 0.009283538, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4563, training loss= 0.00927851, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4564, training loss= 0.0092715, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4565, training loss= 0.009263499, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4566, training loss= 0.0092584025, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4567, training loss= 0.009251353, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4568, training loss= 0.009243738, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4569, training loss= 0.009238872, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4570, training loss= 0.0092324475, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4571, training loss= 0.009224007, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4572, training loss= 0.009217931, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4573, training loss= 0.009211122, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4574, training loss= 0.009204538, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4575, training loss= 0.009196886, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4576, training loss= 0.0091906665, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4577, training loss= 0.009184622, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4578, training loss= 0.009177273, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4579, training loss= 0.009171017, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4580, training loss= 0.009165109, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4581, training loss= 0.00915882, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4582, training loss= 0.009151154, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4583, training loss= 0.009144561, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.35462188720703 ...\n",
            "\n",
            "step 4584, training loss= 0.009138245, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4585, training loss= 0.009131094, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4586, training loss= 0.009124261, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4587, training loss= 0.00911787, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4588, training loss= 0.00911214, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4589, training loss= 0.009105102, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4590, training loss= 0.00909876, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4591, training loss= 0.009092976, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4592, training loss= 0.009085826, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4593, training loss= 0.009079294, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4594, training loss= 0.009075029, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4595, training loss= 0.0090681985, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4596, training loss= 0.009059835, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4597, training loss= 0.009055745, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4598, training loss= 0.009046807, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4599, training loss= 0.009041572, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4600, training loss= 0.009034612, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4601, training loss= 0.00902838, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4602, training loss= 0.00902215, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4603, training loss= 0.0090145115, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4604, training loss= 0.009010701, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4605, training loss= 0.00900358, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4606, training loss= 0.008995175, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4607, training loss= 0.008990408, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4608, training loss= 0.0089816665, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4609, training loss= 0.008976965, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4610, training loss= 0.008968776, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4611, training loss= 0.008964426, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4612, training loss= 0.00895574, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4613, training loss= 0.008950494, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4614, training loss= 0.008945219, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4615, training loss= 0.00893652, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4616, training loss= 0.008931037, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4617, training loss= 0.008924762, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4618, training loss= 0.008918116, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4619, training loss= 0.008912697, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4620, training loss= 0.0089061465, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4621, training loss= 0.00889824, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4622, training loss= 0.008892746, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4623, training loss= 0.008887069, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4624, training loss= 0.008879387, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4625, training loss= 0.008873035, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4626, training loss= 0.008866908, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4627, training loss= 0.008860032, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4628, training loss= 0.008852677, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4629, training loss= 0.00884798, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4630, training loss= 0.0088404175, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4631, training loss= 0.008834138, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4632, training loss= 0.0088283345, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4633, training loss= 0.0088208215, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4634, training loss= 0.008815756, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4635, training loss= 0.008808745, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4636, training loss= 0.00880214, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4637, training loss= 0.008795229, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4638, training loss= 0.00878945, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4639, training loss= 0.008782932, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4640, training loss= 0.008777042, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4641, training loss= 0.008770358, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4642, training loss= 0.008765047, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4643, training loss= 0.008759103, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4644, training loss= 0.008752279, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4645, training loss= 0.008745291, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4646, training loss= 0.00873981, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4647, training loss= 0.008735006, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4648, training loss= 0.008726196, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4649, training loss= 0.008720552, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4650, training loss= 0.008714822, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4651, training loss= 0.008707633, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4652, training loss= 0.008701589, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4653, training loss= 0.008695745, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4654, training loss= 0.008688531, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4655, training loss= 0.008682509, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4656, training loss= 0.008676585, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4657, training loss= 0.008669702, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4658, training loss= 0.008663225, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4659, training loss= 0.008657421, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4660, training loss= 0.00865122, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4661, training loss= 0.008645248, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4662, training loss= 0.008637768, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4663, training loss= 0.008633734, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4664, training loss= 0.0086268755, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4665, training loss= 0.00861972, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4666, training loss= 0.008614487, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4667, training loss= 0.008608072, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4668, training loss= 0.008601019, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4669, training loss= 0.0085967025, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4670, training loss= 0.00858849, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4671, training loss= 0.008584564, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4672, training loss= 0.008578048, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4673, training loss= 0.008570963, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4674, training loss= 0.008565621, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4675, training loss= 0.008558264, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4676, training loss= 0.0085532935, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4677, training loss= 0.008547446, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4678, training loss= 0.008539396, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4679, training loss= 0.008534122, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4680, training loss= 0.008527564, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4681, training loss= 0.008523098, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4682, training loss= 0.008516605, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4683, training loss= 0.008509829, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4684, training loss= 0.008504484, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4685, training loss= 0.008499022, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4686, training loss= 0.008492132, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4687, training loss= 0.008486844, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4688, training loss= 0.00847961, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4689, training loss= 0.008474762, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4690, training loss= 0.008469765, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4691, training loss= 0.008462307, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4692, training loss= 0.008455645, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4693, training loss= 0.008449133, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4694, training loss= 0.008443704, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4695, training loss= 0.008437765, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4696, training loss= 0.008430141, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4697, training loss= 0.008425646, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4698, training loss= 0.008419196, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4699, training loss= 0.008413527, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4700, training loss= 0.008406342, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4701, training loss= 0.008403204, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4702, training loss= 0.008395632, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4703, training loss= 0.008388647, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4704, training loss= 0.008383705, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4705, training loss= 0.008378794, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4706, training loss= 0.008373873, training acc= 99.9033510684967%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4707, training loss= 0.008365981, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4708, training loss= 0.008358175, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4709, training loss= 0.008353407, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4710, training loss= 0.008348141, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4711, training loss= 0.008340281, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4712, training loss= 0.008334804, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4713, training loss= 0.008330271, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4714, training loss= 0.008323122, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4715, training loss= 0.00831726, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4716, training loss= 0.008310536, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4717, training loss= 0.008304226, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4718, training loss= 0.008298103, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4719, training loss= 0.008292118, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4720, training loss= 0.008285805, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4721, training loss= 0.008279744, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4722, training loss= 0.00827379, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4723, training loss= 0.008267071, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4724, training loss= 0.00826195, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4725, training loss= 0.008255833, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4726, training loss= 0.008249932, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4727, training loss= 0.008243553, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4728, training loss= 0.0082368385, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4729, training loss= 0.008231638, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4730, training loss= 0.008225436, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4731, training loss= 0.008218995, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4732, training loss= 0.008213225, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4733, training loss= 0.00820739, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4734, training loss= 0.008201918, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4735, training loss= 0.008195012, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4736, training loss= 0.008189971, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4737, training loss= 0.008183232, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4738, training loss= 0.008178588, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4739, training loss= 0.008172649, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4740, training loss= 0.008167, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4741, training loss= 0.0081608575, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4742, training loss= 0.008155768, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4743, training loss= 0.008149045, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4744, training loss= 0.0081432015, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4745, training loss= 0.0081372205, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4746, training loss= 0.008131294, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4747, training loss= 0.008124087, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4748, training loss= 0.008120835, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4749, training loss= 0.008114355, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4750, training loss= 0.008106565, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4751, training loss= 0.008101092, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4752, training loss= 0.008094539, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4753, training loss= 0.008089521, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4754, training loss= 0.0080826795, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4755, training loss= 0.008079035, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4756, training loss= 0.008072673, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4757, training loss= 0.008066526, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4758, training loss= 0.0080605345, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4759, training loss= 0.008055057, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4760, training loss= 0.008049195, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4761, training loss= 0.0080423495, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4762, training loss= 0.008037205, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4763, training loss= 0.008033232, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4764, training loss= 0.008025794, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4765, training loss= 0.008019829, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4766, training loss= 0.008016386, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4767, training loss= 0.008008423, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4768, training loss= 0.008003432, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4769, training loss= 0.007998592, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4770, training loss= 0.007993103, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4771, training loss= 0.007986826, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4772, training loss= 0.007980779, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4773, training loss= 0.007973392, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4774, training loss= 0.007968314, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4775, training loss= 0.007962898, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4776, training loss= 0.007955936, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4777, training loss= 0.007951482, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4778, training loss= 0.00794613, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4779, training loss= 0.007938374, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4780, training loss= 0.007934002, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4781, training loss= 0.007928061, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4782, training loss= 0.007920575, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4783, training loss= 0.007916115, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4784, training loss= 0.007909978, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4785, training loss= 0.007904052, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4786, training loss= 0.007898851, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4787, training loss= 0.007893307, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4788, training loss= 0.00788755, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4789, training loss= 0.007882148, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4790, training loss= 0.00787536, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4791, training loss= 0.007869348, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.42975616455078 ...\n",
            "\n",
            "step 4792, training loss= 0.007863866, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4793, training loss= 0.007857265, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4794, training loss= 0.007852253, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4795, training loss= 0.007846223, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4796, training loss= 0.007840519, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4797, training loss= 0.007835916, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4798, training loss= 0.007829403, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4799, training loss= 0.007823039, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4800, training loss= 0.007818134, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4801, training loss= 0.0078124655, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4802, training loss= 0.0078073074, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4803, training loss= 0.0078013367, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4804, training loss= 0.007795521, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4805, training loss= 0.007790384, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4806, training loss= 0.0077849007, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4807, training loss= 0.0077795247, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4808, training loss= 0.007774174, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4809, training loss= 0.007767137, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4810, training loss= 0.0077628824, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4811, training loss= 0.007755657, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4812, training loss= 0.0077517126, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4813, training loss= 0.007746884, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4814, training loss= 0.007740671, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4815, training loss= 0.007734975, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4816, training loss= 0.007728172, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4817, training loss= 0.0077229715, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4818, training loss= 0.0077172494, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4819, training loss= 0.007711505, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4820, training loss= 0.0077063977, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4821, training loss= 0.007700397, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4822, training loss= 0.007695207, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4823, training loss= 0.0076906164, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4824, training loss= 0.007683348, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4825, training loss= 0.0076788706, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4826, training loss= 0.007673656, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4827, training loss= 0.007667182, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4828, training loss= 0.0076628854, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4829, training loss= 0.00765625, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4830, training loss= 0.007650076, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4831, training loss= 0.007645598, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4832, training loss= 0.0076403813, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4833, training loss= 0.0076332497, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4834, training loss= 0.007628192, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4835, training loss= 0.0076230466, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4836, training loss= 0.007616953, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4837, training loss= 0.007612567, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4838, training loss= 0.0076070223, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4839, training loss= 0.0076008514, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4840, training loss= 0.007596488, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4841, training loss= 0.007590166, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4842, training loss= 0.007584956, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4843, training loss= 0.0075787273, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4844, training loss= 0.0075747753, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4845, training loss= 0.0075684893, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4846, training loss= 0.0075624227, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4847, training loss= 0.0075581293, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4848, training loss= 0.0075528426, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4849, training loss= 0.00754531, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4850, training loss= 0.0075412015, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4851, training loss= 0.007534001, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4852, training loss= 0.0075294315, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4853, training loss= 0.007523899, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4854, training loss= 0.0075182132, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4855, training loss= 0.007514234, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4856, training loss= 0.007507702, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4857, training loss= 0.0075018606, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4858, training loss= 0.0074974424, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4859, training loss= 0.0074917427, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4860, training loss= 0.007486532, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4861, training loss= 0.007480644, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4862, training loss= 0.0074762665, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4863, training loss= 0.0074708657, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4864, training loss= 0.0074648447, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4865, training loss= 0.0074615525, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4866, training loss= 0.007453967, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4867, training loss= 0.0074498146, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4868, training loss= 0.0074442606, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4869, training loss= 0.007438001, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4870, training loss= 0.007433719, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4871, training loss= 0.00742717, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4872, training loss= 0.007422397, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4873, training loss= 0.007417859, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4874, training loss= 0.007410952, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4875, training loss= 0.007405842, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4876, training loss= 0.0074009732, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4877, training loss= 0.007394749, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4878, training loss= 0.007389861, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4879, training loss= 0.0073841806, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4880, training loss= 0.007378614, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4881, training loss= 0.0073738927, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4882, training loss= 0.0073679658, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4883, training loss= 0.00736275, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4884, training loss= 0.0073574944, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4885, training loss= 0.0073518627, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4886, training loss= 0.0073466785, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4887, training loss= 0.007341287, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4888, training loss= 0.0073361616, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4889, training loss= 0.007330307, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4890, training loss= 0.0073251408, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4891, training loss= 0.0073201354, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4892, training loss= 0.0073146094, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4893, training loss= 0.007309781, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4894, training loss= 0.0073039443, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4895, training loss= 0.007298827, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4896, training loss= 0.007294215, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4897, training loss= 0.007288471, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4898, training loss= 0.007284204, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4899, training loss= 0.00727934, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4900, training loss= 0.0072742533, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4901, training loss= 0.007268045, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4902, training loss= 0.007262775, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4903, training loss= 0.0072592567, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4904, training loss= 0.007251103, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4905, training loss= 0.007248148, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4906, training loss= 0.007243261, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4907, training loss= 0.007236266, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4908, training loss= 0.0072310027, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4909, training loss= 0.007226578, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4910, training loss= 0.007220644, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4911, training loss= 0.0072151413, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4912, training loss= 0.0072103576, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4913, training loss= 0.007204576, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4914, training loss= 0.0071999957, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4915, training loss= 0.0071948604, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4916, training loss= 0.007189359, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4917, training loss= 0.007184151, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4918, training loss= 0.00717911, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4919, training loss= 0.0071737315, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4920, training loss= 0.0071689724, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4921, training loss= 0.007163639, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4922, training loss= 0.0071596224, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4923, training loss= 0.0071539236, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4924, training loss= 0.0071487622, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4925, training loss= 0.007142411, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4926, training loss= 0.007139472, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4927, training loss= 0.0071355966, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4928, training loss= 0.007128501, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4929, training loss= 0.0071234894, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4930, training loss= 0.0071197404, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4931, training loss= 0.0071139866, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4932, training loss= 0.007107631, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4933, training loss= 0.0071029784, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4934, training loss= 0.0070979707, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4935, training loss= 0.007092273, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4936, training loss= 0.007087434, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4937, training loss= 0.007081311, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4938, training loss= 0.007077563, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.5048828125 ...\n",
            "\n",
            "step 4939, training loss= 0.0070732534, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4940, training loss= 0.0070672133, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4941, training loss= 0.007061555, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4942, training loss= 0.0070580887, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4943, training loss= 0.0070519196, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4944, training loss= 0.0070454776, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4945, training loss= 0.0070415963, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4946, training loss= 0.007036451, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4947, training loss= 0.007029759, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4948, training loss= 0.0070259003, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4949, training loss= 0.007020801, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4950, training loss= 0.007015352, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4951, training loss= 0.007010476, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4952, training loss= 0.007005137, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4953, training loss= 0.007001097, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4954, training loss= 0.0069952426, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4955, training loss= 0.0069901547, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4956, training loss= 0.006986129, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4957, training loss= 0.00698005, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4958, training loss= 0.0069757816, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4959, training loss= 0.006970809, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4960, training loss= 0.0069654477, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4961, training loss= 0.0069602337, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4962, training loss= 0.0069548804, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4963, training loss= 0.0069496585, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4964, training loss= 0.0069438587, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4965, training loss= 0.0069392067, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4966, training loss= 0.00693447, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4967, training loss= 0.0069294353, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4968, training loss= 0.0069241705, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4969, training loss= 0.0069191656, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4970, training loss= 0.006914608, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4971, training loss= 0.006908615, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4972, training loss= 0.006904413, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4973, training loss= 0.0068994667, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4974, training loss= 0.0068943487, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4975, training loss= 0.006889369, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4976, training loss= 0.0068843816, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4977, training loss= 0.00687982, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4978, training loss= 0.0068743424, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4979, training loss= 0.006870603, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4980, training loss= 0.006864312, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4981, training loss= 0.0068599046, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4982, training loss= 0.0068548108, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4983, training loss= 0.006850389, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4984, training loss= 0.006845736, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4985, training loss= 0.0068398006, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4986, training loss= 0.0068349186, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4987, training loss= 0.006830634, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4988, training loss= 0.0068245726, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4989, training loss= 0.0068194587, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4990, training loss= 0.0068152314, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4991, training loss= 0.006809404, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4992, training loss= 0.0068048765, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4993, training loss= 0.0067997253, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4994, training loss= 0.006794751, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4995, training loss= 0.0067894286, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4996, training loss= 0.0067844396, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4997, training loss= 0.0067803967, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4998, training loss= 0.0067749834, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "step 4999, training loss= 0.0067708865, training acc= 99.9355673789978%\n",
            "Validation Accuracy 88.58000946044922 ...\n",
            "\n",
            "Valid acc= 89.0308 %\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7stX_1nwgQlH",
        "colab_type": "code",
        "outputId": "d62f4ed8-abd8-4fe7-dec1-e0db12ecdeda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "# steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "# # plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# # plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "# plt.tight_layout()\n",
        "# # plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.grid(abs)\n",
        "# plt.show()\n",
        "steps_plot =  [step for step in range(0, num_steps, plot_every)]\n",
        "plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "# plt.plot(steps_plot, savgol_filter(100*np.asarray(train_accuracy),3,1))  \n",
        "# plt.plot(steps_plot, savgol_filter(np.asarray(val_accuracy),3,1))\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiISKUpsIiISKUpsIiISKUpsIiISKf8fyHE0xdVF1aUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "JXnnuX8tgSPg",
        "colab_type": "code",
        "outputId": "a0ef2ae6-f2b0-42b0-d736-d45e8ec9e0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),3,1)\n",
        "valid_accuracy_filtered = val_accuracy[5:]\n",
        "\n",
        "# valid_accuracy_filtered = savgol_filter(np.asarray(val_accuracy),3,1)\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])\n",
        "print(train_losses[5+np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88.88054\n",
            "2445\n",
            "2445\n",
            "0.033881765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wC_9RTLQ6eHk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Now retrain on this appended test data till 1 steps\n"
      ]
    },
    {
      "metadata": {
        "id": "cgVyc7s3kAQt",
        "colab_type": "code",
        "outputId": "3d5685d4-cf1e-456a-8b27-8c476dea0899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(combined_train_valid.shape)\n",
        "print(aside_valid_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4335, 36)\n",
            "(100, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XmptC10puIK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined_shuffle_indices = np.random.permutation(train_valid_combined.shape[0])\n",
        "train_valid_combined_shuffled = train_valid_combined[train_valid_combined_shuffle_indices,:]\n",
        "validation_test_label_one_hot_shuffled = validation_test_label_one_hot[train_valid_combined_shuffle_indices,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFJzaiyStupC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 400\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ggpymMvuGPC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reinitialize wt\n",
        "## Define weights of the layer\n",
        "# G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "# G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "# G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "# G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "\n",
        "G_W1 = tf.Variable(xavier_init(clf.coefs_[0].shape))\n",
        "G_b1 = tf.Variable(xavier_init(clf.intercepts_ [0].shape))\n",
        "\n",
        "G_W2 =  tf.Variable(xavier_init(clf.coefs_[1].shape))\n",
        "G_b2 = tf.Variable(xavier_init(clf.intercepts_ [1].shape))\n",
        "\n",
        "num_hidden_neurons = 90\n",
        "GwLoop = tf.Variable(xavier_init([output_shape,num_hidden_neurons]))\n",
        "G_bLoop = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GwLoop2 = tf.Variable(xavier_init([num_hidden_neurons,num_hidden_neurons]))\n",
        "G_bLoop2 = tf.Variable(tf.zeros(shape=[num_hidden_neurons]))\n",
        "\n",
        "GLossW = tf.Variable(xavier_init([output_shape,output_shape]))\n",
        "GLossb= tf.Variable(tf.zeros(shape=[output_shape]))\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2gf_uEy6eHl",
        "colab_type": "code",
        "outputId": "49e7eab6-5d86-41a1-feed-8ea72779a7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9520
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 5000\n",
        "# num_steps = 20000\n",
        "\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 100\n",
        "best_accuracy_valid\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        if (step>2500):\n",
        "          plot_every = 10\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            \n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "            if step%plot_every == 0:\n",
        "              if (validationTest_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#         if(train_loss_total<0.033881765):\n",
        "#           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "    saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 2.249485, training acc total= 10.111524164676666%\n",
            "ValidTest acc= 2.0 %\n",
            "step 100, training loss Total= 0.48414153, training acc total= 83.5192084312439%\n",
            "ValidTest acc= 85.0 %\n",
            "step 200, training loss Total= 0.375522, training acc total= 85.35315990447998%\n",
            "ValidTest acc= 80.75 %\n",
            "step 300, training loss Total= 0.3350746, training acc total= 86.34448647499084%\n",
            "ValidTest acc= 80.0 %\n",
            "step 400, training loss Total= 0.30637467, training acc total= 87.13754415512085%\n",
            "ValidTest acc= 80.25 %\n",
            "step 500, training loss Total= 0.28196496, training acc total= 87.65799403190613%\n",
            "ValidTest acc= 80.0 %\n",
            "step 600, training loss Total= 0.26231056, training acc total= 88.17843794822693%\n",
            "ValidTest acc= 79.75 %\n",
            "step 700, training loss Total= 0.24660839, training acc total= 88.69888186454773%\n",
            "ValidTest acc= 79.75 %\n",
            "step 800, training loss Total= 0.23350641, training acc total= 89.41759467124939%\n",
            "ValidTest acc= 81.0 %\n",
            "step 900, training loss Total= 0.22221144, training acc total= 89.83891010284424%\n",
            "ValidTest acc= 81.25 %\n",
            "step 1000, training loss Total= 0.21235307, training acc total= 90.38413763046265%\n",
            "ValidTest acc= 81.75 %\n",
            "step 1100, training loss Total= 0.20377584, training acc total= 90.8302366733551%\n",
            "ValidTest acc= 81.75 %\n",
            "step 1200, training loss Total= 0.1960521, training acc total= 91.17720127105713%\n",
            "ValidTest acc= 81.75 %\n",
            "step 1300, training loss Total= 0.18915793, training acc total= 91.54894948005676%\n",
            "ValidTest acc= 82.75 %\n",
            "step 1400, training loss Total= 0.18303005, training acc total= 91.62329435348511%\n",
            "ValidTest acc= 83.25 %\n",
            "step 1500, training loss Total= 0.1775125, training acc total= 91.84634685516357%\n",
            "ValidTest acc= 83.25 %\n",
            "step 1600, training loss Total= 0.17178088, training acc total= 91.97025895118713%\n",
            "ValidTest acc= 83.5 %\n",
            "step 1700, training loss Total= 0.16721636, training acc total= 92.1933114528656%\n",
            "ValidTest acc= 83.75 %\n",
            "step 1800, training loss Total= 0.16214493, training acc total= 92.29243993759155%\n",
            "ValidTest acc= 84.25 %\n",
            "step 1900, training loss Total= 0.15760247, training acc total= 92.56505370140076%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2000, training loss Total= 0.15317394, training acc total= 92.6889717578888%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2100, training loss Total= 0.14909546, training acc total= 92.86245107650757%\n",
            "ValidTest acc= 84.25 %\n",
            "step 2200, training loss Total= 0.14555033, training acc total= 93.06071996688843%\n",
            "ValidTest acc= 84.0 %\n",
            "step 2300, training loss Total= 0.14117272, training acc total= 93.25898289680481%\n",
            "ValidTest acc= 84.0 %\n",
            "step 2400, training loss Total= 0.13755225, training acc total= 93.5068130493164%\n",
            "ValidTest acc= 84.0 %\n",
            "step 2500, training loss Total= 0.13380362, training acc total= 93.72986555099487%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2510, training loss Total= 0.13346875, training acc total= 93.72986555099487%\n",
            "ValidTest acc= 84.0 %\n",
            "step 2520, training loss Total= 0.1331132, training acc total= 93.72986555099487%\n",
            "ValidTest acc= 84.25 %\n",
            "step 2530, training loss Total= 0.13283372, training acc total= 93.72986555099487%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2540, training loss Total= 0.132504, training acc total= 93.75464916229248%\n",
            "ValidTest acc= 84.0 %\n",
            "step 2550, training loss Total= 0.13209811, training acc total= 93.75464916229248%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2560, training loss Total= 0.13181026, training acc total= 93.77943277359009%\n",
            "ValidTest acc= 85.0 %\n",
            "step 2570, training loss Total= 0.13149396, training acc total= 93.75464916229248%\n",
            "ValidTest acc= 84.25 %\n",
            "step 2580, training loss Total= 0.13112341, training acc total= 93.85377764701843%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2590, training loss Total= 0.13067885, training acc total= 93.77943277359009%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2600, training loss Total= 0.13032559, training acc total= 93.80421042442322%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2610, training loss Total= 0.13004047, training acc total= 93.82899403572083%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2620, training loss Total= 0.1297413, training acc total= 93.85377764701843%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2630, training loss Total= 0.12947716, training acc total= 93.82899403572083%\n",
            "ValidTest acc= 85.5 %\n",
            "step 2640, training loss Total= 0.12909116, training acc total= 93.85377764701843%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2650, training loss Total= 0.12865004, training acc total= 93.87856125831604%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2660, training loss Total= 0.12836237, training acc total= 93.90334486961365%\n",
            "ValidTest acc= 85.0 %\n",
            "step 2670, training loss Total= 0.12797844, training acc total= 93.87856125831604%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2680, training loss Total= 0.1277909, training acc total= 93.92812848091125%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2690, training loss Total= 0.12758851, training acc total= 94.00247931480408%\n",
            "ValidTest acc= 85.5 %\n",
            "step 2700, training loss Total= 0.12696353, training acc total= 93.95291209220886%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2710, training loss Total= 0.12673658, training acc total= 93.95291209220886%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2720, training loss Total= 0.1264687, training acc total= 93.95291209220886%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2730, training loss Total= 0.12603872, training acc total= 93.97769570350647%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2740, training loss Total= 0.12561955, training acc total= 94.02726292610168%\n",
            "ValidTest acc= 85.0 %\n",
            "step 2750, training loss Total= 0.12528224, training acc total= 93.97769570350647%\n",
            "ValidTest acc= 85.0 %\n",
            "step 2760, training loss Total= 0.124961995, training acc total= 94.02726292610168%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2770, training loss Total= 0.1247201, training acc total= 94.0768301486969%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2780, training loss Total= 0.124547936, training acc total= 94.02726292610168%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2790, training loss Total= 0.124210276, training acc total= 93.97769570350647%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2800, training loss Total= 0.123845816, training acc total= 94.12639141082764%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2810, training loss Total= 0.12346585, training acc total= 94.05204653739929%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2820, training loss Total= 0.123140804, training acc total= 94.15117502212524%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2830, training loss Total= 0.122880325, training acc total= 94.0768301486969%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2840, training loss Total= 0.1224825, training acc total= 94.1016137599945%\n",
            "ValidTest acc= 85.5 %\n",
            "step 2850, training loss Total= 0.12207659, training acc total= 94.15117502212524%\n",
            "ValidTest acc= 85.5 %\n",
            "step 2860, training loss Total= 0.12171198, training acc total= 94.1016137599945%\n",
            "ValidTest acc= 86.25 %\n",
            "step 2870, training loss Total= 0.121513546, training acc total= 94.12639141082764%\n",
            "ValidTest acc= 85.0 %\n",
            "step 2880, training loss Total= 0.1211377, training acc total= 94.1016137599945%\n",
            "ValidTest acc= 84.75 %\n",
            "step 2890, training loss Total= 0.120827354, training acc total= 94.15117502212524%\n",
            "ValidTest acc= 85.25 %\n",
            "step 2900, training loss Total= 0.12043597, training acc total= 94.12639141082764%\n",
            "ValidTest acc= 84.5 %\n",
            "step 2910, training loss Total= 0.12033732, training acc total= 94.12639141082764%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2920, training loss Total= 0.12026145, training acc total= 94.17595863342285%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2930, training loss Total= 0.1195429, training acc total= 94.20074224472046%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2940, training loss Total= 0.11930487, training acc total= 94.12639141082764%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2950, training loss Total= 0.11899084, training acc total= 94.17595863342285%\n",
            "ValidTest acc= 86.0 %\n",
            "step 2960, training loss Total= 0.11866993, training acc total= 94.25030946731567%\n",
            "ValidTest acc= 86.25 %\n",
            "step 2970, training loss Total= 0.11828706, training acc total= 94.3246603012085%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2980, training loss Total= 0.11795232, training acc total= 94.27509307861328%\n",
            "ValidTest acc= 85.75 %\n",
            "step 2990, training loss Total= 0.11769892, training acc total= 94.3246603012085%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3000, training loss Total= 0.11730687, training acc total= 94.3494439125061%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3010, training loss Total= 0.11697522, training acc total= 94.3494439125061%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3020, training loss Total= 0.116749704, training acc total= 94.3246603012085%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3030, training loss Total= 0.11642986, training acc total= 94.39901113510132%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3040, training loss Total= 0.11617243, training acc total= 94.42379474639893%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3050, training loss Total= 0.115807, training acc total= 94.39901113510132%\n",
            "ValidTest acc= 86.0 %\n",
            "step 3060, training loss Total= 0.1156634, training acc total= 94.42379474639893%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3070, training loss Total= 0.11527766, training acc total= 94.52292323112488%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3080, training loss Total= 0.11494774, training acc total= 94.42379474639893%\n",
            "ValidTest acc= 86.0 %\n",
            "step 3090, training loss Total= 0.11457014, training acc total= 94.49813961982727%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3100, training loss Total= 0.11442615, training acc total= 94.47335600852966%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3110, training loss Total= 0.113968335, training acc total= 94.49813961982727%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3120, training loss Total= 0.11368345, training acc total= 94.5972740650177%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3130, training loss Total= 0.11351413, training acc total= 94.54770684242249%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3140, training loss Total= 0.113089636, training acc total= 94.49813961982727%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3150, training loss Total= 0.112782836, training acc total= 94.57249045372009%\n",
            "ValidTest acc= 86.0 %\n",
            "step 3160, training loss Total= 0.11246821, training acc total= 94.64684128761292%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3170, training loss Total= 0.11216626, training acc total= 94.62205767631531%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3180, training loss Total= 0.111937456, training acc total= 94.64684128761292%\n",
            "ValidTest acc= 85.75 %\n",
            "step 3190, training loss Total= 0.111747965, training acc total= 94.64684128761292%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3200, training loss Total= 0.11139657, training acc total= 94.72119212150574%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3210, training loss Total= 0.11103252, training acc total= 94.67162489891052%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3220, training loss Total= 0.110677555, training acc total= 94.67162489891052%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3230, training loss Total= 0.11045797, training acc total= 94.72119212150574%\n",
            "ValidTest acc= 86.0 %\n",
            "step 3240, training loss Total= 0.11014515, training acc total= 94.64684128761292%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3250, training loss Total= 0.10982018, training acc total= 94.64684128761292%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3260, training loss Total= 0.109538265, training acc total= 94.72119212150574%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3270, training loss Total= 0.10930522, training acc total= 94.72119212150574%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3280, training loss Total= 0.10896528, training acc total= 94.67162489891052%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3290, training loss Total= 0.10874087, training acc total= 94.67162489891052%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3300, training loss Total= 0.10837747, training acc total= 94.77075338363647%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3310, training loss Total= 0.108151495, training acc total= 94.74596977233887%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3320, training loss Total= 0.10792603, training acc total= 94.74596977233887%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3330, training loss Total= 0.107610255, training acc total= 94.72119212150574%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3340, training loss Total= 0.107239984, training acc total= 94.77075338363647%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3350, training loss Total= 0.107039765, training acc total= 94.8451042175293%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3360, training loss Total= 0.10668893, training acc total= 94.82032060623169%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3370, training loss Total= 0.10635363, training acc total= 94.8451042175293%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3380, training loss Total= 0.10607763, training acc total= 94.8698878288269%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3390, training loss Total= 0.10579954, training acc total= 94.77075338363647%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3400, training loss Total= 0.10555663, training acc total= 94.89467144012451%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3410, training loss Total= 0.10517173, training acc total= 94.8698878288269%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3420, training loss Total= 0.105006695, training acc total= 94.91945505142212%\n",
            "ValidTest acc= 85.5 %\n",
            "step 3430, training loss Total= 0.104608186, training acc total= 94.89467144012451%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3440, training loss Total= 0.10435849, training acc total= 94.96902227401733%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3450, training loss Total= 0.10406403, training acc total= 94.96902227401733%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3460, training loss Total= 0.10381814, training acc total= 95.01858949661255%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3470, training loss Total= 0.10352214, training acc total= 94.94423866271973%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3480, training loss Total= 0.10324179, training acc total= 95.06815075874329%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3490, training loss Total= 0.102995135, training acc total= 95.1177179813385%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3500, training loss Total= 0.10271161, training acc total= 95.1177179813385%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3510, training loss Total= 0.10243044, training acc total= 95.21685242652893%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3520, training loss Total= 0.10236687, training acc total= 95.19206881523132%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3530, training loss Total= 0.10193399, training acc total= 95.16728520393372%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3540, training loss Total= 0.101693176, training acc total= 95.19206881523132%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3550, training loss Total= 0.101414666, training acc total= 95.06815075874329%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3560, training loss Total= 0.10110653, training acc total= 95.1177179813385%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3570, training loss Total= 0.10074793, training acc total= 95.21685242652893%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3580, training loss Total= 0.10057469, training acc total= 95.16728520393372%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3590, training loss Total= 0.100237206, training acc total= 95.16728520393372%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3600, training loss Total= 0.100059114, training acc total= 95.16728520393372%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3610, training loss Total= 0.09968009, training acc total= 95.24163603782654%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3620, training loss Total= 0.09939162, training acc total= 95.21685242652893%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3630, training loss Total= 0.09911915, training acc total= 95.29120326042175%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3640, training loss Total= 0.09887856, training acc total= 95.19206881523132%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3650, training loss Total= 0.098575205, training acc total= 95.29120326042175%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3660, training loss Total= 0.09841029, training acc total= 95.36555409431458%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3670, training loss Total= 0.09808883, training acc total= 95.26641964912415%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3680, training loss Total= 0.09783026, training acc total= 95.31598687171936%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3690, training loss Total= 0.097524256, training acc total= 95.36555409431458%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3700, training loss Total= 0.09732404, training acc total= 95.46468257904053%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3710, training loss Total= 0.09701051, training acc total= 95.43989896774292%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3720, training loss Total= 0.09670007, training acc total= 95.41511535644531%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3730, training loss Total= 0.096456744, training acc total= 95.43989896774292%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3740, training loss Total= 0.096142575, training acc total= 95.36555409431458%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3750, training loss Total= 0.09587866, training acc total= 95.3903317451477%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3760, training loss Total= 0.09562822, training acc total= 95.48946619033813%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3770, training loss Total= 0.095410086, training acc total= 95.43989896774292%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3780, training loss Total= 0.095080696, training acc total= 95.58860063552856%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3790, training loss Total= 0.09485832, training acc total= 95.53903341293335%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3800, training loss Total= 0.09452702, training acc total= 95.53903341293335%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3810, training loss Total= 0.09430025, training acc total= 95.51424980163574%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3820, training loss Total= 0.094014905, training acc total= 95.56381702423096%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3830, training loss Total= 0.09375044, training acc total= 95.56381702423096%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3840, training loss Total= 0.09348289, training acc total= 95.63816785812378%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3850, training loss Total= 0.093323745, training acc total= 95.61338424682617%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3860, training loss Total= 0.09297224, training acc total= 95.63816785812378%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3870, training loss Total= 0.0927046, training acc total= 95.61338424682617%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3880, training loss Total= 0.09242089, training acc total= 95.63816785812378%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3890, training loss Total= 0.09221874, training acc total= 95.61338424682617%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3900, training loss Total= 0.0919548, training acc total= 95.63816785812378%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3910, training loss Total= 0.09177697, training acc total= 95.58860063552856%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3920, training loss Total= 0.09150836, training acc total= 95.66295146942139%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3930, training loss Total= 0.09117219, training acc total= 95.63816785812378%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3940, training loss Total= 0.09090046, training acc total= 95.66295146942139%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3950, training loss Total= 0.090668365, training acc total= 95.687735080719%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3960, training loss Total= 0.09042433, training acc total= 95.66295146942139%\n",
            "ValidTest acc= 85.0 %\n",
            "step 3970, training loss Total= 0.0901084, training acc total= 95.687735080719%\n",
            "ValidTest acc= 84.75 %\n",
            "step 3980, training loss Total= 0.089889295, training acc total= 95.78686356544495%\n",
            "ValidTest acc= 85.25 %\n",
            "step 3990, training loss Total= 0.0898415, training acc total= 95.81164717674255%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4000, training loss Total= 0.08936235, training acc total= 95.76207995414734%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4010, training loss Total= 0.08913775, training acc total= 95.78686356544495%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4020, training loss Total= 0.08881186, training acc total= 95.76207995414734%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4030, training loss Total= 0.08855643, training acc total= 95.83643078804016%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4040, training loss Total= 0.08830391, training acc total= 95.88599801063538%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4050, training loss Total= 0.08801598, training acc total= 95.81164717674255%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4060, training loss Total= 0.08800326, training acc total= 95.88599801063538%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4070, training loss Total= 0.08773128, training acc total= 95.78686356544495%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4080, training loss Total= 0.08735116, training acc total= 95.91078162193298%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4090, training loss Total= 0.08710847, training acc total= 95.81164717674255%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4100, training loss Total= 0.08682678, training acc total= 95.83643078804016%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4110, training loss Total= 0.08660376, training acc total= 95.86121439933777%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4120, training loss Total= 0.0863015, training acc total= 95.88599801063538%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4130, training loss Total= 0.08607222, training acc total= 95.91078162193298%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4140, training loss Total= 0.08575452, training acc total= 95.9603488445282%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4150, training loss Total= 0.08549841, training acc total= 96.03469371795654%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4160, training loss Total= 0.085243754, training acc total= 96.08426094055176%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4170, training loss Total= 0.08505878, training acc total= 95.93556523323059%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4180, training loss Total= 0.08472859, training acc total= 96.03469371795654%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4190, training loss Total= 0.084451355, training acc total= 96.10904455184937%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4200, training loss Total= 0.084185466, training acc total= 96.03469371795654%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4210, training loss Total= 0.0839532, training acc total= 96.10904455184937%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4220, training loss Total= 0.0837134, training acc total= 96.13382816314697%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4230, training loss Total= 0.08347998, training acc total= 96.10904455184937%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4240, training loss Total= 0.08326296, training acc total= 96.18339538574219%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4250, training loss Total= 0.0830075, training acc total= 96.18339538574219%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4260, training loss Total= 0.08277916, training acc total= 96.10904455184937%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4270, training loss Total= 0.08253842, training acc total= 96.15861177444458%\n",
            "ValidTest acc= 84.25 %\n",
            "step 4280, training loss Total= 0.08223238, training acc total= 96.2329626083374%\n",
            "ValidTest acc= 84.25 %\n",
            "step 4290, training loss Total= 0.08200467, training acc total= 96.2329626083374%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4300, training loss Total= 0.08176712, training acc total= 96.30731344223022%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4310, training loss Total= 0.081527025, training acc total= 96.2329626083374%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4320, training loss Total= 0.08123996, training acc total= 96.2329626083374%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4330, training loss Total= 0.08097774, training acc total= 96.30731344223022%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4340, training loss Total= 0.08075157, training acc total= 96.33209705352783%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4350, training loss Total= 0.08064896, training acc total= 96.28252983093262%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4360, training loss Total= 0.08027394, training acc total= 96.33209705352783%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4370, training loss Total= 0.08012058, training acc total= 96.38165831565857%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4380, training loss Total= 0.079758115, training acc total= 96.38165831565857%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4390, training loss Total= 0.079542965, training acc total= 96.43122553825378%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4400, training loss Total= 0.07927177, training acc total= 96.43122553825378%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4410, training loss Total= 0.07905842, training acc total= 96.43122553825378%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4420, training loss Total= 0.07887749, training acc total= 96.40644192695618%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4430, training loss Total= 0.07854112, training acc total= 96.45600914955139%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4440, training loss Total= 0.078442484, training acc total= 96.480792760849%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4450, training loss Total= 0.07818197, training acc total= 96.43122553825378%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4460, training loss Total= 0.07800005, training acc total= 96.5055763721466%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4470, training loss Total= 0.07757605, training acc total= 96.45600914955139%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4480, training loss Total= 0.07733689, training acc total= 96.55514359474182%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4490, training loss Total= 0.077102244, training acc total= 96.5055763721466%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4500, training loss Total= 0.07690522, training acc total= 96.5055763721466%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4510, training loss Total= 0.07668663, training acc total= 96.62949442863464%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4520, training loss Total= 0.07643256, training acc total= 96.60471081733704%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4530, training loss Total= 0.076177314, training acc total= 96.57992720603943%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4540, training loss Total= 0.07589884, training acc total= 96.60471081733704%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4550, training loss Total= 0.075685255, training acc total= 96.57992720603943%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4560, training loss Total= 0.075472586, training acc total= 96.65427803993225%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4570, training loss Total= 0.07532957, training acc total= 96.67905569076538%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4580, training loss Total= 0.07502274, training acc total= 96.70383930206299%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4590, training loss Total= 0.07480374, training acc total= 96.65427803993225%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4600, training loss Total= 0.07456831, training acc total= 96.65427803993225%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4610, training loss Total= 0.07431047, training acc total= 96.70383930206299%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4620, training loss Total= 0.07409393, training acc total= 96.70383930206299%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4630, training loss Total= 0.073846355, training acc total= 96.80297374725342%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4640, training loss Total= 0.073632315, training acc total= 96.70383930206299%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4650, training loss Total= 0.073411584, training acc total= 96.7286229133606%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4660, training loss Total= 0.07318807, training acc total= 96.77819013595581%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4670, training loss Total= 0.072933614, training acc total= 96.77819013595581%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4680, training loss Total= 0.0726935, training acc total= 96.77819013595581%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4690, training loss Total= 0.07238528, training acc total= 96.80297374725342%\n",
            "ValidTest acc= 84.5 %\n",
            "step 4700, training loss Total= 0.07216149, training acc total= 96.77819013595581%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4710, training loss Total= 0.0719737, training acc total= 96.7534065246582%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4720, training loss Total= 0.07175855, training acc total= 96.7534065246582%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4730, training loss Total= 0.07153239, training acc total= 96.80297374725342%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4740, training loss Total= 0.07135037, training acc total= 96.95167541503906%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4750, training loss Total= 0.07106462, training acc total= 96.87732458114624%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4760, training loss Total= 0.070843585, training acc total= 96.82775735855103%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4770, training loss Total= 0.07060614, training acc total= 96.80297374725342%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4780, training loss Total= 0.070409, training acc total= 97.0012366771698%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4790, training loss Total= 0.07013193, training acc total= 96.95167541503906%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4800, training loss Total= 0.069906816, training acc total= 96.85254096984863%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4810, training loss Total= 0.06975369, training acc total= 96.85254096984863%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4820, training loss Total= 0.06942932, training acc total= 96.92689180374146%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4830, training loss Total= 0.069220096, training acc total= 96.97645306587219%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4840, training loss Total= 0.06921118, training acc total= 96.95167541503906%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4850, training loss Total= 0.06875692, training acc total= 97.0012366771698%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4860, training loss Total= 0.06850437, training acc total= 97.0012366771698%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4870, training loss Total= 0.06828374, training acc total= 97.0012366771698%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4880, training loss Total= 0.06818965, training acc total= 96.97645306587219%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4890, training loss Total= 0.0679151, training acc total= 97.02602028846741%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4900, training loss Total= 0.067659065, training acc total= 97.02602028846741%\n",
            "ValidTest acc= 85.5 %\n",
            "step 4910, training loss Total= 0.06744315, training acc total= 96.97645306587219%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4920, training loss Total= 0.06724337, training acc total= 96.95167541503906%\n",
            "ValidTest acc= 85.5 %\n",
            "step 4930, training loss Total= 0.0669899, training acc total= 97.0012366771698%\n",
            "ValidTest acc= 85.25 %\n",
            "step 4940, training loss Total= 0.06674859, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4950, training loss Total= 0.06660779, training acc total= 97.0012366771698%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4960, training loss Total= 0.066307485, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 85.0 %\n",
            "step 4970, training loss Total= 0.066230394, training acc total= 97.12515473365784%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4980, training loss Total= 0.06590084, training acc total= 97.05080389976501%\n",
            "ValidTest acc= 84.75 %\n",
            "step 4990, training loss Total= 0.06564923, training acc total= 97.07558751106262%\n",
            "ValidTest acc= 84.75 %\n",
            "ValidValid acc= 93.23817 %\n",
            "ValidTest acc= 85.5 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TyjBH_5g6lrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined_shuffle_indices = np.random.permutation(train_valid_combined.shape[0])\n",
        "train_valid_combined_shuffled = train_valid_combined[train_valid_combined_shuffle_indices,:]\n",
        "validation_test_label_one_hot_shuffled = validation_test_label_one_hot[train_valid_combined_shuffle_indices,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hMh6Xf06lk2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 400\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot_shuffled[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot_shuffled[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZOPBZ5n7vA4",
        "colab_type": "code",
        "outputId": "ec18acfc-b165-445f-d4e9-b47f0a32686a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "y = (np.argmax(aside_valid_test_label,axis=1))\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 2, 5, 5, 0, 5, 5,\n",
              "       5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 0, 3,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "ZVXK-_nl7jlR",
        "colab_type": "code",
        "outputId": "d8deb4ba-93c3-452f-f47c-10e11db04ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(combined_train_valid_label,axis = 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([965.,   0., 450.,   0., 892.,   0., 371.,   0., 421., 936.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADi5JREFUeJzt3X2IZfV9x/H3p27Mg2mzPgyL3V26\nQsQiQqsd1GIJRVtrVLL+YcTQ6la27D8mNbUQN6UgffjDlBJjoAiLm7JSMRE1uCSSVNQQhGqcVaPR\nTZrBanYXdSfxIbESUptv/7g/24lVx71n5t44v/cLhjnnd86953cI2ffcc8+9pqqQJPXnV6Y9AUnS\ndBgASeqUAZCkThkASeqUAZCkThkASeqUAZCkThkASeqUAZCkTq1ZaockXwDOBw5W1Ult7CjgS8Am\n4Cngoqp6IUmA64BzgVeAP62qh9pjtgB/3Z7276tq11LHPuaYY2rTpk2HeEqS1Lc9e/b8sKpmltov\nS30VRJIPAS8DNy4KwD8Az1fVNUm2A0dW1VVJzgU+wSgApwHXVdVpLRhzwCxQwB7gd6rqhbc69uzs\nbM3NzS11DpKkRZLsqarZpfZb8hJQVX0TeP51w5uB1/6C3wVcsGj8xhq5H1ib5Fjgj4C7qur59o/+\nXcA5b+9UJEkrYdz3ANZV1TNt+VlgXVteD+xbtN/+NvZm4/9Pkm1J5pLMLSwsjDk9SdJSBr8JXKNr\nSMv2laJVtaOqZqtqdmZmyUtYkqQxjRuA59qlHdrvg238ALBx0X4b2tibjUuSpmTcAOwGtrTlLcAd\ni8YvzcjpwEvtUtHXgbOTHJnkSODsNiZJmpK3cxvozcDvA8ck2Q9cDVwD3JJkK/A0cFHb/U5GdwDN\nM7oN9DKAqno+yd8BD7b9/raqXv/GsiRpgpa8DXSavA1Ukg7dst0GKklanQyAJHVqyfcA3sk2bf/q\nVI771DXnTeW4knQofAUgSZ0yAJLUKQMgSZ0yAJLUKQMgSZ1a1XcBSdIQ07qTECZzN6GvACSpUwZA\nkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjrlB8H0jrbaP6gjrSRfAUhSpwyAJHXKAEhSpwyA\nJHXKAEhSpwyAJHXKAEhSpwyAJHXKAEhSpwyAJHXKAEhSpwyAJHXKAEhSpwyAJHXKAEhSpwYFIMlf\nJHk8yXeS3JzkPUmOS/JAkvkkX0pyeNv33W19vm3ftBwnIEkaz9gBSLIe+HNgtqpOAg4DLgY+A1xb\nVR8EXgC2todsBV5o49e2/SRJUzL0EtAa4L1J1gDvA54BzgRubdt3ARe05c1tnbb9rCQZeHxJ0pjG\nDkBVHQD+EfgBo3/4XwL2AC9W1attt/3A+ra8HtjXHvtq2//ocY8vSRpmyCWgIxn9VX8c8OvAEcA5\nQyeUZFuSuSRzCwsLQ59OkvQmhlwC+gPgP6pqoar+C7gdOANY2y4JAWwADrTlA8BGgLb9A8CPXv+k\nVbWjqmaranZmZmbA9CRJb2VIAH4AnJ7kfe1a/lnAE8C9wIVtny3AHW15d1unbb+nqmrA8SVJAwx5\nD+ABRm/mPgQ81p5rB3AVcGWSeUbX+He2h+wEjm7jVwLbB8xbkjTQmqV3eXNVdTVw9euGnwROfYN9\nfwp8dMjxJEnLx08CS1KnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoA\nSFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKn\nDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdWpQAJKsTXJr\nku8m2Zvkd5McleSuJN9vv49s+ybJ55PMJ3k0ySnLcwqSpHEMfQVwHfC1qvpN4LeAvcB24O6qOh64\nu60DfBg4vv1sA64feGxJ0gBjByDJB4APATsBqupnVfUisBnY1XbbBVzQljcDN9bI/cDaJMeOPXNJ\n0iBDXgEcBywA/5zk4SQ3JDkCWFdVz7R9ngXWteX1wL5Fj9/fxiRJUzAkAGuAU4Drq+pk4D/5v8s9\nAFRVAXUoT5pkW5K5JHMLCwsDpidJeitDArAf2F9VD7T1WxkF4bnXLu203wfb9gPAxkWP39DGfkFV\n7aiq2aqanZmZGTA9SdJbGTsAVfUssC/JCW3oLOAJYDewpY1tAe5oy7uBS9vdQKcDLy26VCRJmrA1\nAx//CeCmJIcDTwKXMYrKLUm2Ak8DF7V97wTOBeaBV9q+kqQpGRSAqnoEmH2DTWe9wb4FXD7keJKk\n5eMngSWpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjpl\nACSpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSpUwZAkjplACSp\nUwZAkjplACSpU2umPQEtn03bvzq1Yz91zXlTO7ak8fgKQJI6ZQAkqVMGQJI6ZQAkqVMGQJI65V1A\nkn7pTfMOt9Vs8CuAJIcleTjJV9r6cUkeSDKf5EtJDm/j727r8237pqHHliSNbzkuAV0B7F20/hng\n2qr6IPACsLWNbwVeaOPXtv0kSVMyKABJNgDnATe09QBnAre2XXYBF7TlzW2dtv2str8kaQqGvgL4\nHPAp4Odt/Wjgxap6ta3vB9a35fXAPoC2/aW2vyRpCsYOQJLzgYNVtWcZ50OSbUnmkswtLCws51NL\nkhYZ8grgDOAjSZ4Cvsjo0s91wNokr91dtAE40JYPABsB2vYPAD96/ZNW1Y6qmq2q2ZmZmQHTkyS9\nlbEDUFWfrqoNVbUJuBi4p6r+GLgXuLDttgW4oy3vbuu07fdUVY17fEnSMCvxQbCrgCuTzDO6xr+z\nje8Ejm7jVwLbV+DYkqS3aVk+CFZV3wC+0ZafBE59g31+Cnx0OY4nSRrOr4KQpE75VRDSO4z/4R8t\nF18BSFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoA\nSFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKn\nDIAkdcoASFKnDIAkdcoASFKnDIAkdcoASFKnDIAkdWrsACTZmOTeJE8keTzJFW38qCR3Jfl++31k\nG0+SzyeZT/JoklOW6yQkSYduyCuAV4G/rKoTgdOBy5OcCGwH7q6q44G72zrAh4Hj28824PoBx5Yk\nDTR2AKrqmap6qC3/BNgLrAc2A7vabruAC9ryZuDGGrkfWJvk2LFnLkkaZFneA0iyCTgZeABYV1XP\ntE3PAuva8npg36KH7W9jkqQpGByAJO8HbgM+WVU/XrytqgqoQ3y+bUnmkswtLCwMnZ4k6U0MCkCS\ndzH6x/+mqrq9DT/32qWd9vtgGz8AbFz08A1t7BdU1Y6qmq2q2ZmZmSHTkyS9hSF3AQXYCeytqs8u\n2rQb2NKWtwB3LBq/tN0NdDrw0qJLRZKkCVsz4LFnAJcAjyV5pI39FXANcEuSrcDTwEVt253AucA8\n8Apw2YBjS5IGGjsAVXUfkDfZfNYb7F/A5eMeT5K0vPwksCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBI\nUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcM\ngCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1ygBIUqcMgCR1\nygBIUqcMgCR1ygBIUqcmHoAk5yT5XpL5JNsnfXxJ0shEA5DkMOCfgA8DJwIfS3LiJOcgSRqZ9CuA\nU4H5qnqyqn4GfBHYPOE5SJKYfADWA/sWre9vY5KkCUtVTe5gyYXAOVX1Z239EuC0qvr4on22Adva\n6gnA9wYc8hjghwMe/07T2/mC59wLz/nQ/EZVzSy105oxn3xcB4CNi9Y3tLH/VVU7gB3LcbAkc1U1\nuxzP9U7Q2/mC59wLz3llTPoS0IPA8UmOS3I4cDGwe8JzkCQx4VcAVfVqko8DXwcOA75QVY9Pcg6S\npJFJXwKiqu4E7pzQ4ZblUtI7SG/nC55zLzznFTDRN4ElSb88/CoISerUqgxAb183keQLSQ4m+c60\n5zIpSTYmuTfJE0keT3LFtOe00pK8J8m3kny7nfPfTHtOk5DksCQPJ/nKtOcyKUmeSvJYkkeSzK3Y\ncVbbJaD2dRP/Dvwhow+aPQh8rKqemOrEVlCSDwEvAzdW1UnTns8kJDkWOLaqHkryq8Ae4IJV/r9z\ngCOq6uUk7wLuA66oqvunPLUVleRKYBb4tao6f9rzmYQkTwGzVbWin31Yja8Auvu6iar6JvD8tOcx\nSVX1TFU91JZ/AuxllX+qvEZebqvvaj+r6y+410myATgPuGHac1mNVmMA/LqJziTZBJwMPDDdmay8\ndjnkEeAgcFdVrfZz/hzwKeDn057IhBXwr0n2tG9HWBGrMQDqSJL3A7cBn6yqH097Piutqv67qn6b\n0afoT02yai/5JTkfOFhVe6Y9lyn4vao6hdE3J1/eLvMuu9UYgCW/bkKrQ7sOfhtwU1XdPu35TFJV\nvQjcC5wz7bmsoDOAj7Tr4V8EzkzyL9Od0mRU1YH2+yDwZUaXtpfdagyAXzfRgfaG6E5gb1V9dtrz\nmYQkM0nWtuX3MrrR4bvTndXKqapPV9WGqtrE6P/H91TVn0x5WisuyRHtxgaSHAGcDazIHX6rLgBV\n9Srw2tdN7AVuWe1fN5HkZuDfgBOS7E+yddpzmoAzgEsY/VX4SPs5d9qTWmHHAvcmeZTRHzp3VVU3\nt0Z2ZB1wX5JvA98CvlpVX1uJA62620AlSW/PqnsFIEl6ewyAJHXKAEhSpwyAJHXKAEhSpwyAJHXK\nAEhSpwyAJHXqfwBxcKhdCMBJ/AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RuQyCV4q9l3E",
        "colab_type": "code",
        "outputId": "3141b80d-b103-46ee-b5c9-009f1d418b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(aside_valid_test_label,axis = 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([107.,   0.,  29.,   0.,  69.,   0.,  44.,   0.,  49., 102.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SKHmuqhl6liP",
        "colab_type": "code",
        "outputId": "340408d6-1f76-4e41-9344-3d007e6f4690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34510
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 15000\n",
        "# num_steps = 20000\n",
        "\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 500\n",
        "best_accuracy_valid\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        if (step>5000):\n",
        "          plot_every = 10\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            track_step.append(step)\n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "            if step%plot_every == 0:\n",
        "              if (validationTest_accuracy >= best_accuracy_valid):\n",
        "                best_accuracy_valid = validation_accuracy\n",
        "                saver.save(sess, './statlog_letterAdam')\n",
        "                G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "#         if(train_loss_total<0.033881765):\n",
        "#           break\n",
        "                                         \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 2.2215009, training acc total= 9.219330549240112%\n",
            "ValidTest acc= 11.0 %\n",
            "step 500, training loss Total= 0.2881687, training acc total= 87.38538026809692%\n",
            "ValidTest acc= 83.0 %\n",
            "step 1000, training loss Total= 0.21610025, training acc total= 90.23544192314148%\n",
            "ValidTest acc= 85.25 %\n",
            "step 1500, training loss Total= 0.17700866, training acc total= 91.5985107421875%\n",
            "ValidTest acc= 86.25 %\n",
            "step 2000, training loss Total= 0.15144627, training acc total= 92.56505370140076%\n",
            "ValidTest acc= 86.75 %\n",
            "step 2500, training loss Total= 0.13109908, training acc total= 93.25898289680481%\n",
            "ValidTest acc= 87.5 %\n",
            "step 3000, training loss Total= 0.11394577, training acc total= 94.29987668991089%\n",
            "ValidTest acc= 87.75 %\n",
            "step 3500, training loss Total= 0.09894013, training acc total= 95.34077048301697%\n",
            "ValidTest acc= 87.5 %\n",
            "step 4000, training loss Total= 0.08574314, training acc total= 95.9603488445282%\n",
            "ValidTest acc= 87.75 %\n",
            "step 4500, training loss Total= 0.07370351, training acc total= 96.7534065246582%\n",
            "ValidTest acc= 88.0 %\n",
            "step 5000, training loss Total= 0.06257476, training acc total= 97.37298488616943%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5010, training loss Total= 0.06245931, training acc total= 97.27385640144348%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5020, training loss Total= 0.062220626, training acc total= 97.47211933135986%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5030, training loss Total= 0.06203847, training acc total= 97.27385640144348%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5040, training loss Total= 0.06175938, training acc total= 97.44733572006226%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5050, training loss Total= 0.061579935, training acc total= 97.37298488616943%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5060, training loss Total= 0.061329663, training acc total= 97.47211933135986%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5070, training loss Total= 0.061259728, training acc total= 97.47211933135986%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5080, training loss Total= 0.060962275, training acc total= 97.49690294265747%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5090, training loss Total= 0.060831722, training acc total= 97.34820127487183%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5100, training loss Total= 0.060590968, training acc total= 97.52168655395508%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5110, training loss Total= 0.06035346, training acc total= 97.39776849746704%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5120, training loss Total= 0.060089342, training acc total= 97.44733572006226%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5130, training loss Total= 0.06002398, training acc total= 97.49690294265747%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5140, training loss Total= 0.060141742, training acc total= 97.44733572006226%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5150, training loss Total= 0.059867155, training acc total= 97.49690294265747%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5160, training loss Total= 0.059466824, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5170, training loss Total= 0.059149418, training acc total= 97.44733572006226%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5180, training loss Total= 0.058969837, training acc total= 97.49690294265747%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5190, training loss Total= 0.058879714, training acc total= 97.5712537765503%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5200, training loss Total= 0.05872897, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5210, training loss Total= 0.058421806, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5220, training loss Total= 0.058173202, training acc total= 97.64559864997864%\n",
            "ValidTest acc= 88.5 %\n",
            "step 5230, training loss Total= 0.057965375, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5240, training loss Total= 0.05779481, training acc total= 97.64559864997864%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5250, training loss Total= 0.05756843, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5260, training loss Total= 0.05759995, training acc total= 97.62081503868103%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5270, training loss Total= 0.057303656, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5280, training loss Total= 0.05703559, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5290, training loss Total= 0.056826968, training acc total= 97.5960373878479%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5300, training loss Total= 0.05666673, training acc total= 97.67038226127625%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5310, training loss Total= 0.056493815, training acc total= 97.74473309516907%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5320, training loss Total= 0.05627609, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5330, training loss Total= 0.05608444, training acc total= 97.74473309516907%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5340, training loss Total= 0.055870946, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5350, training loss Total= 0.055691253, training acc total= 97.71994948387146%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5360, training loss Total= 0.055550296, training acc total= 97.76951670646667%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5370, training loss Total= 0.05542373, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5380, training loss Total= 0.05519361, training acc total= 97.74473309516907%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5390, training loss Total= 0.0549387, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5400, training loss Total= 0.0548636, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5410, training loss Total= 0.054667547, training acc total= 97.79430031776428%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5420, training loss Total= 0.054548502, training acc total= 97.76951670646667%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5430, training loss Total= 0.054387763, training acc total= 97.79430031776428%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5440, training loss Total= 0.054041944, training acc total= 97.8686511516571%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5450, training loss Total= 0.05406372, training acc total= 97.69516587257385%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5460, training loss Total= 0.053826455, training acc total= 97.79430031776428%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5470, training loss Total= 0.053630985, training acc total= 97.74473309516907%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5480, training loss Total= 0.053386062, training acc total= 97.81908392906189%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5490, training loss Total= 0.053175446, training acc total= 97.79430031776428%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5500, training loss Total= 0.05294751, training acc total= 97.8438675403595%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5510, training loss Total= 0.05277659, training acc total= 97.8438675403595%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5520, training loss Total= 0.052557483, training acc total= 97.81908392906189%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5530, training loss Total= 0.052364048, training acc total= 97.8686511516571%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5540, training loss Total= 0.052141573, training acc total= 97.89343476295471%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5550, training loss Total= 0.051994756, training acc total= 97.8686511516571%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5560, training loss Total= 0.051823545, training acc total= 97.89343476295471%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5570, training loss Total= 0.051686376, training acc total= 97.81908392906189%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5580, training loss Total= 0.051568687, training acc total= 97.8686511516571%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5590, training loss Total= 0.051352512, training acc total= 97.89343476295471%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5600, training loss Total= 0.051166788, training acc total= 97.8438675403595%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5610, training loss Total= 0.0509942, training acc total= 97.94299602508545%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5620, training loss Total= 0.05077433, training acc total= 97.99256324768066%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5630, training loss Total= 0.050657738, training acc total= 97.91821837425232%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5640, training loss Total= 0.050503947, training acc total= 97.94299602508545%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5650, training loss Total= 0.050334796, training acc total= 97.91821837425232%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5660, training loss Total= 0.050089832, training acc total= 97.91821837425232%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5670, training loss Total= 0.04994915, training acc total= 97.96777963638306%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5680, training loss Total= 0.049736593, training acc total= 97.91821837425232%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5690, training loss Total= 0.04954172, training acc total= 97.96777963638306%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5700, training loss Total= 0.04950697, training acc total= 97.91821837425232%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5710, training loss Total= 0.04926452, training acc total= 97.89343476295471%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5720, training loss Total= 0.049071666, training acc total= 97.94299602508545%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5730, training loss Total= 0.048966352, training acc total= 98.01734685897827%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5740, training loss Total= 0.04872216, training acc total= 98.01734685897827%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5750, training loss Total= 0.0485391, training acc total= 98.01734685897827%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5760, training loss Total= 0.048408616, training acc total= 98.0916976928711%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5770, training loss Total= 0.048193406, training acc total= 98.1164813041687%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5780, training loss Total= 0.048063, training acc total= 97.96777963638306%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5790, training loss Total= 0.048126422, training acc total= 97.89343476295471%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5800, training loss Total= 0.04773079, training acc total= 98.1164813041687%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5810, training loss Total= 0.047597516, training acc total= 98.04213047027588%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5820, training loss Total= 0.047478937, training acc total= 98.14126491546631%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5830, training loss Total= 0.047235593, training acc total= 98.14126491546631%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5840, training loss Total= 0.047043983, training acc total= 98.1164813041687%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5850, training loss Total= 0.046904597, training acc total= 98.16604852676392%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5860, training loss Total= 0.04786362, training acc total= 98.1164813041687%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5870, training loss Total= 0.051795498, training acc total= 97.91821837425232%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5880, training loss Total= 0.04828931, training acc total= 98.1164813041687%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5890, training loss Total= 0.04710447, training acc total= 98.16604852676392%\n",
            "ValidTest acc= 89.5 %\n",
            "step 5900, training loss Total= 0.046697702, training acc total= 98.16604852676392%\n",
            "ValidTest acc= 88.75 %\n",
            "step 5910, training loss Total= 0.04626529, training acc total= 98.26517701148987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5920, training loss Total= 0.046112232, training acc total= 98.19083213806152%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5930, training loss Total= 0.045906175, training acc total= 98.26517701148987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5940, training loss Total= 0.045919582, training acc total= 98.16604852676392%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5950, training loss Total= 0.04554803, training acc total= 98.1164813041687%\n",
            "ValidTest acc= 89.0 %\n",
            "step 5960, training loss Total= 0.045403622, training acc total= 98.24039936065674%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5970, training loss Total= 0.045337304, training acc total= 98.26517701148987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 5980, training loss Total= 0.045247123, training acc total= 98.26517701148987%\n",
            "ValidTest acc= 89.5 %\n",
            "step 5990, training loss Total= 0.045135226, training acc total= 98.21561574935913%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6000, training loss Total= 0.04497286, training acc total= 98.26517701148987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6010, training loss Total= 0.044757303, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6020, training loss Total= 0.044615168, training acc total= 98.33952784538269%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6030, training loss Total= 0.04453699, training acc total= 98.28996062278748%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6040, training loss Total= 0.04431825, training acc total= 98.28996062278748%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6050, training loss Total= 0.044189464, training acc total= 98.31474423408508%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6060, training loss Total= 0.044105724, training acc total= 98.31474423408508%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6070, training loss Total= 0.04410167, training acc total= 98.33952784538269%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6080, training loss Total= 0.043893754, training acc total= 98.28996062278748%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6090, training loss Total= 0.043940257, training acc total= 98.33952784538269%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6100, training loss Total= 0.043865707, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6110, training loss Total= 0.043475054, training acc total= 98.33952784538269%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6120, training loss Total= 0.043375783, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 88.75 %\n",
            "step 6130, training loss Total= 0.043244988, training acc total= 98.33952784538269%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6140, training loss Total= 0.04311564, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6150, training loss Total= 0.04291019, training acc total= 98.31474423408508%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6160, training loss Total= 0.042756766, training acc total= 98.43866229057312%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6170, training loss Total= 0.042677246, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6180, training loss Total= 0.042531546, training acc total= 98.41387867927551%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6190, training loss Total= 0.04239631, training acc total= 98.41387867927551%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6200, training loss Total= 0.042300828, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6210, training loss Total= 0.0421535, training acc total= 98.3643114566803%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6220, training loss Total= 0.042070165, training acc total= 98.41387867927551%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6230, training loss Total= 0.041890312, training acc total= 98.41387867927551%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6240, training loss Total= 0.0417793, training acc total= 98.41387867927551%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6250, training loss Total= 0.041636437, training acc total= 98.53779673576355%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6260, training loss Total= 0.041584745, training acc total= 98.43866229057312%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6270, training loss Total= 0.041444667, training acc total= 98.48822951316833%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6280, training loss Total= 0.041286096, training acc total= 98.53779673576355%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6290, training loss Total= 0.041162178, training acc total= 98.51301312446594%\n",
            "ValidTest acc= 89.0 %\n",
            "step 6300, training loss Total= 0.041011494, training acc total= 98.56258034706116%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6310, training loss Total= 0.040919643, training acc total= 98.58735799789429%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6320, training loss Total= 0.040739655, training acc total= 98.53779673576355%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6330, training loss Total= 0.040640656, training acc total= 98.56258034706116%\n",
            "ValidTest acc= 89.75 %\n",
            "step 6340, training loss Total= 0.04050756, training acc total= 98.51301312446594%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6350, training loss Total= 0.040439066, training acc total= 98.53779673576355%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6360, training loss Total= 0.040302727, training acc total= 98.41387867927551%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6370, training loss Total= 0.040176976, training acc total= 98.48822951316833%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6380, training loss Total= 0.040043335, training acc total= 98.51301312446594%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6390, training loss Total= 0.03985257, training acc total= 98.6369252204895%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6400, training loss Total= 0.039798632, training acc total= 98.58735799789429%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6410, training loss Total= 0.039630096, training acc total= 98.6121416091919%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6420, training loss Total= 0.039496925, training acc total= 98.6369252204895%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6430, training loss Total= 0.039377674, training acc total= 98.66170883178711%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6440, training loss Total= 0.039428353, training acc total= 98.48822951316833%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6450, training loss Total= 0.039201412, training acc total= 98.53779673576355%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6460, training loss Total= 0.03904262, training acc total= 98.66170883178711%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6470, training loss Total= 0.038857963, training acc total= 98.66170883178711%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6480, training loss Total= 0.03885026, training acc total= 98.56258034706116%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6490, training loss Total= 0.038669307, training acc total= 98.68649244308472%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6500, training loss Total= 0.038538374, training acc total= 98.71127605438232%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6510, training loss Total= 0.03839155, training acc total= 98.68649244308472%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6520, training loss Total= 0.03838315, training acc total= 98.58735799789429%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6530, training loss Total= 0.038170096, training acc total= 98.71127605438232%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6540, training loss Total= 0.038101226, training acc total= 98.6369252204895%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6550, training loss Total= 0.037971407, training acc total= 98.66170883178711%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6560, training loss Total= 0.037847478, training acc total= 98.66170883178711%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6570, training loss Total= 0.037694894, training acc total= 98.71127605438232%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6580, training loss Total= 0.037628617, training acc total= 98.73605966567993%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6590, training loss Total= 0.03757238, training acc total= 98.58735799789429%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6600, training loss Total= 0.037302203, training acc total= 98.73605966567993%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6610, training loss Total= 0.03721019, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6620, training loss Total= 0.03707335, training acc total= 98.76084327697754%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6630, training loss Total= 0.036954306, training acc total= 98.73605966567993%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6640, training loss Total= 0.037075598, training acc total= 98.66170883178711%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6650, training loss Total= 0.03675737, training acc total= 98.76084327697754%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6660, training loss Total= 0.036682427, training acc total= 98.76084327697754%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6670, training loss Total= 0.036552817, training acc total= 98.73605966567993%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6680, training loss Total= 0.036340218, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6690, training loss Total= 0.036240276, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6700, training loss Total= 0.036249142, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6710, training loss Total= 0.036244757, training acc total= 98.76084327697754%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6720, training loss Total= 0.036058456, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6730, training loss Total= 0.03577629, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6740, training loss Total= 0.035646435, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6750, training loss Total= 0.035593554, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6760, training loss Total= 0.03544205, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6770, training loss Total= 0.035330854, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6780, training loss Total= 0.035237648, training acc total= 98.83519411087036%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6790, training loss Total= 0.03527887, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6800, training loss Total= 0.03517752, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6810, training loss Total= 0.034998074, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6820, training loss Total= 0.034790777, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6830, training loss Total= 0.034796573, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6840, training loss Total= 0.03457786, training acc total= 98.78562688827515%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6850, training loss Total= 0.034451444, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6860, training loss Total= 0.034309387, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6870, training loss Total= 0.03418517, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6880, training loss Total= 0.034090705, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6890, training loss Total= 0.033947233, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6900, training loss Total= 0.03385825, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.5 %\n",
            "step 6910, training loss Total= 0.033725034, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6920, training loss Total= 0.033643033, training acc total= 98.81041049957275%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6930, training loss Total= 0.033525717, training acc total= 98.93432259559631%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6940, training loss Total= 0.033437274, training acc total= 98.9095389842987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6950, training loss Total= 0.033335134, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6960, training loss Total= 0.033165984, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6970, training loss Total= 0.03316774, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6980, training loss Total= 0.032984152, training acc total= 98.9095389842987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 6990, training loss Total= 0.032920223, training acc total= 98.93432259559631%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7000, training loss Total= 0.03276096, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7010, training loss Total= 0.032639254, training acc total= 98.93432259559631%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7020, training loss Total= 0.03255493, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7030, training loss Total= 0.032679155, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7040, training loss Total= 0.032424826, training acc total= 98.88476133346558%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7050, training loss Total= 0.032229964, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7060, training loss Total= 0.032264963, training acc total= 98.85997772216797%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7070, training loss Total= 0.03205426, training acc total= 98.9095389842987%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7080, training loss Total= 0.03195008, training acc total= 98.9095389842987%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7090, training loss Total= 0.031848017, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7100, training loss Total= 0.031981785, training acc total= 98.93432259559631%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7110, training loss Total= 0.031561516, training acc total= 99.00867342948914%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7120, training loss Total= 0.031448457, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7130, training loss Total= 0.031379953, training acc total= 99.03345704078674%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7140, training loss Total= 0.031207835, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7150, training loss Total= 0.031095732, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7160, training loss Total= 0.030992355, training acc total= 99.00867342948914%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7170, training loss Total= 0.031068088, training acc total= 99.05824065208435%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7180, training loss Total= 0.030752838, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7190, training loss Total= 0.030725576, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7200, training loss Total= 0.03060492, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7210, training loss Total= 0.030534253, training acc total= 99.03345704078674%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7220, training loss Total= 0.030339722, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7230, training loss Total= 0.030351903, training acc total= 99.03345704078674%\n",
            "ValidTest acc= 88.5 %\n",
            "step 7240, training loss Total= 0.030265767, training acc total= 99.10780787467957%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7250, training loss Total= 0.030022986, training acc total= 98.95910620689392%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7260, training loss Total= 0.02994471, training acc total= 99.00867342948914%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7270, training loss Total= 0.029829422, training acc total= 99.00867342948914%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7280, training loss Total= 0.02973734, training acc total= 99.03345704078674%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7290, training loss Total= 0.029615525, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7300, training loss Total= 0.02949917, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7310, training loss Total= 0.02957651, training acc total= 99.13259148597717%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7320, training loss Total= 0.029288448, training acc total= 99.00867342948914%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7330, training loss Total= 0.029189758, training acc total= 98.98388981819153%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7340, training loss Total= 0.029116988, training acc total= 99.08302426338196%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7350, training loss Total= 0.028963907, training acc total= 99.00867342948914%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7360, training loss Total= 0.028875044, training acc total= 99.05824065208435%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7370, training loss Total= 0.028761169, training acc total= 99.10780787467957%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7380, training loss Total= 0.028716125, training acc total= 99.08302426338196%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7390, training loss Total= 0.028588325, training acc total= 99.03345704078674%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7400, training loss Total= 0.028513005, training acc total= 99.10780787467957%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7410, training loss Total= 0.02838191, training acc total= 99.15737509727478%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7420, training loss Total= 0.028271193, training acc total= 99.08302426338196%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7430, training loss Total= 0.028209556, training acc total= 99.05824065208435%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7440, training loss Total= 0.028078632, training acc total= 99.10780787467957%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7450, training loss Total= 0.028035626, training acc total= 99.13259148597717%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7460, training loss Total= 0.027951315, training acc total= 99.18215870857239%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7470, training loss Total= 0.027778232, training acc total= 99.13259148597717%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7480, training loss Total= 0.027777264, training acc total= 99.10780787467957%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7490, training loss Total= 0.027604336, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7500, training loss Total= 0.027555931, training acc total= 99.18215870857239%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7510, training loss Total= 0.027465232, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 88.75 %\n",
            "step 7520, training loss Total= 0.027346551, training acc total= 99.10780787467957%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7530, training loss Total= 0.027199656, training acc total= 99.08302426338196%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7540, training loss Total= 0.027132487, training acc total= 99.15737509727478%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7550, training loss Total= 0.027013497, training acc total= 99.13259148597717%\n",
            "ValidTest acc= 89.5 %\n",
            "step 7560, training loss Total= 0.026929991, training acc total= 99.18215870857239%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7570, training loss Total= 0.026823165, training acc total= 99.13259148597717%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7580, training loss Total= 0.02675921, training acc total= 99.25650358200073%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7590, training loss Total= 0.026618304, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7600, training loss Total= 0.026675563, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7610, training loss Total= 0.02646177, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7620, training loss Total= 0.026350964, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7630, training loss Total= 0.026290212, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7640, training loss Total= 0.026146756, training acc total= 99.30607080459595%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7650, training loss Total= 0.026055407, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7660, training loss Total= 0.025945155, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7670, training loss Total= 0.02585512, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7680, training loss Total= 0.025773598, training acc total= 99.18215870857239%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7690, training loss Total= 0.02566383, training acc total= 99.15737509727478%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7700, training loss Total= 0.025572253, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7710, training loss Total= 0.02547206, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7720, training loss Total= 0.025413964, training acc total= 99.33085441589355%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7730, training loss Total= 0.025339106, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7740, training loss Total= 0.025230125, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7750, training loss Total= 0.025215574, training acc total= 99.30607080459595%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7760, training loss Total= 0.02503272, training acc total= 99.23171997070312%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7770, training loss Total= 0.02496913, training acc total= 99.28128719329834%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7780, training loss Total= 0.024869263, training acc total= 99.20693635940552%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7790, training loss Total= 0.024836482, training acc total= 99.25650358200073%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7800, training loss Total= 0.024686594, training acc total= 99.35563802719116%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7810, training loss Total= 0.024650194, training acc total= 99.35563802719116%\n",
            "ValidTest acc= 88.75 %\n",
            "step 7820, training loss Total= 0.024677744, training acc total= 99.35563802719116%\n",
            "ValidTest acc= 88.75 %\n",
            "step 7830, training loss Total= 0.024408625, training acc total= 99.38042163848877%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7840, training loss Total= 0.024328226, training acc total= 99.38042163848877%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7850, training loss Total= 0.024266465, training acc total= 99.28128719329834%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7860, training loss Total= 0.024115242, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7870, training loss Total= 0.024130095, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7880, training loss Total= 0.023977444, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7890, training loss Total= 0.023857122, training acc total= 99.38042163848877%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7900, training loss Total= 0.023789497, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7910, training loss Total= 0.023702485, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7920, training loss Total= 0.023636606, training acc total= 99.38042163848877%\n",
            "ValidTest acc= 88.75 %\n",
            "step 7930, training loss Total= 0.023504224, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7940, training loss Total= 0.023439113, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7950, training loss Total= 0.02336536, training acc total= 99.40520524978638%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7960, training loss Total= 0.02325999, training acc total= 99.40520524978638%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7970, training loss Total= 0.02320197, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.25 %\n",
            "step 7980, training loss Total= 0.023132496, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 89.0 %\n",
            "step 7990, training loss Total= 0.023017514, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8000, training loss Total= 0.022973541, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8010, training loss Total= 0.022875218, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8020, training loss Total= 0.02272564, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8030, training loss Total= 0.022656208, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8040, training loss Total= 0.022614906, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8050, training loss Total= 0.02253953, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8060, training loss Total= 0.022585418, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8070, training loss Total= 0.022340776, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8080, training loss Total= 0.02236001, training acc total= 99.40520524978638%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8090, training loss Total= 0.022189781, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8100, training loss Total= 0.02225889, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8110, training loss Total= 0.022033464, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8120, training loss Total= 0.02202591, training acc total= 99.45477247238159%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8130, training loss Total= 0.02185483, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8140, training loss Total= 0.02217684, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8150, training loss Total= 0.031610962, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8160, training loss Total= 0.031394057, training acc total= 99.30607080459595%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8170, training loss Total= 0.023971455, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8180, training loss Total= 0.022679375, training acc total= 99.42998886108398%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8190, training loss Total= 0.02212132, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8200, training loss Total= 0.0217688, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8210, training loss Total= 0.02161923, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8220, training loss Total= 0.021547075, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8230, training loss Total= 0.021465177, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8240, training loss Total= 0.021398114, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8250, training loss Total= 0.021389002, training acc total= 99.4795560836792%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8260, training loss Total= 0.021274202, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8270, training loss Total= 0.021208443, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8280, training loss Total= 0.021196587, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8290, training loss Total= 0.021114353, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8300, training loss Total= 0.021050192, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8310, training loss Total= 0.021038584, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8320, training loss Total= 0.020976415, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8330, training loss Total= 0.020909136, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8340, training loss Total= 0.020851832, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8350, training loss Total= 0.020838259, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8360, training loss Total= 0.02077578, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8370, training loss Total= 0.020772241, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8380, training loss Total= 0.020671878, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8390, training loss Total= 0.020620283, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8400, training loss Total= 0.020582043, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8410, training loss Total= 0.0205404, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 89.25 %\n",
            "step 8420, training loss Total= 0.020478394, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8430, training loss Total= 0.020445006, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8440, training loss Total= 0.0203985, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8450, training loss Total= 0.020329865, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8460, training loss Total= 0.020322917, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8470, training loss Total= 0.020247258, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8480, training loss Total= 0.020216035, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8490, training loss Total= 0.020148734, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8500, training loss Total= 0.02009628, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8510, training loss Total= 0.020066375, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8520, training loss Total= 0.020013273, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8530, training loss Total= 0.019969184, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8540, training loss Total= 0.019931788, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8550, training loss Total= 0.019877786, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8560, training loss Total= 0.019834744, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8570, training loss Total= 0.019776713, training acc total= 99.5043396949768%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8580, training loss Total= 0.019726872, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8590, training loss Total= 0.019696835, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8600, training loss Total= 0.01967689, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8610, training loss Total= 0.019629804, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8620, training loss Total= 0.019551752, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8630, training loss Total= 0.019497601, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8640, training loss Total= 0.019444723, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8650, training loss Total= 0.019409552, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8660, training loss Total= 0.019363567, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8670, training loss Total= 0.019330867, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8680, training loss Total= 0.019265769, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8690, training loss Total= 0.019221345, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8700, training loss Total= 0.01920508, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8710, training loss Total= 0.019124065, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 89.0 %\n",
            "step 8720, training loss Total= 0.019076683, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8730, training loss Total= 0.01902059, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8740, training loss Total= 0.018973356, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8750, training loss Total= 0.018934349, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8760, training loss Total= 0.018882902, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8770, training loss Total= 0.018842787, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8780, training loss Total= 0.018783078, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8790, training loss Total= 0.018760057, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8800, training loss Total= 0.018699335, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8810, training loss Total= 0.018656459, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8820, training loss Total= 0.018620588, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.0 %\n",
            "step 8830, training loss Total= 0.018560918, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8840, training loss Total= 0.018543338, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8850, training loss Total= 0.018484935, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8860, training loss Total= 0.018423505, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8870, training loss Total= 0.018385487, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8880, training loss Total= 0.018379465, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.0 %\n",
            "step 8890, training loss Total= 0.018279193, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.0 %\n",
            "step 8900, training loss Total= 0.018245209, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.0 %\n",
            "step 8910, training loss Total= 0.01820367, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.25 %\n",
            "step 8920, training loss Total= 0.018157726, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8930, training loss Total= 0.018111266, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8940, training loss Total= 0.018060047, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8950, training loss Total= 0.018020494, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.5 %\n",
            "step 8960, training loss Total= 0.018010538, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8970, training loss Total= 0.017930573, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8980, training loss Total= 0.017885286, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 8990, training loss Total= 0.017844621, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9000, training loss Total= 0.017801024, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9010, training loss Total= 0.017809747, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9020, training loss Total= 0.017794253, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9030, training loss Total= 0.017740885, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9040, training loss Total= 0.017634353, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9050, training loss Total= 0.017608318, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9060, training loss Total= 0.017558564, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9070, training loss Total= 0.017447773, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9080, training loss Total= 0.017404726, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9090, training loss Total= 0.017367097, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9100, training loss Total= 0.017313514, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9110, training loss Total= 0.017369442, training acc total= 99.52911734580994%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9120, training loss Total= 0.01727909, training acc total= 99.55390095710754%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9130, training loss Total= 0.01722925, training acc total= 99.57868456840515%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9140, training loss Total= 0.017123941, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9150, training loss Total= 0.017086567, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9160, training loss Total= 0.017039426, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9170, training loss Total= 0.017004045, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9180, training loss Total= 0.016983792, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9190, training loss Total= 0.01690021, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9200, training loss Total= 0.016845979, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9210, training loss Total= 0.016804503, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9220, training loss Total= 0.016762193, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9230, training loss Total= 0.016715638, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9240, training loss Total= 0.016665127, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9250, training loss Total= 0.01662482, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9260, training loss Total= 0.01656407, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9270, training loss Total= 0.01652288, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9280, training loss Total= 0.016545495, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9290, training loss Total= 0.01643932, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9300, training loss Total= 0.016380945, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9310, training loss Total= 0.016370792, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9320, training loss Total= 0.016295798, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9330, training loss Total= 0.016251279, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9340, training loss Total= 0.016197728, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9350, training loss Total= 0.016150055, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9360, training loss Total= 0.016116925, training acc total= 99.60346817970276%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9370, training loss Total= 0.016078373, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9380, training loss Total= 0.016021617, training acc total= 99.70260262489319%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9390, training loss Total= 0.015962902, training acc total= 99.70260262489319%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9400, training loss Total= 0.015937358, training acc total= 99.70260262489319%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9410, training loss Total= 0.01587503, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9420, training loss Total= 0.015844397, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9430, training loss Total= 0.015794614, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9440, training loss Total= 0.015746718, training acc total= 99.62825179100037%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9450, training loss Total= 0.015687045, training acc total= 99.70260262489319%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9460, training loss Total= 0.015643526, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9470, training loss Total= 0.015608077, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9480, training loss Total= 0.015583418, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9490, training loss Total= 0.015558433, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9500, training loss Total= 0.0154887345, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9510, training loss Total= 0.015424613, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9520, training loss Total= 0.015439098, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9530, training loss Total= 0.015394838, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9540, training loss Total= 0.015322384, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9550, training loss Total= 0.015231744, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9560, training loss Total= 0.015184883, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9570, training loss Total= 0.01515651, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9580, training loss Total= 0.015096219, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9590, training loss Total= 0.015055014, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9600, training loss Total= 0.015033878, training acc total= 99.77695345878601%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9610, training loss Total= 0.015000251, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9620, training loss Total= 0.014914739, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9630, training loss Total= 0.014893873, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9640, training loss Total= 0.014862587, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9650, training loss Total= 0.014795542, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9660, training loss Total= 0.014768073, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.75 %\n",
            "step 9670, training loss Total= 0.014701581, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9680, training loss Total= 0.01463129, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9690, training loss Total= 0.014623366, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9700, training loss Total= 0.014583611, training acc total= 99.67781901359558%\n",
            "ValidTest acc= 88.5 %\n",
            "step 9710, training loss Total= 0.014539029, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9720, training loss Total= 0.014518179, training acc total= 99.65303540229797%\n",
            "ValidTest acc= 87.75 %\n",
            "step 9730, training loss Total= 0.014440621, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9740, training loss Total= 0.014401537, training acc total= 99.70260262489319%\n",
            "ValidTest acc= 87.75 %\n",
            "step 9750, training loss Total= 0.014315384, training acc total= 99.77695345878601%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9760, training loss Total= 0.014279509, training acc total= 99.77695345878601%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9770, training loss Total= 0.014276638, training acc total= 99.7273862361908%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9780, training loss Total= 0.0142029645, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9790, training loss Total= 0.014253191, training acc total= 99.70260262489319%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9800, training loss Total= 0.01413168, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9810, training loss Total= 0.014063353, training acc total= 99.7521698474884%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9820, training loss Total= 0.014044035, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9830, training loss Total= 0.013960442, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9840, training loss Total= 0.013946897, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9850, training loss Total= 0.013875076, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9860, training loss Total= 0.01382764, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9870, training loss Total= 0.013793999, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9880, training loss Total= 0.01374563, training acc total= 99.77695345878601%\n",
            "ValidTest acc= 87.75 %\n",
            "step 9890, training loss Total= 0.013690491, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9900, training loss Total= 0.013657488, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.0 %\n",
            "step 9910, training loss Total= 0.013598988, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9920, training loss Total= 0.013569792, training acc total= 99.80173707008362%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9930, training loss Total= 0.013553066, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9940, training loss Total= 0.013457554, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9950, training loss Total= 0.01341163, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9960, training loss Total= 0.013377365, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9970, training loss Total= 0.013315644, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9980, training loss Total= 0.013284174, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 9990, training loss Total= 0.013229829, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10000, training loss Total= 0.013208015, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10010, training loss Total= 0.013154688, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10020, training loss Total= 0.013100332, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10030, training loss Total= 0.01306878, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10040, training loss Total= 0.013012666, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10050, training loss Total= 0.012976555, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10060, training loss Total= 0.012919875, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10070, training loss Total= 0.012910945, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10080, training loss Total= 0.012836264, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10090, training loss Total= 0.012796112, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10100, training loss Total= 0.012750539, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10110, training loss Total= 0.012698905, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10120, training loss Total= 0.012663884, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10130, training loss Total= 0.012684234, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10140, training loss Total= 0.012602565, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10150, training loss Total= 0.012573381, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10160, training loss Total= 0.01250756, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10170, training loss Total= 0.012500056, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10180, training loss Total= 0.012418803, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10190, training loss Total= 0.012371172, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10200, training loss Total= 0.012301963, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10210, training loss Total= 0.012267942, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10220, training loss Total= 0.012226683, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10230, training loss Total= 0.012207192, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.5 %\n",
            "step 10240, training loss Total= 0.012237025, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.5 %\n",
            "step 10250, training loss Total= 0.012107184, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.5 %\n",
            "step 10260, training loss Total= 0.012081674, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10270, training loss Total= 0.012012373, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10280, training loss Total= 0.012019726, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10290, training loss Total= 0.01200474, training acc total= 99.82652068138123%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10300, training loss Total= 0.011894167, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10310, training loss Total= 0.011890837, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10320, training loss Total= 0.011805732, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10330, training loss Total= 0.011756679, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10340, training loss Total= 0.011708349, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10350, training loss Total= 0.011663937, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10360, training loss Total= 0.0116300965, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10370, training loss Total= 0.011577107, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10380, training loss Total= 0.0115485, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10390, training loss Total= 0.011589267, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10400, training loss Total= 0.011503254, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10410, training loss Total= 0.011416829, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10420, training loss Total= 0.011381893, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10430, training loss Total= 0.011325906, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10440, training loss Total= 0.011286634, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10450, training loss Total= 0.011264188, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10460, training loss Total= 0.011223752, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10470, training loss Total= 0.011210822, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10480, training loss Total= 0.011157486, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10490, training loss Total= 0.011156954, training acc total= 99.85129833221436%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10500, training loss Total= 0.011058342, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10510, training loss Total= 0.0110221645, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10520, training loss Total= 0.010964036, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10530, training loss Total= 0.010949158, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10540, training loss Total= 0.010880246, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10550, training loss Total= 0.010889179, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10560, training loss Total= 0.010807159, training acc total= 99.87608194351196%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10570, training loss Total= 0.010770945, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10580, training loss Total= 0.010728847, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10590, training loss Total= 0.010676358, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10600, training loss Total= 0.01064431, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10610, training loss Total= 0.010660099, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10620, training loss Total= 0.010563229, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10630, training loss Total= 0.010537873, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10640, training loss Total= 0.010481274, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10650, training loss Total= 0.0104234265, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10660, training loss Total= 0.010406802, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10670, training loss Total= 0.010348878, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10680, training loss Total= 0.010298884, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10690, training loss Total= 0.010279352, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10700, training loss Total= 0.0102276895, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10710, training loss Total= 0.010188325, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10720, training loss Total= 0.010269481, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10730, training loss Total= 0.010126102, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10740, training loss Total= 0.010077888, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10750, training loss Total= 0.010068692, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10760, training loss Total= 0.010001309, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10770, training loss Total= 0.009951802, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10780, training loss Total= 0.009913895, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10790, training loss Total= 0.009871234, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10800, training loss Total= 0.009829509, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10810, training loss Total= 0.009815401, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10820, training loss Total= 0.009750099, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10830, training loss Total= 0.009705834, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10840, training loss Total= 0.009665894, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10850, training loss Total= 0.009616444, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10860, training loss Total= 0.009647498, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10870, training loss Total= 0.00956189, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10880, training loss Total= 0.009526925, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10890, training loss Total= 0.009474959, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10900, training loss Total= 0.00943153, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10910, training loss Total= 0.009392859, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10920, training loss Total= 0.009374216, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10930, training loss Total= 0.009310488, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10940, training loss Total= 0.009281997, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10950, training loss Total= 0.009243672, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 87.75 %\n",
            "step 10960, training loss Total= 0.00920696, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 88.0 %\n",
            "step 10970, training loss Total= 0.009158865, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 88.25 %\n",
            "step 10980, training loss Total= 0.009124919, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 87.5 %\n",
            "step 10990, training loss Total= 0.0091071185, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11000, training loss Total= 0.009064428, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11010, training loss Total= 0.009076431, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11020, training loss Total= 0.008979281, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 88.25 %\n",
            "step 11030, training loss Total= 0.008949279, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 88.25 %\n",
            "step 11040, training loss Total= 0.008950553, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11050, training loss Total= 0.00895163, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11060, training loss Total= 0.008845997, training acc total= 99.92564916610718%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11070, training loss Total= 0.008805397, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11080, training loss Total= 0.008790797, training acc total= 99.95043277740479%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11090, training loss Total= 0.008773419, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11100, training loss Total= 0.008698686, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11110, training loss Total= 0.009004462, training acc total= 99.90086555480957%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11120, training loss Total= 0.008767531, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11130, training loss Total= 0.008590756, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11140, training loss Total= 0.008553511, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11150, training loss Total= 0.008504926, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.25 %\n",
            "step 11160, training loss Total= 0.008476345, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11170, training loss Total= 0.008453995, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11180, training loss Total= 0.008433922, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11190, training loss Total= 0.00837978, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11200, training loss Total= 0.008366666, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11210, training loss Total= 0.008378608, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11220, training loss Total= 0.00826769, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11230, training loss Total= 0.008235306, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11240, training loss Total= 0.0082980255, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11250, training loss Total= 0.008172833, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11260, training loss Total= 0.008151677, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11270, training loss Total= 0.008097487, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11280, training loss Total= 0.008193342, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11290, training loss Total= 0.008071429, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.25 %\n",
            "step 11300, training loss Total= 0.008004508, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11310, training loss Total= 0.008002326, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11320, training loss Total= 0.007934346, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11330, training loss Total= 0.007908263, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11340, training loss Total= 0.007885819, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11350, training loss Total= 0.007892526, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11360, training loss Total= 0.007818575, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11370, training loss Total= 0.007790838, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11380, training loss Total= 0.007751885, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11390, training loss Total= 0.0077427914, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11400, training loss Total= 0.007685108, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11410, training loss Total= 0.007661436, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11420, training loss Total= 0.007627772, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11430, training loss Total= 0.007581082, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11440, training loss Total= 0.007564907, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11450, training loss Total= 0.0075382493, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11460, training loss Total= 0.0074957204, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11470, training loss Total= 0.007452659, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11480, training loss Total= 0.0074330526, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11490, training loss Total= 0.0073994193, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11500, training loss Total= 0.007369932, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11510, training loss Total= 0.0073352368, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11520, training loss Total= 0.0073231864, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11530, training loss Total= 0.00728166, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11540, training loss Total= 0.0072421147, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11550, training loss Total= 0.007223467, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11560, training loss Total= 0.007189457, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11570, training loss Total= 0.0071732397, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11580, training loss Total= 0.0071426565, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11590, training loss Total= 0.0070893224, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11600, training loss Total= 0.0071395147, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11610, training loss Total= 0.007054931, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11620, training loss Total= 0.0070248535, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11630, training loss Total= 0.0069846795, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11640, training loss Total= 0.0069502755, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11650, training loss Total= 0.006962588, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11660, training loss Total= 0.006887872, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11670, training loss Total= 0.006893383, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11680, training loss Total= 0.006826121, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11690, training loss Total= 0.0068024574, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11700, training loss Total= 0.0067604557, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 11710, training loss Total= 0.006744113, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11720, training loss Total= 0.006707433, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11730, training loss Total= 0.006668518, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11740, training loss Total= 0.006645416, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11750, training loss Total= 0.0066216076, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11760, training loss Total= 0.0066070645, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11770, training loss Total= 0.0065666246, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11780, training loss Total= 0.006603469, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11790, training loss Total= 0.0065375953, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11800, training loss Total= 0.006482292, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11810, training loss Total= 0.0064754817, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11820, training loss Total= 0.0064335433, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11830, training loss Total= 0.0064569046, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11840, training loss Total= 0.0064749173, training acc total= 99.97521638870239%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11850, training loss Total= 0.006335923, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11860, training loss Total= 0.0063655083, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11870, training loss Total= 0.0062867496, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11880, training loss Total= 0.0062699467, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11890, training loss Total= 0.0062795714, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11900, training loss Total= 0.006240297, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11910, training loss Total= 0.0061839786, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11920, training loss Total= 0.0061824913, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11930, training loss Total= 0.0061364872, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11940, training loss Total= 0.006128731, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11950, training loss Total= 0.0060809194, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11960, training loss Total= 0.006103963, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 11970, training loss Total= 0.0060217017, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11980, training loss Total= 0.0059928684, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 11990, training loss Total= 0.005970872, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12000, training loss Total= 0.0059726755, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12010, training loss Total= 0.005917091, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12020, training loss Total= 0.00592046, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12030, training loss Total= 0.0058705998, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12040, training loss Total= 0.005841587, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12050, training loss Total= 0.0058161053, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12060, training loss Total= 0.005795636, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12070, training loss Total= 0.0057907896, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12080, training loss Total= 0.0057366677, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12090, training loss Total= 0.005729784, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12100, training loss Total= 0.0057206335, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12110, training loss Total= 0.005663789, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12120, training loss Total= 0.005637416, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12130, training loss Total= 0.0056371186, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12140, training loss Total= 0.0055927373, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12150, training loss Total= 0.0055858158, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12160, training loss Total= 0.005541777, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12170, training loss Total= 0.0055171745, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12180, training loss Total= 0.005502902, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12190, training loss Total= 0.005488503, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12200, training loss Total= 0.0054819216, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12210, training loss Total= 0.0054365555, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12220, training loss Total= 0.0054050656, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12230, training loss Total= 0.0053772237, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12240, training loss Total= 0.0053613884, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12250, training loss Total= 0.0053467085, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12260, training loss Total= 0.0053347657, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12270, training loss Total= 0.005312178, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12280, training loss Total= 0.0052831275, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12290, training loss Total= 0.0052322065, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12300, training loss Total= 0.0052452744, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12310, training loss Total= 0.00520346, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12320, training loss Total= 0.0051757847, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12330, training loss Total= 0.0051449323, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12340, training loss Total= 0.0051776767, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12350, training loss Total= 0.0051108547, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12360, training loss Total= 0.0050770664, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12370, training loss Total= 0.005055632, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12380, training loss Total= 0.0050732805, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12390, training loss Total= 0.005020024, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12400, training loss Total= 0.004997791, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12410, training loss Total= 0.0049643395, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12420, training loss Total= 0.0049517793, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12430, training loss Total= 0.004945717, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12440, training loss Total= 0.004908678, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12450, training loss Total= 0.0048878654, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12460, training loss Total= 0.004873425, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12470, training loss Total= 0.004848022, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12480, training loss Total= 0.0048236595, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12490, training loss Total= 0.0047976077, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12500, training loss Total= 0.004790743, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12510, training loss Total= 0.004750485, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12520, training loss Total= 0.004734974, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12530, training loss Total= 0.004715045, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12540, training loss Total= 0.0046844603, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12550, training loss Total= 0.0046711247, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12560, training loss Total= 0.0046597887, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12570, training loss Total= 0.0046502217, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12580, training loss Total= 0.004613922, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12590, training loss Total= 0.004583571, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12600, training loss Total= 0.0045679365, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12610, training loss Total= 0.00454837, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12620, training loss Total= 0.0045229425, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12630, training loss Total= 0.004557058, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12640, training loss Total= 0.0045007127, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12650, training loss Total= 0.0044683698, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12660, training loss Total= 0.0044455663, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12670, training loss Total= 0.0044289567, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12680, training loss Total= 0.0044160113, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12690, training loss Total= 0.0043853763, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12700, training loss Total= 0.0043649506, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12710, training loss Total= 0.0043525333, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12720, training loss Total= 0.004326977, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12730, training loss Total= 0.0043137292, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12740, training loss Total= 0.004351678, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12750, training loss Total= 0.004306042, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12760, training loss Total= 0.004257625, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12770, training loss Total= 0.004241837, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12780, training loss Total= 0.0042189416, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12790, training loss Total= 0.004184617, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12800, training loss Total= 0.0041806675, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12810, training loss Total= 0.004158221, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 12820, training loss Total= 0.004133487, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12830, training loss Total= 0.0041103233, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12840, training loss Total= 0.0040920274, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12850, training loss Total= 0.0040946333, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12860, training loss Total= 0.0040594083, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12870, training loss Total= 0.0040850127, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12880, training loss Total= 0.0040568993, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 12890, training loss Total= 0.003999346, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12900, training loss Total= 0.004007502, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12910, training loss Total= 0.00395671, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12920, training loss Total= 0.003937938, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12930, training loss Total= 0.0039239787, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12940, training loss Total= 0.003913043, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12950, training loss Total= 0.003892214, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12960, training loss Total= 0.0038683738, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12970, training loss Total= 0.003854244, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 12980, training loss Total= 0.0038557167, training acc total= 100.0%\n",
            "ValidTest acc= 88.25 %\n",
            "step 12990, training loss Total= 0.0038172668, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13000, training loss Total= 0.003804149, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13010, training loss Total= 0.0038086642, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13020, training loss Total= 0.0037700292, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13030, training loss Total= 0.0037884184, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 13040, training loss Total= 0.0037358757, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13050, training loss Total= 0.0037070054, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13060, training loss Total= 0.003695844, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13070, training loss Total= 0.0036893862, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13080, training loss Total= 0.0036589927, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13090, training loss Total= 0.003641583, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13100, training loss Total= 0.0036280162, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13110, training loss Total= 0.0036170932, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13120, training loss Total= 0.0035937494, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13130, training loss Total= 0.003574708, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13140, training loss Total= 0.0035701282, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13150, training loss Total= 0.0035542923, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13160, training loss Total= 0.0035408735, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13170, training loss Total= 0.0035275575, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13180, training loss Total= 0.0034984367, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13190, training loss Total= 0.0035119434, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13200, training loss Total= 0.003473771, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13210, training loss Total= 0.0034525227, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13220, training loss Total= 0.0034463569, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13230, training loss Total= 0.003412544, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13240, training loss Total= 0.0034035987, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13250, training loss Total= 0.0033861548, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13260, training loss Total= 0.0033884288, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13270, training loss Total= 0.0033518923, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13280, training loss Total= 0.0033390475, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13290, training loss Total= 0.0034401922, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13300, training loss Total= 0.0033141829, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13310, training loss Total= 0.003335679, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13320, training loss Total= 0.003315341, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13330, training loss Total= 0.0032774836, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13340, training loss Total= 0.0032420831, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13350, training loss Total= 0.003257149, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13360, training loss Total= 0.0032353792, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13370, training loss Total= 0.0032089222, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13380, training loss Total= 0.0031930306, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13390, training loss Total= 0.003168431, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13400, training loss Total= 0.0031864208, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13410, training loss Total= 0.0031410118, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13420, training loss Total= 0.003125039, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13430, training loss Total= 0.0031094858, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13440, training loss Total= 0.0030957928, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13450, training loss Total= 0.0030914512, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13460, training loss Total= 0.003067333, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13470, training loss Total= 0.0030560938, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13480, training loss Total= 0.0030408448, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13490, training loss Total= 0.0030219392, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13500, training loss Total= 0.0030152944, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13510, training loss Total= 0.0030232067, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13520, training loss Total= 0.0029780122, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13530, training loss Total= 0.0029667902, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13540, training loss Total= 0.0029623793, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13550, training loss Total= 0.0029677786, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13560, training loss Total= 0.0029402727, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13570, training loss Total= 0.0029122466, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13580, training loss Total= 0.002912161, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13590, training loss Total= 0.0029006305, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13600, training loss Total= 0.0028884988, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13610, training loss Total= 0.0028665082, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "step 13620, training loss Total= 0.0028737714, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13630, training loss Total= 0.0028535144, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13640, training loss Total= 0.0029086687, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13650, training loss Total= 0.002818345, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13660, training loss Total= 0.0027950788, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13670, training loss Total= 0.0027868967, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13680, training loss Total= 0.0027750342, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13690, training loss Total= 0.0027580431, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13700, training loss Total= 0.0027391124, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13710, training loss Total= 0.0027296424, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13720, training loss Total= 0.002796598, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13730, training loss Total= 0.0026998443, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13740, training loss Total= 0.0026979938, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13750, training loss Total= 0.0026838996, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13760, training loss Total= 0.0026655626, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13770, training loss Total= 0.0026625672, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13780, training loss Total= 0.0026420036, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13790, training loss Total= 0.0026369414, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13800, training loss Total= 0.0026193033, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13810, training loss Total= 0.0026021702, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13820, training loss Total= 0.0025888716, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13830, training loss Total= 0.0025849554, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13840, training loss Total= 0.0025820753, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13850, training loss Total= 0.002575704, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13860, training loss Total= 0.0025618356, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13870, training loss Total= 0.0025279857, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13880, training loss Total= 0.002529411, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13890, training loss Total= 0.002507311, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13900, training loss Total= 0.002496772, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 13910, training loss Total= 0.0024824424, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13920, training loss Total= 0.002489871, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13930, training loss Total= 0.002455772, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13940, training loss Total= 0.0024470265, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13950, training loss Total= 0.0024310846, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13960, training loss Total= 0.0024242015, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13970, training loss Total= 0.0024293398, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13980, training loss Total= 0.0024278436, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 13990, training loss Total= 0.0023907376, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14000, training loss Total= 0.0023833946, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14010, training loss Total= 0.0023666194, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14020, training loss Total= 0.0023558764, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14030, training loss Total= 0.0023546373, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14040, training loss Total= 0.0023577947, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14050, training loss Total= 0.0023269518, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14060, training loss Total= 0.0023125636, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14070, training loss Total= 0.002309131, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14080, training loss Total= 0.0022883948, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14090, training loss Total= 0.0022794947, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14100, training loss Total= 0.0022772874, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14110, training loss Total= 0.002260036, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14120, training loss Total= 0.002265452, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14130, training loss Total= 0.002258574, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14140, training loss Total= 0.0022463803, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14150, training loss Total= 0.0022175654, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14160, training loss Total= 0.002208834, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14170, training loss Total= 0.0022062925, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14180, training loss Total= 0.0021887997, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14190, training loss Total= 0.0021763744, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14200, training loss Total= 0.0021706328, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14210, training loss Total= 0.00215708, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14220, training loss Total= 0.0021442024, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14230, training loss Total= 0.0021363813, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14240, training loss Total= 0.0021556611, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14250, training loss Total= 0.0021124203, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14260, training loss Total= 0.0021251983, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14270, training loss Total= 0.0020954977, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14280, training loss Total= 0.0020829905, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14290, training loss Total= 0.0020813707, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14300, training loss Total= 0.0020682847, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14310, training loss Total= 0.0020532866, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14320, training loss Total= 0.0020468293, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14330, training loss Total= 0.0020633552, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14340, training loss Total= 0.0020361505, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14350, training loss Total= 0.0020219358, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14360, training loss Total= 0.0020058926, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14370, training loss Total= 0.0019988148, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14380, training loss Total= 0.0019883565, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14390, training loss Total= 0.0019835837, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14400, training loss Total= 0.0019749405, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14410, training loss Total= 0.0020093045, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14420, training loss Total= 0.0019538023, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14430, training loss Total= 0.0019398784, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14440, training loss Total= 0.001957387, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14450, training loss Total= 0.001924047, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14460, training loss Total= 0.0019349187, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14470, training loss Total= 0.0019115617, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14480, training loss Total= 0.0018952339, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14490, training loss Total= 0.0018857778, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14500, training loss Total= 0.001883281, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14510, training loss Total= 0.0018782201, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14520, training loss Total= 0.0018624413, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14530, training loss Total= 0.0018793641, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14540, training loss Total= 0.0018462493, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14550, training loss Total= 0.0018294137, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14560, training loss Total= 0.001837578, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14570, training loss Total= 0.001824314, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14580, training loss Total= 0.0018119437, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14590, training loss Total= 0.0018015981, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14600, training loss Total= 0.0017997504, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14610, training loss Total= 0.00178306, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14620, training loss Total= 0.0017724946, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14630, training loss Total= 0.0017651145, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14640, training loss Total= 0.0017566517, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14650, training loss Total= 0.0017476107, training acc total= 100.0%\n",
            "ValidTest acc= 88.0 %\n",
            "step 14660, training loss Total= 0.0017419036, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14670, training loss Total= 0.0017402067, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14680, training loss Total= 0.0017300769, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14690, training loss Total= 0.0017192542, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14700, training loss Total= 0.0017095365, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14710, training loss Total= 0.001708563, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14720, training loss Total= 0.0016931893, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14730, training loss Total= 0.0016855618, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14740, training loss Total= 0.0016848918, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14750, training loss Total= 0.0016854659, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14760, training loss Total= 0.0016649979, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14770, training loss Total= 0.0016549573, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14780, training loss Total= 0.0016466872, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14790, training loss Total= 0.0016343964, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14800, training loss Total= 0.0016275614, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14810, training loss Total= 0.0016243355, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14820, training loss Total= 0.0016284747, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14830, training loss Total= 0.0016121523, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14840, training loss Total= 0.0015970801, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14850, training loss Total= 0.0015965292, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14860, training loss Total= 0.0015813246, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14870, training loss Total= 0.0015762477, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14880, training loss Total= 0.001567152, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14890, training loss Total= 0.0015686405, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14900, training loss Total= 0.0015649807, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14910, training loss Total= 0.0015452267, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14920, training loss Total= 0.001536245, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14930, training loss Total= 0.0015327373, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14940, training loss Total= 0.0015272768, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14950, training loss Total= 0.0015177685, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14960, training loss Total= 0.0015132962, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14970, training loss Total= 0.0015093539, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14980, training loss Total= 0.0015074707, training acc total= 100.0%\n",
            "ValidTest acc= 87.75 %\n",
            "step 14990, training loss Total= 0.0014892156, training acc total= 100.0%\n",
            "ValidTest acc= 87.5 %\n",
            "ValidValid acc= 98.5725 %\n",
            "ValidTest acc= 87.75 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cO8q3Sy3RYLu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zRQmYnh5RYGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W3H5QPD2RYD4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 50\n",
        "aside_valid_test = train_valid_combined_shuffled[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot_shuffled[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined_shuffled[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot_shuffled[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "coOs604YS_Tl",
        "colab_type": "code",
        "outputId": "1fa8b1a6-8845-4b3a-9582-5ff08c284b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(aside_valid_test_label,axis = 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([14.,  0.,  3.,  0., 10.,  0.,  4.,  0., 12.,  7.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ut9Qmd6jRYBE",
        "colab_type": "code",
        "outputId": "d8fc6d29-2a7d-4aa5-e67a-5c47c07df9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "cell_type": "code",
      "source": [
        "## Building the graph - Best!\n",
        "saver = tf.train.Saver()\n",
        "hid_neuron = [104]\n",
        "num_steps = 6340\n",
        "# num_steps = 20000\n",
        "\n",
        "# batch_size = 200\n",
        "batch_size = train_data.shape[0]\n",
        "\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "plot_every = 500\n",
        "best_accuracy_valid\n",
        "learning_rate = 0.001\n",
        "track_step = []\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "\n",
        "\n",
        "\n",
        "wLoss1 = 6\n",
        "wLoss2 = 2\n",
        "wLoss3 = 0\n",
        "loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "### Initialization and running the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    best_accuracy_valid = 0\n",
        "    for step in range(0, num_steps):\n",
        "        if (step>6000):\n",
        "          plot_every = 10\n",
        "        batch_x, batch_y = next_batch(batch_size, combined_train_valid, combined_train_valid_label)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "        if step % plot_every == 0:\n",
        "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "#             train_accuracy.append(train_acc)\n",
        "#             print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "            track_step.append(step)\n",
        "            train_loss_total, train_acc_total = sess.run([loss, accuracy], feed_dict={X: combined_train_valid,Y: combined_train_valid_label})\n",
        "            train_accuracy.append(train_acc_total)\n",
        "            train_losses.append(train_loss_total)\n",
        "            print(\"step \" + str(step) + \", training loss Total= \" + str(train_loss_total) +\", training acc total= \"+str(train_acc_total*100)+\"%\")\n",
        "            validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "            print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "#             if step%plot_every == 0:\n",
        "#               if (validationTest_accuracy >= best_accuracy_valid):\n",
        "#                 best_accuracy_valid = validation_accuracy\n",
        "\n",
        "#         if(train_loss_total<0.033881765):\n",
        "#           break\n",
        "    saver.save(sess, './statlog_letterAdam2')\n",
        "    G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])                                     \n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: validation_data,Y:validation_label_one_hot})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    \n",
        "    validationTest_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidTest acc=\",str(validationTest_accuracy), \"%\")\n",
        "    this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "    W_track.append(this_params)\n",
        "#     saver.save(sess, './statlog_letterAdam')\n",
        "    print(\"=\"*50)\n",
        "    print(\"W1\")\n",
        "    print(wLoss1)\n",
        "\n",
        "    print(\"W2\")\n",
        "    print(wLoss2)\n",
        "    print(\"*\"*50)\n",
        "    \n",
        "    print(\"=\"*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, training loss Total= 2.2155166, training acc total= 9.395667165517807%\n",
            "ValidTest acc= 8.0 %\n",
            "step 500, training loss Total= 0.29402617, training acc total= 87.0467483997345%\n",
            "ValidTest acc= 78.0 %\n",
            "step 1000, training loss Total= 0.2238727, training acc total= 89.80615735054016%\n",
            "ValidTest acc= 80.0 %\n",
            "step 1500, training loss Total= 0.18729344, training acc total= 91.4709210395813%\n",
            "ValidTest acc= 82.0 %\n",
            "step 2000, training loss Total= 0.16092114, training acc total= 92.45153665542603%\n",
            "ValidTest acc= 84.0 %\n",
            "step 2500, training loss Total= 0.14030409, training acc total= 93.40934753417969%\n",
            "ValidTest acc= 84.0 %\n",
            "step 3000, training loss Total= 0.12369603, training acc total= 94.00228261947632%\n",
            "ValidTest acc= 84.0 %\n",
            "step 3500, training loss Total= 0.10983165, training acc total= 94.86886858940125%\n",
            "ValidTest acc= 84.0 %\n",
            "step 4000, training loss Total= 0.096315205, training acc total= 95.73546051979065%\n",
            "ValidTest acc= 84.0 %\n",
            "step 4500, training loss Total= 0.08433506, training acc total= 96.23717069625854%\n",
            "ValidTest acc= 84.0 %\n",
            "step 5000, training loss Total= 0.073204115, training acc total= 96.89851999282837%\n",
            "ValidTest acc= 88.0 %\n",
            "step 5500, training loss Total= 0.063110076, training acc total= 97.33181595802307%\n",
            "ValidTest acc= 86.0 %\n",
            "step 6000, training loss Total= 0.05448688, training acc total= 97.78791069984436%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6010, training loss Total= 0.054267418, training acc total= 97.81071543693542%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6020, training loss Total= 0.054094613, training acc total= 97.78791069984436%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6030, training loss Total= 0.053975828, training acc total= 97.78791069984436%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6040, training loss Total= 0.053820867, training acc total= 97.74230122566223%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6050, training loss Total= 0.05373668, training acc total= 97.78791069984436%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6060, training loss Total= 0.05354935, training acc total= 97.81071543693542%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6070, training loss Total= 0.053522248, training acc total= 97.78791069984436%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6080, training loss Total= 0.05326828, training acc total= 97.83352613449097%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6090, training loss Total= 0.053042904, training acc total= 97.83352613449097%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6100, training loss Total= 0.05286475, training acc total= 97.83352613449097%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6110, training loss Total= 0.052877087, training acc total= 97.7651059627533%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6120, training loss Total= 0.052664343, training acc total= 97.83352613449097%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6130, training loss Total= 0.052455537, training acc total= 97.85633087158203%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6140, training loss Total= 0.052261416, training acc total= 97.8791356086731%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6150, training loss Total= 0.05222993, training acc total= 97.83352613449097%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6160, training loss Total= 0.051955152, training acc total= 97.90194034576416%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6170, training loss Total= 0.051811144, training acc total= 97.85633087158203%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6180, training loss Total= 0.051668115, training acc total= 97.90194034576416%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6190, training loss Total= 0.05142165, training acc total= 97.85633087158203%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6200, training loss Total= 0.051675063, training acc total= 97.83352613449097%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6210, training loss Total= 0.05143037, training acc total= 97.85633087158203%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6220, training loss Total= 0.0511086, training acc total= 97.92474508285522%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6230, training loss Total= 0.050926372, training acc total= 97.85633087158203%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6240, training loss Total= 0.050668508, training acc total= 97.99315929412842%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6250, training loss Total= 0.050525274, training acc total= 97.92474508285522%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6260, training loss Total= 0.050354365, training acc total= 97.97035455703735%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6270, training loss Total= 0.05026531, training acc total= 97.90194034576416%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6280, training loss Total= 0.050215885, training acc total= 97.92474508285522%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6290, training loss Total= 0.0500265, training acc total= 97.94754981994629%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6300, training loss Total= 0.04983576, training acc total= 97.92474508285522%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6310, training loss Total= 0.049765542, training acc total= 98.01596403121948%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6320, training loss Total= 0.049560554, training acc total= 97.94754981994629%\n",
            "ValidTest acc= 84.0 %\n",
            "step 6330, training loss Total= 0.04937941, training acc total= 97.97035455703735%\n",
            "ValidTest acc= 84.0 %\n",
            "ValidValid acc= 97.295265 %\n",
            "ValidTest acc= 84.0 %\n",
            "==================================================\n",
            "W1\n",
            "6\n",
            "W2\n",
            "2\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EYKj7Vip6leQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVO2RTmQ4tYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "je7OjX3E6eHo",
        "colab_type": "code",
        "outputId": "dce7f3cd-d320-440b-e9b0-dd7f0e6a2ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    validationValid_accuracy = sess.run(accuracy*100, feed_dict={X: aside_valid_test,Y:aside_valid_test_label})\n",
        "    print(\"ValidValid acc=\",str(validationValid_accuracy), \"%\")\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={X: test_data,Y:test_label_one_hot})\n",
        "    print(\"Test acc=\",str(test_accuracy), \"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./statlog_letterAdam2\n",
            "ValidValid acc= 84.0 %\n",
            "Test acc= 90.35 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lwsn__mE6eHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "y4u4i4HzTxZI"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning by splitting valid into two sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iS2Vm-EOx1az",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# contd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Qq4-Y2IRx1Nl",
        "outputId": "32429ab1-8010-4abb-8380-4d22bd573711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(valid_validation_data.shape)\n",
        "print(valid_test_data.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 36)\n",
            "(331, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4ZTEAcHAT1nX",
        "outputId": "3d90a844-ae23-4630-95b3-fb991ba7efb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555835
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## Building the graph\n",
        "# saver = tf.train.Saver()\n",
        "# hid_neuron = [90]\n",
        "num_steps = 30000\n",
        "batch_size = 200\n",
        "train_losses = []\n",
        "test_acc = []\n",
        "plot_every = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "X = tf.placeholder(\"float\", [None, train_data.shape[1]])\n",
        "Y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "weights = {\n",
        "    'h1': tf.Variable(np.float32(clf.coefs_[0])),\n",
        "    'out': tf.Variable(np.float32(clf.coefs_[1]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(np.float32(clf.intercepts_ [0])),\n",
        "    'out': tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "}\n",
        "saver = tf.train.Saver()\n",
        "W_track = []\n",
        "ValidAccuracy_Track = []\n",
        "ValidAccuracy_Test_track = []\n",
        "def neural_net(x,train = True):\n",
        "    layer_outputs = []\n",
        "    layer_1 = tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    out_layer = tf.matmul(layer_1, G_W2) + G_b2\n",
        "    layer_outputs.append(out_layer)\n",
        "    for loop in range(0,2):        \n",
        "        layer1_feedback1 = tf.add(tf.matmul(out_layer, GwLoop), G_bLoop)\n",
        "        layer1_feedback1 = tf.nn.relu(layer1_feedback1)\n",
        "        layer1_feedback2 = tf.add(tf.matmul(layer1_feedback1, GwLoop2), G_bLoop2)\n",
        "        layer1_feedback2 = tf.nn.tanh(layer1_feedback2)\n",
        "        layer_1 = layer_1 + layer1_feedback2 + tf.add(tf.matmul(x, G_W1), G_b1)\n",
        "        out_layer = (tf.matmul(layer_1, G_W2) + G_b2) + tf.nn.tanh((tf.matmul(out_layer, GLossW) + GLossb))\n",
        "        layer_outputs.append(out_layer)\n",
        "    if train == True:\n",
        "        return layer_outputs\n",
        "    else:\n",
        "        return layer_outputs[0]\n",
        "    \n",
        "for wL1 in range(1,7):\n",
        "  for WL2 in range(1,wL1+1):\n",
        "    for WL3 in range(0,2):\n",
        "\n",
        "        wLoss1 = wL1\n",
        "        wLoss2 = WL2\n",
        "        wLoss3 = WL3\n",
        "        loss1 = wLoss1*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[0], labels=Y))\n",
        "        loss2 = wLoss2*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[1], labels=Y))\n",
        "        loss3 = wLoss3*tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=neural_net(X)[2], labels=Y))\n",
        "\n",
        "        loss = (loss1+loss2+loss3)/(wLoss1+ wLoss2 + wLoss3)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        correct_pred = tf.equal(tf.argmax(neural_net(X)[0], 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "        ### Initialization and running the model\n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            best_accuracy_valid = 0\n",
        "            for step in range(0, num_steps):\n",
        "                batch_x, batch_y = next_batch(batch_size, train_data, train_label_one_hot)\n",
        "                sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
        "                if step % plot_every == 0:\n",
        "                    train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
        "                    print(\"step \" + str(step) + \", training loss= \" + str(train_loss) +\", training acc= \"+str(train_acc*100)+\"%\")\n",
        "                    train_losses.append(train_loss)\n",
        "                    validation_accuracy = sess.run(accuracy*100, feed_dict={X: valid_validation_data,Y:valid_validation_data_label})\n",
        "                    if step%plot_every == 0:\n",
        "                      print(\"Validation Accuracy valid {} ...\".format(validation_accuracy))\n",
        "                      print()\n",
        "                      if (validation_accuracy >= best_accuracy_valid):\n",
        "                        best_accuracy_valid = validation_accuracy\n",
        "                        saver.save(sess, './statlog_letterAdam')\n",
        "                        G_W1np, G_b1np, G_W2np, G_b2np = sess.run([G_W1, G_b1, G_W2, G_b2])\n",
        "            print(\"Valid acc=\",str(best_accuracy_valid), \"%\")\n",
        "            ValidAccuracy_Track.append(best_accuracy_valid)\n",
        "            this_params = G_W1np, G_b1np, G_W2np, G_b2np\n",
        "            W_track.append(this_params)\n",
        "            # code for checking accuracy of valid_test\n",
        "            validation_test_accuracy = sess.run(accuracy*100, feed_dict={X: valid_test_data,Y:valid_test_data_label})\n",
        "            ValidAccuracy_Test_track.append(validation_test_accuracy)\n",
        "            print(\"Validation Accuracy Test {} ...\".format(validation_test_accuracy))\n",
        "            print(\"=\"*50)\n",
        "            print(\"W1 = {} ...\".format(wLoss1))\n",
        "            print(\"W2 = {} ...\".format(wLoss2))\n",
        "            print(\"W3 = {} ...\".format(wLoss3))\n",
        "\n",
        "            print(\"*\"*50)\n",
        "            print(\"=\"*50)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-29-c63b218ff97c>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "step 0, training loss= 1.3488517, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.08567171, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 200, training loss= 0.059998617, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.11387714, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.080282405, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.052642126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.08350072, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.076291084, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.062202986, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.05054958, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.041073233, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.048634496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.06623569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.0587347, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.039023057, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.04399723, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.06097916, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.04752657, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.037507687, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.057655215, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.04052432, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.05965087, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.038023047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.050358996, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.05275222, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.04501963, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.06819325, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.04590257, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.049204536, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.04582892, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.055396184, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.0341899, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.05727059, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3300, training loss= 0.03982147, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.026740802, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.044254337, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.02740402, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.03970208, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.034974243, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.04932213, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.03645609, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.028107757, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.027311573, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.034819923, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.043992244, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.04183163, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.025887255, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4700, training loss= 0.051782228, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.021722201, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.027863689, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.036249287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5100, training loss= 0.038888637, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.05285104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.044487614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5400, training loss= 0.0422064, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.033152927, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.042744156, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.025688127, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.034542847, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.018552845, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.037094936, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.030987242, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6200, training loss= 0.05576358, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.020571288, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.044858415, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.02865715, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.033970468, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.029146913, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.038941655, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.027594902, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.043006323, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.03386018, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.027714172, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.03111488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.025935289, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.033408187, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.021574307, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.033107538, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7800, training loss= 0.029582463, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.061377235, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.080219835, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8100, training loss= 0.038206533, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.020296745, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.03231915, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.027626805, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.025836239, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.023967328, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.023837274, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.033757914, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.020316573, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9000, training loss= 0.023294544, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.032979038, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.041029967, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.027940348, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.022629807, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9500, training loss= 0.022647915, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.03222277, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.023710163, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.019987235, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.026148546, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.038965926, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.01603636, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.014557231, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.027153568, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.020623963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.030736081, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.027655307, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.023770785, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10800, training loss= 0.03011191, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.029804822, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.03203321, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.025136866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.02857732, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.03126829, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.02826215, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.032816987, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.03346891, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.023110908, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.022924287, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.034020763, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.029728958, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.030279944, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12200, training loss= 0.023161886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.023094002, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.031383824, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.025598345, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.022756416, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.021968672, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.013227449, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.038004704, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.030708684, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.027204886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.0178302, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.02881734, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.023600392, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.03538281, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.024430636, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.025029968, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.024266666, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.022743044, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.020914154, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14100, training loss= 0.016040443, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.017043155, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.035448924, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 14400, training loss= 0.022903321, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.022325665, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.011945743, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.019753357, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.02080682, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.023782237, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15000, training loss= 0.020953692, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.015799185, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.019494986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15300, training loss= 0.01867202, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.017142352, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.017149255, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.027117355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.041952945, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.02138913, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.020403568, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.014225761, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.027333893, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.018021105, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.011847873, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.03314052, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.024832979, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.013978278, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16700, training loss= 0.016553642, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.023645855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.010298194, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.022278935, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17100, training loss= 0.016017092, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.021786744, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.019222695, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.015394477, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.015354325, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.019144135, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.018682092, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.021749811, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.024843803, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.018780172, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.017094992, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.019812645, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18300, training loss= 0.01919328, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18400, training loss= 0.00892412, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18500, training loss= 0.015887192, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18600, training loss= 0.019362938, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.01409386, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.014821987, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.025140923, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.03557844, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.013645856, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19200, training loss= 0.013784833, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.014897218, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.016140833, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.019423475, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.012846203, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.016266596, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19800, training loss= 0.012009655, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.015592176, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 0.010409009, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20100, training loss= 0.019810008, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20200, training loss= 0.017339613, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20300, training loss= 0.013322775, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20400, training loss= 0.016104493, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20500, training loss= 0.01686941, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.023075283, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.013785634, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.009539033, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.014167257, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.014722421, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.01296241, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.019210864, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21300, training loss= 0.019045472, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21400, training loss= 0.011789601, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.015090264, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.017241077, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.016652869, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21800, training loss= 0.019795997, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.012108711, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.014129728, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.011157623, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 0.012621158, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22300, training loss= 0.007893756, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22400, training loss= 0.012189307, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.0114905005, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.015605691, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.023111917, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.012446332, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.021275975, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.011214726, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.021550281, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.011862989, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23300, training loss= 0.010297577, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.013441693, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.017237702, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23600, training loss= 0.013380242, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.01708817, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.013911325, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.011220871, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.0150478175, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24100, training loss= 0.01228748, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.013482128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.015637344, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24400, training loss= 0.009429255, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24500, training loss= 0.016541902, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.010506007, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24700, training loss= 0.014285042, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 0.009187716, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24900, training loss= 0.009328108, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25000, training loss= 0.009365337, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.012000498, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.03331653, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.03484999, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.014960949, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 0.011174687, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.012880736, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.017639684, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.007147548, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.011681151, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26000, training loss= 0.012908992, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.007890015, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.007602856, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.009460441, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26400, training loss= 0.014132347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 0.025257945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26600, training loss= 0.043815546, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.014857237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.013943648, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.007667424, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27000, training loss= 0.009734163, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27100, training loss= 0.0077923173, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.009773699, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.018909281, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27400, training loss= 0.0083699785, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 0.012009109, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27600, training loss= 0.017838359, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.011194327, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27800, training loss= 0.009445983, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 0.008981775, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 0.010389152, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28100, training loss= 0.012223044, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28200, training loss= 0.010720086, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28300, training loss= 0.011961122, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.0127664935, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.009221408, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.011806936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.00954263, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.0091275815, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.014602198, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.013627064, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29100, training loss= 0.008638782, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.008900786, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 0.005347551, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.008102951, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29500, training loss= 0.009294073, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0104267225, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.0131319435, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29800, training loss= 0.00831671, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29900, training loss= 0.009086959, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.8330266, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.1648905, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.16422167, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.08694081, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 400, training loss= 0.09461081, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.10654205, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.068011194, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 700, training loss= 0.07909529, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.08792615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.057903275, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.036259096, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.05048328, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.026030067, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.06103159, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.08646466, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.04913836, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.07827677, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1700, training loss= 0.0927962, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.04600382, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.043515023, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.038207665, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.051567458, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.05458544, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.037727136, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.04906831, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.043698397, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2600, training loss= 0.031081576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.042019933, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.044505976, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.054282613, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.035766557, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.028160974, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.0512229, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.03338956, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.055883273, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.10743683, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.072066754, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.03717123, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.044942968, training acc= 93.99999976158142%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.02655395, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.040228188, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.045127906, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.02652274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.03010431, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.08214554, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.039166808, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.027112706, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.040224902, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.038620967, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.029158037, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.022338387, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.03408657, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.050137114, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.03522861, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.053943466, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.025827397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5600, training loss= 0.024523582, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.034702286, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.03318888, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.04645434, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6000, training loss= 0.023821678, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6100, training loss= 0.02269294, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.019303296, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.03476882, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.027140861, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.024079956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.04009091, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.038230233, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.026023842, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 6900, training loss= 0.028084164, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.023048438, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.0321777, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.049440913, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.03189413, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.02696712, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.037994195, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 7600, training loss= 0.022948412, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7700, training loss= 0.018155627, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.029961653, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.035822615, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.0338255, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.027774692, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.051470697, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.028362755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.029502977, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8500, training loss= 0.030493129, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.030036895, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.026375126, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.030026458, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.015906123, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.026293881, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.018512586, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9200, training loss= 0.023710322, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.026179684, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.018416949, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.02495573, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.057424195, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9700, training loss= 0.0513038, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.025671419, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.035836533, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.017002517, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.021610504, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10200, training loss= 0.018431332, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.02180773, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10400, training loss= 0.021648563, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.022349365, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10600, training loss= 0.025555328, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.023344055, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.031495042, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.026778435, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.02279923, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.024464194, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.02602502, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.025676688, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11400, training loss= 0.04570446, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.04318644, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.033027593, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.07752122, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.029105023, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.021308348, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.03007891, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.024327807, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.031010568, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.024479736, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.020243635, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12500, training loss= 0.029736739, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12600, training loss= 0.026011802, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12700, training loss= 0.1688206, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.027837245, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.031656247, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.022012558, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.033614445, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.02433335, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.024584984, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13400, training loss= 0.029815927, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.019792793, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.023183458, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.025169674, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13800, training loss= 0.025104355, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.016138524, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14000, training loss= 0.0744537, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.018147796, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14200, training loss= 0.030050253, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.025789388, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.027473465, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.020720018, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.019378176, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.02572315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.017993733, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.016788514, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.018835753, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.03321863, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.020501962, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.026353454, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.022426888, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15500, training loss= 0.013927387, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.01741681, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.017824188, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.022492347, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.08593324, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.04020418, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16100, training loss= 0.041565597, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.027239246, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.029236889, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.029244617, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.020167258, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.016585175, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.024782103, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.022866331, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.017911794, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.017914305, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.018836986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.030268757, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.021577142, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.012802902, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.015680935, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.025693676, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.023165166, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.054349508, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 17900, training loss= 0.030894343, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.02023682, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.029482309, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.03389796, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.017903727, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.024855701, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.023021922, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.025016267, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.024404235, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.018940926, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.025871044, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.015507462, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.017104093, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.02203352, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.015907072, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.053362396, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.028845023, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.02489053, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.02126423, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.028467976, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.023916624, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.019234065, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20100, training loss= 0.018849622, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.023790427, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.024952587, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.019352142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.019075025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.019744404, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.023840416, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.020207984, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.018366916, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.01958967, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21100, training loss= 0.033389352, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.02920065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 21300, training loss= 0.024890963, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21400, training loss= 0.018477187, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.019157965, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21600, training loss= 0.025983542, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.017763488, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.0168399, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.027508315, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.019287411, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22100, training loss= 0.019358922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.021928284, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.023714824, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.017481897, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.018202666, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22600, training loss= 0.07156144, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.060433894, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.024684278, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.0232454, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.01717287, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.020848475, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23200, training loss= 0.018314525, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.020721415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.02153311, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.01808744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.016562866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.023754116, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.014883522, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.017102461, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24000, training loss= 0.017722676, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.020116683, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.01631054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.015378015, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24400, training loss= 0.019593924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.015681516, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.0141080795, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.028852269, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24800, training loss= 0.018527841, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.020329695, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.030542042, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25100, training loss= 0.024499565, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.02535776, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.017812882, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.013970323, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.017739702, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.017709395, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.024414172, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.022978552, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.020601764, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.021582475, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.017518751, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.027552899, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26300, training loss= 0.014450783, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.016105562, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.01867662, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.01956798, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.017239805, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26800, training loss= 0.02217244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.020564487, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.021356866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.012304988, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.020946909, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.017685652, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.024928369, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.026993122, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.02375345, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27700, training loss= 0.017609248, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.020260215, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.025743952, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.022842495, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.01898661, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.028611211, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.020681001, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.01853499, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.018620357, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.016233815, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.014257464, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.018513672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.025388058, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.016406659, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.014043594, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29200, training loss= 0.013952602, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.018834462, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.035450585, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.023330346, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.015169304, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.013818245, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.02039387, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.025092578, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.3 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 1 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.758716, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.10401401, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 200, training loss= 0.10697988, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 300, training loss= 0.06663781, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 400, training loss= 0.055882066, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.056308817, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.063955314, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 700, training loss= 0.05938664, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.05877784, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.094218485, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.072346464, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.07312122, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.05401529, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.041734807, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.06888523, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.07396139, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.076924555, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.06563484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.09207432, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.051810198, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.05414968, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.05074076, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.054549254, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.05511442, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.06097749, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.041358285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2600, training loss= 0.052506875, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.041875534, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.0559789, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.038308907, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.05843694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.06775939, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.046771374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.038246714, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.06441662, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.04172131, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.042876527, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.041757878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.03805118, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.04887627, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.051614236, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.040136967, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.04889237, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 4300, training loss= 0.034469694, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.054052256, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.06512751, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.06808254, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.045974683, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.027604489, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.03127835, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5000, training loss= 0.04343097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.029222526, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.047421347, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.044301387, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.04706534, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.040225737, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 5600, training loss= 0.039061595, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.05237031, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.028368529, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5900, training loss= 0.036210444, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.03633792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.02465037, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.02352798, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6300, training loss= 0.029343724, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6400, training loss= 0.028156415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.03793502, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6600, training loss= 0.061556783, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6700, training loss= 0.041945647, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.04175219, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.04560625, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.045551863, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7100, training loss= 0.028808733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.04462345, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.031670768, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.03989069, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.028978374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.03386122, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.041344337, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.025383448, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.049037665, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.040375162, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.027396565, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8200, training loss= 0.02890753, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.027292853, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.05669005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.028634658, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.04054355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.03740742, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.03358085, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.03704723, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.036631756, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.038625546, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.028107062, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.027212223, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.049161628, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.034435004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.049214907, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.032833885, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9800, training loss= 0.024399478, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.033652563, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.032619555, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.032315813, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.022063494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.02162072, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.023589313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.02297309, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10600, training loss= 0.015303671, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.026743282, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.021816876, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10900, training loss= 0.021921283, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 11000, training loss= 0.03110807, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.020673735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.02638844, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.037043214, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.030622948, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.02612498, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11600, training loss= 0.026621683, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.024422757, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.021384005, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.02973125, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12000, training loss= 0.011713905, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.022665568, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.032217294, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.02703078, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.029452883, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.017649723, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.025375035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.021840215, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12800, training loss= 0.012686199, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12900, training loss= 0.01978118, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.01906253, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.030147802, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.01626589, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.016257543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.04022398, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.018288823, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.014947595, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.0117473975, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.020417139, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.023902848, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.022179348, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.025269285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.021746643, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.017416526, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.025702542, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.017476883, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.017540228, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.019901797, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14800, training loss= 0.022510827, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.021419888, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.021371633, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.026199028, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15200, training loss= 0.026668042, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.01675184, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.018425692, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15500, training loss= 0.016620629, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.016057815, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.013641439, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.016995981, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.021444565, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.010730885, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.017165959, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.022056483, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.02348911, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16400, training loss= 0.022140924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.01590433, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.015302021, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 0.014032152, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16800, training loss= 0.017210472, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16900, training loss= 0.011373954, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.022308491, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.024999555, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.017681241, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17300, training loss= 0.009428371, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17400, training loss= 0.02620459, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 0.015033467, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17600, training loss= 0.018560745, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.02393758, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.009382611, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17900, training loss= 0.015690276, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18000, training loss= 0.015541373, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18100, training loss= 0.009590438, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18200, training loss= 0.030212738, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18300, training loss= 0.010826556, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.019243117, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.030303653, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.018912578, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.013174854, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.019920241, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.007912886, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19000, training loss= 0.0134739, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19100, training loss= 0.011947456, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.017641557, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19300, training loss= 0.029638886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.013676505, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.011928534, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.011884784, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.015291594, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.014209103, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.013576966, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.011980394, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.013488199, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.011109786, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.017300572, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20400, training loss= 0.010564165, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20500, training loss= 0.015093666, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.0093433205, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.010712981, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.013337983, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.012954326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.011395954, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.011796845, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.015068905, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21300, training loss= 0.017801274, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.00899098, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.010752134, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.0064635384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.009614442, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.007231557, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.008209955, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22000, training loss= 0.0110023655, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.009646996, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.015267404, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22300, training loss= 0.0694362, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22400, training loss= 0.011433668, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.0086653065, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.014315903, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22700, training loss= 0.012044331, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 0.00834183, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 0.010465026, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.008218539, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 0.010329282, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.0084142545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.0062317755, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23400, training loss= 0.011756027, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23500, training loss= 0.0065794582, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23600, training loss= 0.0073641343, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23700, training loss= 0.010096143, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 0.006601314, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.006448577, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.011777291, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 0.006223533, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.0071605584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.009451615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24400, training loss= 0.011466844, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24500, training loss= 0.009603722, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24600, training loss= 0.011734705, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24700, training loss= 0.00832456, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24800, training loss= 0.0053216177, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 0.010120446, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.011828154, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.010076757, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25200, training loss= 0.016249226, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25300, training loss= 0.012192226, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.01216686, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.008395474, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.008002048, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.011972312, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.0069181174, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.008936338, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.0082569085, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.00886303, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.00994425, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.008943105, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.0103653185, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26500, training loss= 0.008480635, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.009129923, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.015207941, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.018228924, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.007747149, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.013076972, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.014396751, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.005957281, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27300, training loss= 0.010070544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0080149, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.008214477, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.007840319, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.0055031246, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.0060527585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.0061406214, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.009352938, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.011162131, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.012075364, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.011681581, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.0059247627, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.008114342, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.007460631, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.0078057325, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.0057416977, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28900, training loss= 0.00653926, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.010214146, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.0027594545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.0072626956, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.0045244647, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.00848634, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.007275562, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.006796669, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.0050279414, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.00704284, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.007945761, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "Valid acc= 90.7 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.313989, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.19209526, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.13425714, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.072685175, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 400, training loss= 0.108249776, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.09020533, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 600, training loss= 0.092039734, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.10226324, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.050689787, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.08213882, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.057215214, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.06061806, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.057498887, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.07600989, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1400, training loss= 0.058010593, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.056133814, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.068360105, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.041457374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.038908433, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.050789718, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.053891446, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.07043797, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.047618713, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.056311615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.044362985, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.048758253, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.055498213, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.05312586, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2800, training loss= 0.057880946, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.03894112, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.040026713, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 3100, training loss= 0.1029681, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.051373523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.033420328, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.045537584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.05809788, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.059573196, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.06865902, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.05942329, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.046397474, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.03832461, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.047602385, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.03522896, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.049478274, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.03960456, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4500, training loss= 0.033000916, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.04214832, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.038325995, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.067022175, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.035666466, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.04889056, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.05222685, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.03909298, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.050147656, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.031041248, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.037069317, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.032354563, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.050674036, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.047083363, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.040167022, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.025563246, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.057425063, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.036353126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.039030157, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.067797035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.04282697, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.04681106, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.035159074, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.04726329, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.034677055, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.04963478, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.03438736, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.039280906, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.046726868, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.052157853, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.027520442, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.030380381, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.0392123, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.057973094, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.09696387, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.051585034, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.045764163, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.048340183, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8300, training loss= 0.031828962, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.03746163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.045028068, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8600, training loss= 0.033979546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.027500857, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.028194085, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.029741278, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.036066268, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9100, training loss= 0.03962622, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9200, training loss= 0.075999595, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9300, training loss= 0.03218896, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.041944806, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.040857308, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.042623084, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.06303401, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.03697816, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.046781648, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.021098332, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.03332672, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10200, training loss= 0.041014772, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.022653464, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.042708743, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.021735398, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.044035777, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.031020213, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.028214911, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.026199069, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.02594533, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.037525818, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.04233966, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.027568767, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11400, training loss= 0.035288226, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.036474325, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.031654708, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.028816689, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.022758627, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.038438868, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.042094715, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.02970124, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.037684772, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.03202045, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12400, training loss= 0.030161718, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.034898285, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.026461648, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.0368529, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.036667485, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.021668421, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13000, training loss= 0.039506935, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.03746755, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.026834467, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.01955444, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.027511856, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.02478813, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.027566563, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.06572472, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 13800, training loss= 0.034435876, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.023567345, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.030824501, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14100, training loss= 0.034436397, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.03224853, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.023947867, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14400, training loss= 0.02587713, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14500, training loss= 0.036652032, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14600, training loss= 0.034829848, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14700, training loss= 0.034798846, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.03561962, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.03433816, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.04151303, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.027002066, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15200, training loss= 0.023799192, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.024551716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.025335357, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15500, training loss= 0.07041568, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.052662086, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.030069627, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15800, training loss= 0.030486071, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15900, training loss= 0.0303436, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.03037362, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.033455357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.037513103, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.033006035, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.022722889, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.029831585, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.027288638, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.03501657, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.034749262, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.021182016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.023236567, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.027337577, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17200, training loss= 0.02624324, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.023083773, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.022311185, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.022762856, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.016758593, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.014119968, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.024177028, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.026036091, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18000, training loss= 0.020827314, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.026968427, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.034233663, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.039797764, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18400, training loss= 0.023013406, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.02475744, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.027130384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.030219698, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.03547172, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.022949789, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.028437072, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.022778442, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.02231061, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.033071745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.02543631, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.05862191, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.036481693, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19700, training loss= 0.044658605, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.03037685, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.029989228, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.018156717, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.021634107, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.027083574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.03686264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.01845, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20500, training loss= 0.02405196, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.020026794, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20700, training loss= 0.03538746, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.03200178, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.028762769, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.024227768, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.026391773, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.06234367, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.023861237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.034218192, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21500, training loss= 0.030398961, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21600, training loss= 0.018377963, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.015601332, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.027706144, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21900, training loss= 0.02802764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.02100697, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.024731068, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.035976976, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.06883846, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.024829032, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.023374733, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.04161145, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.018850563, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22800, training loss= 0.0298501, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.026709985, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23000, training loss= 0.024445008, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.024985384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.021069683, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.02449413, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.028332066, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.02131312, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.026215471, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.02870347, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.022230644, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.016225748, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.021215692, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.026466513, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.022281108, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.018388467, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.018952861, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.025763145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.022133857, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24700, training loss= 0.019650448, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.032314654, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.022447154, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.022306575, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.017121566, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.02383097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.019401077, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.021940399, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.038756765, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.029982975, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.02533501, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.022334926, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.020535715, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.019468155, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.020129945, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.016322488, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.016676769, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.023172624, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.026664944, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.018835569, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.015141045, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26800, training loss= 0.017984368, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.02103105, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.02143187, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.055700026, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.019299628, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.018728437, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.025729546, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.017861288, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.018706948, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.013661392, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.014827302, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.015063702, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.01581273, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.01699985, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28200, training loss= 0.015655145, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.013953826, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.017329441, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.011308814, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.016513973, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.02261425, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.019224623, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28900, training loss= 0.13804118, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.02264248, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.0168306, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29200, training loss= 0.023169583, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.023720449, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29400, training loss= 0.00916342, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.01697538, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.0145921735, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.012174587, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.014994155, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.017337514, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.884512, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.13294782, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.08372454, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.07871151, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.03851533, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.09475799, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.048379138, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 700, training loss= 0.05058637, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.06511916, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.07119788, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.028259128, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.058724698, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.05909973, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.0750283, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1400, training loss= 0.066815056, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.061100908, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.064892285, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.052233383, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.06903749, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.041597933, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.04967013, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2100, training loss= 0.03330132, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2200, training loss= 0.046248972, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.04591715, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.04145223, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.05365949, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.04927939, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.045359362, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.033469744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.040570993, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.046695203, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3100, training loss= 0.033296056, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3200, training loss= 0.03544641, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.054658346, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.059728928, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3500, training loss= 0.0584607, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.038935017, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.03870407, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.030816553, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.033628378, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.035699517, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.028981796, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.037593223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.040090732, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.036783658, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.050269537, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.032917853, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.028889801, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.041217733, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.033411037, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.037995104, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.035147592, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.032925546, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.03560825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.03478614, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.054974504, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.032242816, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.047089837, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.041272033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.05315901, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.029892718, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.053579576, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.044144582, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.022166243, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.033034578, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.029794447, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.03305163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.03727646, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.030199021, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.027538953, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.0382102, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.028317342, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7200, training loss= 0.038587917, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.037602454, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7400, training loss= 0.0361379, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.03177694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.027354687, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.01973045, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7800, training loss= 0.029512146, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.04568196, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.02407538, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.03602976, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.026823346, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.030316498, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.038004063, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.03837356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.03173904, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.023300348, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.03911592, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8900, training loss= 0.028307127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.03016881, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.028824845, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.025212038, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.027718075, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.022305882, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.028734233, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.033433583, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.02012724, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9800, training loss= 0.049171872, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.025453856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.022477925, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.028361734, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.028106926, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.029696625, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.032535017, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.025091363, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.031601865, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.01920316, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.037195027, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.023529349, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.017058115, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.020587737, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.025798045, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.020910943, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.03839397, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.047384106, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.014863102, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.022799242, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.019154986, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.025278345, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.020021142, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.03072448, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.02108353, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.026560646, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.024547236, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.026010446, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.02520891, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.022151953, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.032281425, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.024282705, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.015732044, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.021506839, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.037643295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.026926825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13400, training loss= 0.0142123215, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.022605088, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.022744315, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.015149329, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13800, training loss= 0.022449506, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.023358753, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.016810654, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.017444441, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.023782752, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.015231843, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.033075012, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.017081665, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.0172793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.020289853, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.017348552, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.0291762, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15000, training loss= 0.02415913, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15100, training loss= 0.016493604, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.044212084, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15300, training loss= 0.022330415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.021127792, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.023457194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.025686344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15700, training loss= 0.0262289, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.019231921, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.017508922, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.028249215, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.013640851, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.022850877, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.011585343, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.014101685, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.011287151, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.027909981, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16700, training loss= 0.016435143, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.013599538, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.016247205, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.017107127, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.014631772, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.013806752, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.019672701, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.020318538, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.019313455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.02479062, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.01767009, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.020177195, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.017262967, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.019430002, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.016974648, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18200, training loss= 0.031683933, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.023164919, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 18400, training loss= 0.039197177, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.023720782, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.02040386, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.009801574, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.014570817, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.016220989, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.018753124, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.010557044, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.015757952, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.018046074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19400, training loss= 0.016397385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.013121628, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.016858496, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.022018518, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.010390752, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.014453165, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.016821662, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.008907523, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20200, training loss= 0.012619585, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.022325197, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.013590159, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20500, training loss= 0.020869698, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20600, training loss= 0.008850744, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.01745565, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20800, training loss= 0.016199015, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.015903397, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21000, training loss= 0.011130522, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.01648814, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.014926524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.01442518, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.009312105, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.013429734, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.01885747, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.017510831, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.013382931, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.008704337, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.01291086, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.010423608, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22200, training loss= 0.016548978, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22300, training loss= 0.016336983, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.014041192, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.016157355, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.01364429, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.01797016, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.014387012, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 0.016023686, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.014753739, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.011222342, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.05506484, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.017589232, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.01224647, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.012451043, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23600, training loss= 0.013520728, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.01570835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23800, training loss= 0.008950346, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23900, training loss= 0.01674121, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.013510808, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24100, training loss= 0.013677443, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24200, training loss= 0.014842306, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.011440296, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24400, training loss= 0.018254757, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.009808365, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.013924005, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.012241809, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.009158255, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24900, training loss= 0.00820067, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.016159208, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.009835328, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.018472482, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.031134047, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25400, training loss= 0.020060593, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.013008545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.016097225, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.013885308, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.011565259, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.017426973, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.0086747445, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.011467578, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.010034812, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.010365238, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.012530561, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.012443382, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.010159531, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.010817422, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.0114857815, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.013217145, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.014367825, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.017651523, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.0067299325, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.00963581, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.009766841, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 0.008832277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.014462417, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27700, training loss= 0.010166516, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.011193906, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.009690304, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.011498343, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.00926458, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28200, training loss= 0.015580063, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.016955486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.015434258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.009491939, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.010522825, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.008279241, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.013513704, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.010239752, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29000, training loss= 0.0077883955, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.011491453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.035121597, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.009597083, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.011938252, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.012294617, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.0137377065, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.012393412, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.007471974, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.009035037, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.8 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.3837001, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.118263386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.10776985, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.100354455, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 400, training loss= 0.08047555, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.1470151, training acc= 93.50000023841858%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.07724468, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.056005467, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.101319745, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.07313364, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.08544394, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.0456298, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.050875403, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.02903401, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.064602844, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.06960579, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.04299236, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.04660582, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.06527645, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.043534126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2000, training loss= 0.05430746, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.05486825, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.03561233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.036347963, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.037648123, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.051318195, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2600, training loss= 0.046509787, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.041048788, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2800, training loss= 0.03303542, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.047958236, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.04718026, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.03547674, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3200, training loss= 0.043118637, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.029640362, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.031333197, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.029043643, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.04157479, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.03103329, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.03741492, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.020705169, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.028379863, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.029475952, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.029366, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.05887845, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.032506082, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.047611605, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.028983785, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4700, training loss= 0.03566819, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.03864066, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4900, training loss= 0.031165337, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.03110191, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.039561447, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.056462567, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.030420596, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.027071064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.057113316, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.04385879, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.042782135, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.026276542, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5900, training loss= 0.04049342, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.028626895, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.030615492, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.032042682, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.034974348, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.042460404, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.042224407, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6600, training loss= 0.056493517, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.03209414, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.029767254, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.022604072, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.053403147, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7100, training loss= 0.033249557, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.03714434, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.035009798, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.05198821, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.028598865, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.026342887, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.043876816, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.023488302, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.02878703, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.023029067, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.026248097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.030879512, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.027160829, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.027407825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.02200456, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.018093085, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.036008105, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.017430028, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.030000627, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.027371287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.018389782, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.05733775, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.06181503, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.04343211, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 9500, training loss= 0.03498606, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.036654375, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.019668953, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.03518556, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.028948456, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.032154106, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.027477225, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.023767387, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.025468243, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.029297179, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.04264128, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.02490489, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.022194244, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.024167158, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.026452396, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.03067932, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.026214639, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.047512513, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 11300, training loss= 0.03125003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.025182737, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.038601637, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.026904702, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.030498317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.028630544, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11900, training loss= 0.02584751, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12000, training loss= 0.023801941, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.020214837, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.022170205, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12300, training loss= 0.026232554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.020134453, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.021416767, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.028600058, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.02637322, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.027161209, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.046534467, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.045405097, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.025063032, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.03325224, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 13300, training loss= 0.023665762, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.027969629, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.027695304, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.032879796, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.020722274, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.025467131, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.016725061, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.023778317, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.023250138, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.019904947, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.03400449, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.025536908, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.025585148, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.03183467, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.035483386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.023318028, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.025485182, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.032747354, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15100, training loss= 0.02674199, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15200, training loss= 0.022832466, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.032343432, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15400, training loss= 0.020206615, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.02591273, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.02234225, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15700, training loss= 0.025672069, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.018618979, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15900, training loss= 0.02585266, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.0432613, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.037554182, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.024733787, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.028136555, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.025516173, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.026296416, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.02127274, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.021391546, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.021983977, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.028429737, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.020849923, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.023520952, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 17200, training loss= 0.033424176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.019253168, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17400, training loss= 0.016510319, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.030522466, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.021516984, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.021559788, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.022116898, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.035561316, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.019818032, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.05195577, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18200, training loss= 0.040824357, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.024977827, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.035321496, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.025721336, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.5999984741211 ...\n",
            "\n",
            "step 18600, training loss= 0.028427204, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.028712738, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.02885191, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.022243328, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.021024728, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.017334903, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.025543666, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.038316876, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.028778998, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.019252583, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19600, training loss= 0.020240124, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.024600944, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.023076424, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.029597497, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.018568223, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20100, training loss= 0.015751736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.021503372, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.023898078, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.032105487, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20500, training loss= 0.02481736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.0393957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.02246689, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.0321698, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 20900, training loss= 0.016770957, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.023616424, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.023034334, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.018503368, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21300, training loss= 0.010847836, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.01741473, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.023774248, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.021998486, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.028431147, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.018150128, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.02135907, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.01765822, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.0342804, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.039451864, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.022645958, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.024804436, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.020824, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.01704917, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.021728342, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.026648909, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.016669426, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.03097842, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23100, training loss= 0.030963266, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.016415704, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.024410617, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.025335735, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.014347108, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.013106507, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.020005748, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.013557899, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23900, training loss= 0.018591532, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.08440781, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.03315919, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.020474134, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.023010788, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.020680599, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.019785542, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24600, training loss= 0.017561425, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24700, training loss= 0.01592103, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24800, training loss= 0.017984452, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.014424885, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.023936387, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25100, training loss= 0.014206869, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.017822837, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.017890666, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.026433427, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25500, training loss= 0.015683454, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25600, training loss= 0.018838126, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.014290213, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.015488857, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.020680232, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.013510411, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26100, training loss= 0.018308917, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.01625453, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.023200022, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.018535344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26500, training loss= 0.01780353, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.019661529, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.017248066, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.028342122, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.041437708, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.037599023, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 27100, training loss= 0.012912459, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27200, training loss= 0.02008436, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.015030225, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27400, training loss= 0.015391215, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.017429706, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.022085156, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.01809154, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.01769173, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.02307654, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.019636838, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.0128534585, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28200, training loss= 0.020153062, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.010999593, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.016213818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.012953428, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.02316126, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.016230214, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.01428987, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.016085874, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.020391127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 29100, training loss= 0.013325639, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 29200, training loss= 0.012386946, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 29300, training loss= 0.013548531, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.017815493, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.07874646, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.045621853, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 29700, training loss= 0.02158097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29800, training loss= 0.018553788, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.011743789, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 2 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.6826747, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.07713716, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.08290504, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.09835585, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.059471287, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.085409544, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.063332185, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.08342505, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.057812877, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.06318478, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.076228365, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.09232985, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.06730518, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.06580742, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.060426652, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.061283868, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.04553726, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.06715707, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.0712251, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.06506167, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.07357505, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.06366653, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.05575097, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.07328166, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.07972314, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.050260626, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.06186767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.038827237, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.03761784, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.045270126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.040753223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.05502149, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3200, training loss= 0.060218956, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.072438054, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.0813732, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.036960706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.06378997, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3700, training loss= 0.05937831, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.038020298, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.06633449, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.039036423, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.041570798, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.037465338, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.04834927, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.050495952, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.049740527, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.038816646, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.060215652, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4800, training loss= 0.03520174, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.030670794, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.037875954, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.054083202, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.04185887, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.05233803, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.03401873, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.06019322, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.04642185, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.032188002, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.040781286, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.04901675, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.03835306, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.048859548, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.055076946, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.027457174, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.03315953, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.038410205, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.044051908, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.043797124, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.058891933, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.030587845, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.024543984, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.038077004, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.038254388, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.04087885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.0286964, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.047163606, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.040707227, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.045019325, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.042778246, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.029104466, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.04194071, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.038192168, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.022345003, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.038197536, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.030317502, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.035416815, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.033333555, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8700, training loss= 0.028315943, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8800, training loss= 0.020232564, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.023928944, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.020889051, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.024763918, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.04269936, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9300, training loss= 0.020565242, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.025295325, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.030419562, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.031599805, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.0294697, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.017523456, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.025381222, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.02771906, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.021244964, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.029365933, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.031924095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.03284197, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.01897052, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.018746722, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.019960487, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.019755948, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10900, training loss= 0.02463, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.03496183, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.021025725, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.030850362, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.0214058, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.02875747, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11500, training loss= 0.020671966, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.028301693, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.02080896, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.01879056, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.03037697, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.0311565, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.01667692, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.029910887, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.01718021, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.018858997, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.026832515, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.015079934, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.02034764, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.020030046, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.022775436, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.021876983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13100, training loss= 0.0170417, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.019331584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.016368551, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.018446343, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 0.015196176, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.023161756, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.016819177, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.023024421, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.02464543, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.027499571, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.0194728, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.013124428, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14300, training loss= 0.013220339, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.019620346, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.014449155, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14600, training loss= 0.010769691, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14700, training loss= 0.015637847, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.013122205, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.016454792, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15000, training loss= 0.014769975, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.012275724, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15200, training loss= 0.019314308, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.016134882, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15400, training loss= 0.01682571, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.014588478, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.022873823, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.01625732, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.012078055, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.0134434365, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16000, training loss= 0.018612493, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16100, training loss= 0.014542306, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.013943941, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.02926058, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.021078078, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.012577013, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.016798867, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.010127795, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16800, training loss= 0.014966731, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.009825751, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.015630763, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17100, training loss= 0.011878545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.015839892, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.013753828, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.013941196, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.012226018, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17600, training loss= 0.009738971, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17700, training loss= 0.009294348, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.025027733, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.00865807, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.022603791, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.012544594, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.017800106, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.011928771, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18400, training loss= 0.016307492, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.016760478, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.012986637, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.011981093, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.013121621, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.009845107, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.011590833, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.01611638, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.016006827, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.01685973, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.006832005, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.014285769, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.009312675, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.013678886, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.011126362, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.014065921, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.015486138, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.008110625, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.009459875, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.007678423, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.008157286, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.0073129954, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.008975887, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.009488432, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.0071490733, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.010008417, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21000, training loss= 0.011717231, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.010376593, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.015769772, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.011354836, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.012875032, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.00921503, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.016675184, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21700, training loss= 0.008541936, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.008683237, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21900, training loss= 0.010596836, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.011490523, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.011521345, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.007443294, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.010484389, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.010276674, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.013579326, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 0.011089998, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.009752778, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.012178873, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.00592494, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.009492923, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23100, training loss= 0.010970732, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.009974958, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.0069017536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.016772073, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.018328056, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23600, training loss= 0.013817354, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.013160999, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.007601592, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23900, training loss= 0.008547175, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24000, training loss= 0.0065792194, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.008010585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.0093540745, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.012818378, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.0066820546, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.007464996, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24600, training loss= 0.0050942423, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 0.0059669134, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.0073510706, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.00782901, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.0062746513, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25100, training loss= 0.008394454, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.016929805, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.011728749, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.009792946, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.006419124, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.0060800747, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.0070053963, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.005560233, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.005128134, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.0067651668, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.00917994, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.0049451184, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.007828867, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.010936996, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.0057817744, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26600, training loss= 0.010043087, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.0053830706, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0071079195, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.0064231353, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.0042200843, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.0057902685, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.0045430628, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.007546343, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0075524515, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.008765015, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.00505183, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.0053372364, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.0035970581, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.004552464, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.003712295, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.00947402, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 0.0070779184, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 0.0043769623, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.008648847, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 0.0044811335, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28600, training loss= 0.0032672533, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28700, training loss= 0.0049202624, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.006451842, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.0071805585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.0062816096, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.0050351066, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 0.007562709, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.005656795, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.003994551, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 0.004562793, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.004415374, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.0059549226, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.0041828076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.0060657375, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "Valid acc= 90.8 %\n",
            "Validation Accuracy Test 85.80060577392578 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.0757735, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.09259569, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.13126174, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.09100872, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 400, training loss= 0.0813912, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.12148183, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 600, training loss= 0.09338424, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.056942333, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.07795513, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.07881359, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.058025964, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.07689184, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.08435525, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.06969033, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.044960998, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.07360236, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.0527964, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.062182724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1800, training loss= 0.04075459, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.08063692, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.05315381, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.048811115, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.05794483, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.06976855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.05439321, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.043629214, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2600, training loss= 0.039434955, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.041305095, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.047142725, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.04440206, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.055638757, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3100, training loss= 0.043794792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.045238387, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.052331507, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.049199756, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3500, training loss= 0.042338394, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.07959155, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.039413854, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.038264588, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.042188086, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.04469591, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.073021136, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.044908263, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.063979335, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.056358423, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.031816866, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.04934056, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.049472563, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.045932986, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.074258104, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.040465023, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.057390805, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5200, training loss= 0.06291532, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.037791472, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.0463745, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.053336084, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.040097963, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.03553285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.034018327, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.05639229, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.06368219, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6100, training loss= 0.09652815, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.04704168, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.031820618, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.03215162, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.035720672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6600, training loss= 0.03723451, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.057306595, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.04794006, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.048764855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.0310885, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.04426692, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.036132045, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.04059622, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.023395786, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.03248019, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.041278765, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.037419096, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.050873037, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.056612786, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.043687347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.056142237, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8200, training loss= 0.050618768, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8300, training loss= 0.040904548, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.04074546, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.058859028, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.02476273, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8700, training loss= 0.03199817, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.031109756, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8900, training loss= 0.036428314, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.02400886, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.035864573, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.05150587, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.021922326, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9400, training loss= 0.05317397, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.03532611, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.038563427, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.04965877, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.041472398, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.04723225, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.069688454, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.04431903, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.03151485, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.020955706, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.048472755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.03371924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.038426634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10700, training loss= 0.031283494, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.031500455, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.03222342, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.032296073, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.040273685, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.04050744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.03548217, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.041250184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.03242294, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.027029393, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.031835116, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.07259647, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.02540097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.052202404, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.041160252, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.04114122, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.029495502, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12400, training loss= 0.033227816, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12500, training loss= 0.03779023, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.03709804, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.03360657, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.042448718, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.030310431, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.04152516, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.025654465, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.041450705, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.025689954, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.03669217, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.024029462, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.03363121, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.02380158, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.033517245, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.03219858, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.026746357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14100, training loss= 0.040137213, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14200, training loss= 0.02518639, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14300, training loss= 0.04781922, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.04505331, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.029825205, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.029649897, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14700, training loss= 0.024495723, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.030497093, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.02447903, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.05112176, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.036642864, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.03155306, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.031343304, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.024033824, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.03573003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15600, training loss= 0.022080425, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.019374086, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 0.05706206, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.06147602, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.04222243, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.025484053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.043514516, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.029548822, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.0145034315, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.024655264, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.031822983, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.020902956, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.021103377, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.0267777, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.021845846, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17100, training loss= 0.051030803, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.030269757, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.023618985, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 17400, training loss= 0.025235623, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.029258048, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17600, training loss= 0.03258888, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.012157363, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.032542374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.019856043, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.023233416, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18100, training loss= 0.020187711, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.024002438, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.027015463, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.027942766, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.028741047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.028371483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.028620753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.024777716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.045264397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.025674736, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.04886945, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.02550518, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.017334891, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.026958166, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.027065698, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.026457613, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.024686713, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.029245665, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.02487659, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.029421067, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.0197125, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.028944302, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.021724036, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.052400094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.036453255, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.016666817, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.025046665, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.021333924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.017939482, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21000, training loss= 0.025400957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.024803126, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.019886803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.021741888, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21400, training loss= 0.028605236, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.024378475, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.025146673, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.032984108, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.035225756, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.019097071, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.03067997, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.07243077, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.03371178, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.0250024, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.0274576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.011878358, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.037849393, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.022896247, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22800, training loss= 0.022811294, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.024590563, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.031655945, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23100, training loss= 0.014304416, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23200, training loss= 0.105382204, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23300, training loss= 0.02569485, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.016939817, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.018688755, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.020692697, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.015455273, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.02645622, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.02278924, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.019943547, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.022324538, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.013670101, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.023871614, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.033630013, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.021735007, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.029197956, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.025647316, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24800, training loss= 0.018601974, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.02536726, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.023114206, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.02007169, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.011068366, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.017141722, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25400, training loss= 0.013672735, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.019324077, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25600, training loss= 0.025534252, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.02526432, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.019244194, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.018282639, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.019779611, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.01852226, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.018188054, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26300, training loss= 0.027271394, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.02085621, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.03146117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26600, training loss= 0.020589028, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.03019282, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.022532301, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.026872752, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.026923249, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.015118064, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27200, training loss= 0.022818113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27300, training loss= 0.016544366, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.017834237, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27500, training loss= 0.019372227, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.018248238, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.015477878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.015228641, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.02484241, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.019276056, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.015703976, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.01572805, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.019608665, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.026481187, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.01783088, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.014565319, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.012755918, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.023698254, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.018360576, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29000, training loss= 0.12145682, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.019265912, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.02311675, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.023971057, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.01943407, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.02083922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.011484937, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.018360073, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.017619727, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.02432591, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "Valid acc= 90.4 %\n",
            "Validation Accuracy Test 86.40483856201172 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.2885867, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.08150178, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.1193789, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.11518877, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 400, training loss= 0.061639067, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.08317608, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.08794838, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.061850574, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.0769956, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.057082605, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.08423519, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.04804629, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.054680854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.0766037, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1400, training loss= 0.050743785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.057052344, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.058220673, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.04157046, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.045424994, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.044536386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.04930776, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.037956193, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2200, training loss= 0.06415303, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.05080325, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2400, training loss= 0.06180198, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.068916164, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.06328169, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.034135994, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.047010202, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.03855514, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.07784158, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.059879996, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.038906734, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3300, training loss= 0.06451642, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3400, training loss= 0.039576188, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.033022884, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.04213775, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.040049706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.046116088, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.049618527, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.04265641, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.03566078, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4200, training loss= 0.062338043, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.054430254, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.043775167, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.03687923, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.038063385, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.058413323, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4800, training loss= 0.050863154, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.040445656, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.046645094, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.03680798, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.06408156, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.05717923, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.053426143, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.03588432, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.042654734, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.04628845, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.036488127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5900, training loss= 0.043995705, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.029168878, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.03175255, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 6200, training loss= 0.037392724, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.049481746, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.034514397, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.03710311, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6600, training loss= 0.021137146, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.028785441, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.038185894, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.024462385, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.03946496, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7100, training loss= 0.047981597, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7200, training loss= 0.027712435, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7300, training loss= 0.023716634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.035187956, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7500, training loss= 0.034388423, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.042144146, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 7700, training loss= 0.029958507, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7800, training loss= 0.036367424, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.030947013, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.029781574, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.03202922, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 8200, training loss= 0.036233883, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8300, training loss= 0.02311207, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8400, training loss= 0.020004375, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.036433153, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.032464053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8700, training loss= 0.029954953, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.023206217, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.031678393, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.02014398, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.031028911, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9200, training loss= 0.03414147, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.026662145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9400, training loss= 0.049228795, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.031056479, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.02908039, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.030123873, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.03147484, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.03166027, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.018152734, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.027400363, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.019956868, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.026421813, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10400, training loss= 0.016686676, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.03368349, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.025404057, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.029166171, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.024529643, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10900, training loss= 0.034526777, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.028874392, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.016648775, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.019963946, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11300, training loss= 0.021139352, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.04397724, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.029001001, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.023594994, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.023181183, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11800, training loss= 0.02347496, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.013490403, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12000, training loss= 0.02262046, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12100, training loss= 0.018991334, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.025992138, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.026667748, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12400, training loss= 0.036677282, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.028910829, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12600, training loss= 0.022610212, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12700, training loss= 0.01848755, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.019937664, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12900, training loss= 0.015123384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.04950543, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.019402632, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.020860368, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13300, training loss= 0.03217484, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.019344592, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.02159364, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.022891743, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.019987227, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.02728948, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.022630116, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14000, training loss= 0.032001738, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.02530758, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14200, training loss= 0.015374799, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.026218949, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.013833349, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.023141673, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.020431569, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.017876219, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.025750084, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.028812174, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.025836898, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.035312995, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15200, training loss= 0.024964048, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.013003905, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.0294793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.021460138, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.08559741, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.025778318, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.019284477, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.022009505, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16000, training loss= 0.015983222, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.021342142, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.019494323, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.020048654, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16400, training loss= 0.019744953, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16500, training loss= 0.020801729, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.021998106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.020913862, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.0139102265, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16900, training loss= 0.016878776, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.017337805, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.01756164, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.020404294, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17300, training loss= 0.016861541, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.01543877, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17500, training loss= 0.014338987, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17600, training loss= 0.017696569, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.010728891, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.018552927, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.015468097, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.014981033, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.023404378, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.01816228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.01674906, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.009126588, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.021764634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.01415047, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.017171388, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.011244244, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.012968625, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.018889604, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.015977262, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.01502994, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.020786623, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19400, training loss= 0.013212505, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.012930249, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.01805597, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.013981396, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.014347918, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19900, training loss= 0.019058071, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.013095272, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.018557588, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.014186463, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.066983365, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20400, training loss= 0.021406833, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.017778998, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.020174004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.014405727, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.012330503, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.0144906035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.011001318, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.015623133, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.013171042, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.019947464, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.011346766, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.016086325, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.014928321, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.010963118, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.014621139, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.008973572, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.0096765645, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.010880421, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.017078068, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.011142801, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.009374235, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.01063655, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.017234776, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.011670762, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22800, training loss= 0.008785684, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.009877429, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.01693231, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.010961645, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.014632295, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.010113279, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.009843052, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23500, training loss= 0.0068995035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.009761771, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23700, training loss= 0.009104476, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23800, training loss= 0.011400991, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.016307237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.016891127, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24100, training loss= 0.009534738, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.01473881, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.014221373, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24400, training loss= 0.009419176, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.009916468, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.015974756, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.007315762, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.011822264, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24900, training loss= 0.015168979, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25000, training loss= 0.01825461, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.013085179, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.015619921, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.013404821, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.0141583, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25500, training loss= 0.009692321, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.009663663, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.014972718, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.0071415524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25900, training loss= 0.012871528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.013324673, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.009091385, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.012363276, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26300, training loss= 0.009667347, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26400, training loss= 0.012743833, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.004181862, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.006527323, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.008748907, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0126113435, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.0111850025, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.008245464, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.01023513, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.01542337, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.012851528, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.010615514, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27500, training loss= 0.008157509, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.0072653103, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.014709936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.012886429, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.011185211, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.010446035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.010816917, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.011561937, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.01043148, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.013198989, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.008192086, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.009298503, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.008593739, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.008190921, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.01127637, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.00912194, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.016169494, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.007525059, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.0092196455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.0086271735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.008485416, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.007973838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.007766568, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.013230889, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.010012036, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.7 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 2.3610625, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.08132168, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 200, training loss= 0.09311852, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.07515746, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.1229393, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.06399201, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.06772436, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.037721455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 800, training loss= 0.06644909, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.07589683, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.08965103, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.053526398, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.08427988, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.049140006, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 1400, training loss= 0.04955128, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.0516406, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.046981733, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.07191056, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.04561713, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.05788637, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.04227207, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2100, training loss= 0.043216743, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.062232535, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.059038304, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2400, training loss= 0.04204067, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.049039524, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.04426543, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.060259443, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.049203884, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.0448526, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.04040219, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.045570176, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.07853751, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.060141668, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.09633222, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.06723368, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.07241629, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.035429776, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.04822428, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.029497653, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.04257975, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.040431622, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.036471173, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.063289545, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.056038737, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.04619537, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.050803483, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.0522353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.018696155, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.039178506, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.037024204, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.03755102, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.05916071, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.041870244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.042982176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.025431614, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.048054874, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.04057829, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 5800, training loss= 0.03540647, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.03196618, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.057267066, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.041616704, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.03171709, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.042535596, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.03884385, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.03396228, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.053980127, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.047434837, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.038076255, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.059289794, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7000, training loss= 0.045685582, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.040260665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.03993167, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.031559695, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7400, training loss= 0.04449489, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.04785274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.037394993, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.050567336, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.068163276, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.029069997, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.03318649, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.040871702, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.038915403, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8300, training loss= 0.03568051, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.03962541, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.03565523, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.027149756, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.032287687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.043259185, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.030701514, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.014971624, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.039116178, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.046469968, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.03282635, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9400, training loss= 0.02386891, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.043317597, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9600, training loss= 0.034162104, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.040161826, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.09459107, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.043741688, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.02789039, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.038817443, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.036457043, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.028774388, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.027449822, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.030530117, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.025203217, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.047381148, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.025592264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.019210443, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.03194979, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.021735407, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.038275935, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.23732442, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 87.5999984741211 ...\n",
            "\n",
            "step 11400, training loss= 0.033680096, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.026541308, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.025054922, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.028799966, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.033173427, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.031098317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12000, training loss= 0.039025374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.028411154, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.032773487, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.03752944, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12400, training loss= 0.03508977, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.02908215, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.026123624, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.044228673, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.03943436, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.030525021, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.018832989, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.01874207, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.023054142, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.020919498, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.0372259, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.023451453, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.029802185, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.04562135, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.027660748, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.041302316, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14000, training loss= 0.06023435, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14100, training loss= 0.038496234, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.02987494, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.028559, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.024208527, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14500, training loss= 0.031395502, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14600, training loss= 0.023543585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.031019805, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.027840337, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.027829802, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15000, training loss= 0.029291939, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.02664074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.036876865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.03503193, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.023248179, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.027087297, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.016525663, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15700, training loss= 0.01804978, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.016771313, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.030080069, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.020316117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.031612597, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.027793966, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.022238959, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.023479432, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.0198203, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.018373996, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.052139193, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.0415726, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.028705336, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.018035563, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.027704451, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.02138671, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.0352185, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.028127387, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.022102118, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17600, training loss= 0.027478356, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.021386687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.022534281, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.023403045, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.016282717, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.029629435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.028191423, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18300, training loss= 0.055176567, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18400, training loss= 0.026715655, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.022429897, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18600, training loss= 0.02118445, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.026595963, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18800, training loss= 0.03731829, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.022037795, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.02342501, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.02498595, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.018006815, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.030412689, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.025627669, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.027574811, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.020815324, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.026206484, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.021500181, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19900, training loss= 0.02528143, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.02565997, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.026799906, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.01469014, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.027204085, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.024184106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.0999557, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20600, training loss= 0.02919781, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 88.5 ...\n",
            "\n",
            "step 20700, training loss= 0.026578173, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.016636414, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 20900, training loss= 0.033292696, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.024023421, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 21100, training loss= 0.018275421, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 21200, training loss= 0.020772174, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21300, training loss= 0.021120152, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21400, training loss= 0.029832138, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.021290792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.02235683, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.013819772, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.017785508, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.020090569, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.02104944, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.038981423, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.091293275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.02075117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.03249316, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.022340607, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.019993963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.019331615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.016675435, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.017321594, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23000, training loss= 0.016512394, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.020716924, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.024598166, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23300, training loss= 0.011695973, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.011229854, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.016075613, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23600, training loss= 0.024349716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.019905984, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 23800, training loss= 0.015327631, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23900, training loss= 0.028065369, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.10106119, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24100, training loss= 0.019873232, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.015728561, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.020672768, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.021832455, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.015129099, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.024018213, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.016174847, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.019985516, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.015376187, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.015497198, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.018275984, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.025739325, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.021319646, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.029932067, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.019496609, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.024342343, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 25700, training loss= 0.024610817, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.020334741, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.01607194, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.022646941, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.021574374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.023832265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.018355772, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.016414864, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.017077956, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.013376091, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.018010432, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.026147842, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26900, training loss= 0.013607013, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.013307994, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.017120635, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 27200, training loss= 0.020704098, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.021333864, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 27400, training loss= 0.0191469, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.017613854, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.013511273, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 27700, training loss= 0.023674961, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.014348688, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.011769794, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.014789983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28100, training loss= 0.023971885, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.015495807, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.020211823, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 28400, training loss= 0.0140815005, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.010935616, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.016707126, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.015963301, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.0132147325, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.016095024, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.014288427, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.012218188, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.012499634, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.01977323, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.01965049, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29500, training loss= 0.015946029, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.022441939, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.011517993, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.010531245, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.019080104, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.0414164, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.13181317, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.14945562, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 300, training loss= 0.10334303, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.03821994, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.06524138, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.076969825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.09203867, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 800, training loss= 0.04235993, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.07808732, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.042765666, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.05482655, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.04326545, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.0438648, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1400, training loss= 0.07513009, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.061846953, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.061521523, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.047975574, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1800, training loss= 0.05246785, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.047531806, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.058077943, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2100, training loss= 0.048622597, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.027828427, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.051581483, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2400, training loss= 0.047906227, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.046928093, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.05177334, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2700, training loss= 0.07199021, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.061947033, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.06954298, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.030731525, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.04231261, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.029102206, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.055180103, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.055381134, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.044925824, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.054569304, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.040198065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 3800, training loss= 0.03386272, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.046382748, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.03166837, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.04927244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.025322163, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.027929356, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.036414973, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.038737547, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.026170969, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.019096697, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.03249907, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.03208565, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.029422589, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.0355929, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.035421807, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5300, training loss= 0.03253377, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.032871824, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.043883067, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.03979773, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.029881017, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.04085965, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.04334824, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.035738576, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.04054791, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.031221362, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.020847986, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.02939374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6500, training loss= 0.040422756, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.031625398, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.026100444, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.03070567, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.03678893, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.030258501, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.06353397, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.036273427, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7300, training loss= 0.031948447, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.025311274, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.024726616, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.024363013, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.0327298, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.026323088, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.023016095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.020323597, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.029308356, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8200, training loss= 0.032643966, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.03828832, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.030354144, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.025152136, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.022298137, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.02819454, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.026740184, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.026458027, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.033464495, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.037327636, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.03257548, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.023591142, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9400, training loss= 0.031217817, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.03642045, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.03545762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.029465238, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.019719264, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.02106543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.025110936, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.023810368, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.017925417, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.030642081, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.044811174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.036227897, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.022117041, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.026626188, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.015927587, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.023563348, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.022251176, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.018373188, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.026043069, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.022456063, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11400, training loss= 0.02112448, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.027345661, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.023939522, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11700, training loss= 0.029726636, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.019727558, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.081599444, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12000, training loss= 0.08977628, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.03762524, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12200, training loss= 0.019485418, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.024528898, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.022814516, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.012935266, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.0257229, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.011576978, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.021116842, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.026834019, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.018452484, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.023174727, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.024180917, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.03224366, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.022296384, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.020317001, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.038338322, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.018798029, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.020254228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13900, training loss= 0.028598186, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.02799808, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14100, training loss= 0.02539787, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.03280414, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14300, training loss= 0.017737677, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.013074113, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.022551067, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.01707065, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14700, training loss= 0.021169763, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.020213198, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.0147835035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15000, training loss= 0.02405292, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.019019417, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15200, training loss= 0.021286683, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.018089216, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.020067895, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.02454931, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.020070096, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.02970065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.018085025, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.026025664, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.022561343, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.024876753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16200, training loss= 0.015379015, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.031047225, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.01878163, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.022626223, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.017909495, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.021678744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.01893542, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.016851854, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.027861068, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.016778903, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17200, training loss= 0.023670955, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 17300, training loss= 0.013502757, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.012275678, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.012838794, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.0231358, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.021069294, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.012279811, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.013054881, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18000, training loss= 0.018224016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.017978087, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18200, training loss= 0.020587206, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18300, training loss= 0.019740792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18400, training loss= 0.034483686, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.020277247, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18600, training loss= 0.01867398, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.02053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 0.018668257, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.022051107, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.021481896, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.016864607, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.01717359, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.011637786, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19400, training loss= 0.014652852, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.014628917, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.014389895, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.026386436, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.018001463, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.024723507, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.014589252, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20100, training loss= 0.016732683, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.015811192, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.012345865, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.019109959, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 0.010375808, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.017977316, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.013844094, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20800, training loss= 0.014801685, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20900, training loss= 0.018203193, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.017042922, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.014914833, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.011032676, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.020555701, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21400, training loss= 0.0170787, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.026711045, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.0113579575, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.018442135, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.01601999, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21900, training loss= 0.014880744, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.011654162, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22100, training loss= 0.013468378, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 0.0228213, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.014027795, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 0.015443138, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 0.014671391, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.017668294, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.0129615795, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.015054191, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22900, training loss= 0.010213751, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23000, training loss= 0.017810434, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23100, training loss= 0.009914657, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.015093399, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.012253963, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.009488202, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.013288097, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.018707803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23700, training loss= 0.014724751, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.010501179, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.0114344135, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.010286301, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.009764897, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.0129112825, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.009761625, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.013728146, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24500, training loss= 0.010275383, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.008887271, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.014670245, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.015767682, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.008879132, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25000, training loss= 0.018199792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.07463004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.009751088, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.014016906, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 0.0070614005, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.013512069, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 0.013780141, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 0.016811894, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25800, training loss= 0.017701307, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25900, training loss= 0.014261457, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.017208796, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.010312201, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.013482981, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.010922372, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26400, training loss= 0.01475223, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.012357313, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.014050226, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.011251775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.012302397, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.009762927, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.00971454, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.011754965, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 0.011773986, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27300, training loss= 0.0136708785, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27400, training loss= 0.0064171823, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.011944833, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.010729107, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.019086013, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.011800404, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.022326598, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.00911516, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.019805051, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28200, training loss= 0.0121005075, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28300, training loss= 0.014682428, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.026190933, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 0.013104866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28600, training loss= 0.015827313, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.01078908, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28800, training loss= 0.010690123, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.014370133, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29000, training loss= 0.011112873, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.0077773314, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 0.016082395, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29300, training loss= 0.00778965, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29400, training loss= 0.013322317, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 0.011413493, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29600, training loss= 0.007463573, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 0.010264855, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29800, training loss= 0.009144745, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29900, training loss= 0.010442668, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "Valid acc= 90.8 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.4689411, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.1504213, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.09967732, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 300, training loss= 0.11595808, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 400, training loss= 0.09199076, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.10398586, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.060150523, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.08211678, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.07200077, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.06926189, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.06516862, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.031322982, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.064003244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.033484045, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.06351404, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.08360168, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.043393, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.036807377, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.03623975, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.05742149, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.06303852, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.03290255, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.03941165, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.032276735, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.044382896, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.046537377, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2600, training loss= 0.042231254, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.07055341, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.06995503, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.045904163, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.07746702, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.0341668, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.054773584, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.04969726, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.032163825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.041124683, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.06527263, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.035827756, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.033592843, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.03769807, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.043634597, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.03122548, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4200, training loss= 0.031110555, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.03318703, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.060242258, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.037131496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.10786844, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.02522911, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4800, training loss= 0.030439794, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.029280834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.045895286, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.04142707, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5200, training loss= 0.05498659, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.02997387, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.03957875, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.040877976, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.05734728, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.02939687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.027334534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.043552365, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.04397206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.027824556, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.034299638, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.028749036, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.034817997, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.03217696, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6600, training loss= 0.0255239, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.028224543, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.02772611, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6900, training loss= 0.040000524, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.056636315, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.035585124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.02704325, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.03622452, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.026808297, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.02368855, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.028105536, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.024615375, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.030818608, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.028714929, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8000, training loss= 0.036898006, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8100, training loss= 0.02553264, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.02858826, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.048821364, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.023706326, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8500, training loss= 0.024801942, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.049750578, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.032410815, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8800, training loss= 0.040208913, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.028701099, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9000, training loss= 0.026994333, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.034795463, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.02758893, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.026886433, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.033183746, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.024785368, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.031997293, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9700, training loss= 0.022123773, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.037406117, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.036345404, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.026686538, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.04538353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.028681882, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.028697852, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 10400, training loss= 0.027546247, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.027063778, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.02358415, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10700, training loss= 0.02273055, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.028067628, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.028893262, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.02684908, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.025558608, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.02476739, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.02192832, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.036613524, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11500, training loss= 0.024522735, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.028202243, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.022902107, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11800, training loss= 0.032779213, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.017884111, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.017510686, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.03269277, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.028515391, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.03032163, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12400, training loss= 0.025919128, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.036445778, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.027554499, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.015659094, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.02190713, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.02227715, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.027707806, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.024393717, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13200, training loss= 0.031896323, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.066950604, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.028047692, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.035890646, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13600, training loss= 0.03807353, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.023328278, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13800, training loss= 0.035333805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.02243169, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.039082255, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.03632777, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.0220646, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.022284616, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.025623595, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.019931756, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.020240096, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.02487046, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.07668193, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.03578764, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.02473008, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.02005787, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.017746802, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.032095637, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.026493797, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.022343127, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.024980735, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15700, training loss= 0.018776482, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.02012346, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.03267032, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.01992669, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16100, training loss= 0.024394179, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.02254453, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.025070183, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.028582804, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16500, training loss= 0.026618598, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.021871928, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.015772708, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.020835368, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.022747735, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.024559664, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.027416185, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.03185292, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17300, training loss= 0.023167111, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.020145683, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.036968887, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.026812408, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.016960237, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.016089106, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.020363849, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.019666487, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.016308082, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.016560107, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.023192266, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18400, training loss= 0.021311125, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.019635765, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.013757011, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.022445565, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.026963672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.06567319, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.029125312, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.018331049, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19200, training loss= 0.022462895, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.018615443, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.017825015, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.01884583, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.037071265, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.03211115, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.06962617, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.023400275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.015171824, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.019471254, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20200, training loss= 0.020938586, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.017515201, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.026452137, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.025597561, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20600, training loss= 0.024746818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.017695766, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.01913685, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.02921022, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.020869877, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.019925306, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.020002205, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.021598348, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21400, training loss= 0.058263823, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.080764845, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.041498467, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.018633222, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.014999424, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.01606938, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.026153589, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.021648873, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22200, training loss= 0.025779448, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.01707993, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.018588025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.016302248, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.01808149, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.01847501, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.026573936, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22900, training loss= 0.014585139, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.017837858, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23100, training loss= 0.021774221, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.026530407, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23300, training loss= 0.021721823, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.022223305, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.034168117, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.018437602, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.020149881, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.021318728, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23900, training loss= 0.017905336, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.028012684, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.016108882, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.01716656, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24300, training loss= 0.012612724, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.022766134, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.01754312, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24600, training loss= 0.023775818, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.02010793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.022856897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.016522972, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25000, training loss= 0.014229599, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25100, training loss= 0.012559785, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.013983347, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.009142032, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.018397277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.0199255, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25600, training loss= 0.041328933, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25700, training loss= 0.036204536, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.02120519, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.015749332, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.016069638, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.0178449, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.014802579, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.013643253, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.01529344, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26500, training loss= 0.0147821205, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.01690464, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.015403632, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.01917614, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.013863316, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.015411492, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.012648413, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.0127093075, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27300, training loss= 0.021092333, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.023709346, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.019611541, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.014769365, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27700, training loss= 0.01983304, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27800, training loss= 0.012060068, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.020860795, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28000, training loss= 0.024806352, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.017244536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28200, training loss= 0.019698316, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.015991248, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.020030135, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.01753277, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.021853961, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.014860231, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.016730882, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.017466664, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.012277937, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.01862713, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29200, training loss= 0.013714575, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.01299736, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.01587591, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.012302118, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.012478505, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.013038365, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.025894217, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.019072488, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "Valid acc= 90.7 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 3 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.6048467, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.092926405, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.12536307, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 300, training loss= 0.08542236, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.06720658, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 500, training loss= 0.073162936, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.0766881, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.096133724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.07477729, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.099012576, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.07848581, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.04785597, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.058478016, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.055960085, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.07264527, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.059598397, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.09302569, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.04139365, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.062075295, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.07750222, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.0677126, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.062256318, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.07256719, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.07475541, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2400, training loss= 0.059896745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.03849237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.062134504, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.046222065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.04800448, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.033247218, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.052705545, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.06805133, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.051924217, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.038844254, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.04050425, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3500, training loss= 0.044993516, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.07006136, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.06572217, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.050375517, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.0461096, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.057514846, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.03440736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.046737935, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.053405054, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.051949646, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.06721898, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.06715711, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.04452861, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.051840264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4900, training loss= 0.0677923, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.039317884, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.026350675, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.059021223, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5300, training loss= 0.04702207, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.032858532, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.037561696, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.058957614, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5700, training loss= 0.02853877, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.023982702, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.03483103, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.037182156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.032691408, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.033006042, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.045926716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.041314747, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6500, training loss= 0.024232896, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6600, training loss= 0.038572166, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.033805322, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.040842444, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.039117515, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.03573758, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7100, training loss= 0.038384467, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.054308176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 7300, training loss= 0.024629481, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7400, training loss= 0.025442738, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.04217419, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.03204997, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7700, training loss= 0.024189686, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.036141146, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.046396893, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.017983513, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.035203934, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.03257562, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8300, training loss= 0.04361687, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.0308532, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.024387559, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.03381976, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8700, training loss= 0.026339883, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.032472815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.03369635, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9000, training loss= 0.034039885, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.029070733, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.02239221, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.024217408, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.027750356, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.019925473, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.027973402, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.032605138, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.023124559, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9900, training loss= 0.029851103, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10000, training loss= 0.035842452, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.027071659, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10200, training loss= 0.02884963, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.023141189, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.039227646, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.027933404, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.022856781, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.019098505, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.029020393, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.031154037, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.013176004, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11100, training loss= 0.02564334, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.019141724, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11300, training loss= 0.022678709, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.01795538, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.01629699, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11600, training loss= 0.024799166, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.019222688, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.016440809, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.039348077, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12000, training loss= 0.026124874, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.014215133, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.018832294, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12300, training loss= 0.02302947, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.016679574, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.019802954, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.015144554, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.032132395, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12800, training loss= 0.02050647, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.011671169, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.013036236, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.020776091, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.010970394, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.010776253, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13400, training loss= 0.01818143, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 13500, training loss= 0.011439382, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.01671532, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.013339839, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.010856258, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.0074685845, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.016035525, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.012667216, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.011796691, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.015840754, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.009041222, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.013551963, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.017332818, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.02380099, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.0134432465, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.012469021, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.0207361, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.013665432, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.020712445, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.030447215, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.009973214, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.0073636803, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.010050096, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.012202176, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15800, training loss= 0.008331909, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.019253464, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.011880165, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.010718177, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.0154409725, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.0174501, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16400, training loss= 0.0107300645, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.014246801, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.008577817, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.0075580636, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.011811796, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.008134053, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17000, training loss= 0.008632935, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.012533261, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.011391173, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.011160106, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.010988146, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.014914033, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17600, training loss= 0.008465584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.009225492, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.0086925635, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17900, training loss= 0.0065967175, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.007009434, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.012863989, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.008338359, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.007836302, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.007303928, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.015118259, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.012693553, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.008143332, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.008265912, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18900, training loss= 0.0148692345, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.014133632, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.014338267, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.012147104, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.0057604965, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.010159138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.007976456, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19600, training loss= 0.012121804, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.005679758, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.009816161, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.005256184, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.0072751506, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.0064249295, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.007323228, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.007319774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20400, training loss= 0.0058141733, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.0071056234, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20600, training loss= 0.0057432624, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.013379033, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20800, training loss= 0.0049378714, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.010543267, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21000, training loss= 0.005167547, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21100, training loss= 0.008229342, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.005388678, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.009589878, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.005188332, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.010195553, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.006836685, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21700, training loss= 0.0084560495, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.005776997, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.0077142245, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22000, training loss= 0.0082616545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.0072587878, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.006978158, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.004197139, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.0049847956, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.005690306, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.005365982, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.00375973, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22800, training loss= 0.010594114, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.00925609, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.006558381, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.006440305, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.0043900744, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.005171282, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23400, training loss= 0.012209705, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.006199152, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.006367122, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.0053017354, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.006171094, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.008791368, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.0068913023, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.004046337, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24200, training loss= 0.006052054, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24300, training loss= 0.007749104, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.006883671, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.0030235236, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.005699944, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24700, training loss= 0.004236167, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.004891467, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.0066211666, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.004458303, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.0060156123, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.007685335, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.030643983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.0043458273, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.0069872476, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.00560095, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.005453762, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.003991175, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25900, training loss= 0.0041823084, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.003943162, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.0032228497, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.0059566493, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.0036442892, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.0023939216, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.0055777044, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26600, training loss= 0.0045806854, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.008983056, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.0037573453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.0036446676, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.0064446987, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.0055936407, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.0026227836, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.0027459408, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.0036685977, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.0042626145, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.00392577, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.006178038, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.004245227, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.0030149252, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.0022771514, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.0038002357, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.0038477078, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.0023368795, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.0047255913, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.005098328, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.0025495708, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.0029738673, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.0036987567, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.013540684, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.003557251, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29100, training loss= 0.0044625863, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.0049002874, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29300, training loss= 0.0042323754, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 0.003493261, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.004137904, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0023771573, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.003968503, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.005133611, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.0034621258, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.4159569, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.13441153, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 200, training loss= 0.13787512, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.07659209, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.11794978, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.06318516, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 600, training loss= 0.15814696, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.07868198, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.09002261, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.10828659, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1000, training loss= 0.08147265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.09265652, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.07172808, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1300, training loss= 0.102403104, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.07059063, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.07342176, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.075782776, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.07937038, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.07719572, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.044772103, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.062367808, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.042965855, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.0690893, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.04492832, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2400, training loss= 0.07723102, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.08065342, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.07387734, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.07336339, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.050405677, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.04667598, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3000, training loss= 0.043402515, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.0566698, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.04298745, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.04606947, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.064497404, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.04219962, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.056387287, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.07302289, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.05809588, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.07483874, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.050081298, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.0728423, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.07531987, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.07108815, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.06820397, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.05132396, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.06028775, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.07154156, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.04929521, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.06011194, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.07970645, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5100, training loss= 0.067067176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5200, training loss= 0.032420672, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.035130538, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.041272555, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.039274994, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.05535754, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5700, training loss= 0.040950134, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.03250341, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.036023214, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.06821549, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.03642571, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.053112965, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.051818453, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.0603113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.052025165, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6600, training loss= 0.03874448, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.062471718, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.06295682, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.042476736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.057538725, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 7100, training loss= 0.055242263, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7200, training loss= 0.06521742, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.06650598, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.036417544, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.058527008, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.043242924, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.042859536, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.039893992, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.041945226, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.03379146, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.053600304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.038769744, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.03608083, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.05629857, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.044480767, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.036153458, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.06896001, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.045552067, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.046528485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9000, training loss= 0.04578496, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9100, training loss= 0.027985193, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.030705526, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.024258202, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9400, training loss= 0.04966432, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9500, training loss= 0.03446708, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.04393744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9700, training loss= 0.03854786, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.055447668, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.05740509, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.043267053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.052537948, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.03986228, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10300, training loss= 0.045583438, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.04233692, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.045833938, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10600, training loss= 0.050019667, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.037637547, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.034770288, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.034274064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.051670905, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.033378705, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11200, training loss= 0.036012594, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.049909767, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.02890231, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.05150131, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.037768014, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.028565735, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11800, training loss= 0.046953782, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.064090826, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.042519897, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12100, training loss= 0.033932928, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.029410481, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.02352184, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.0310105, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.026298132, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.041739173, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12700, training loss= 0.026623137, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.030498384, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12900, training loss= 0.05095258, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.027134102, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.027063388, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.036579106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.04617422, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.049454927, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13500, training loss= 0.041455086, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13600, training loss= 0.047495008, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.030615214, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13800, training loss= 0.024018219, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.021541387, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14000, training loss= 0.030834256, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.046198394, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.022621583, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.025716431, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.024307437, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.03134372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.030044135, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.02550943, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14800, training loss= 0.034367345, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.033041336, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.031265512, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.04833014, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.024829436, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15300, training loss= 0.03247111, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.030243246, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.02070725, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.02927076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.020909816, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.021376528, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.039146774, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.03692082, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16100, training loss= 0.042724352, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.03162417, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.020443385, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.039346464, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.027329221, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.031362362, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.025975978, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.032174326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.022615787, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.037815675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17100, training loss= 0.024613522, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.01881775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.032538667, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.022263234, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.09502187, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.0337824, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.02026639, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.027785629, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.019799657, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18000, training loss= 0.029821027, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18100, training loss= 0.037853982, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18200, training loss= 0.030625371, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.021585818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.025009915, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.028165467, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18600, training loss= 0.026507732, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.039377227, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.029124042, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.02909841, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.021652412, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.022165764, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19200, training loss= 0.021960985, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19300, training loss= 0.014487076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.02674724, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.029268388, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.016313363, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.03117261, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.021797817, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.022163369, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.023773951, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.056075037, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.03788379, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.07270247, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.024144074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.0204144, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.027005106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.026274294, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.023962451, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.016290482, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21000, training loss= 0.025788506, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21100, training loss= 0.02488482, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21200, training loss= 0.026549123, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.02115972, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.02537556, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21500, training loss= 0.024161352, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.018653871, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.032379862, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.03730113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.020360215, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 0.018172218, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.03706091, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.017512422, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.021788202, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.017321367, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.017528027, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.025443006, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.023263622, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.022606622, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.012200351, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.028427048, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 0.020170283, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23200, training loss= 0.02042359, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.038157083, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23400, training loss= 0.042728703, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.014630811, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.017900173, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.019734113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.014288941, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.020690639, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.020622352, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.015462781, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.017703632, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.027670084, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.024874985, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.023501847, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.017456116, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.024253337, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.020476807, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.06014858, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.027873693, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.018172339, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.02560923, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.016875543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.021462932, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.02477005, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.021424724, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.017190406, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.019482411, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.015690386, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.014093409, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.012177541, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.019541588, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.020477628, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.021808071, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26500, training loss= 0.028485632, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26600, training loss= 0.021102943, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.017005801, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.019027926, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.018049236, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.015440982, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.0153588345, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.021726694, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.016824834, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.0142572615, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.014733363, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.015657458, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27700, training loss= 0.013560139, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.018873693, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.015172682, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.015882218, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.01700878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.018204696, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28300, training loss= 0.011592081, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.015327479, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.0139069315, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.016217127, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.014446333, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.017830286, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.014301296, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.015807822, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.0118134385, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.019069675, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.014250546, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.016112586, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.017397609, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.01439856, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.018393192, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.030230768, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.020893883, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.8358762, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.09718889, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.07152918, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 300, training loss= 0.044759005, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.09823325, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.073185004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.072595894, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.077910215, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.09031445, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.056014195, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.051340573, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.06998768, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.06672728, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.054197565, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.048641693, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.06588963, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.051277034, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1700, training loss= 0.07504189, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.057358973, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.072924145, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.05019679, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.06805594, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.08353925, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.05917883, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.052867424, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.068745516, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.03588539, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.041425895, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.06530218, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.06239921, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.0499568, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.038893767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.058660433, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.03912907, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.047930103, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3500, training loss= 0.05677965, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.0560204, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.049048655, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.0427171, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.04345747, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.039843973, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.061488837, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.055036224, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.05055314, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 4400, training loss= 0.036481895, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.05977515, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4600, training loss= 0.03356, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.027279198, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4800, training loss= 0.03511487, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4900, training loss= 0.034968928, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5000, training loss= 0.057010274, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.044301327, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.04736335, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.024064902, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.028058678, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.050037026, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.027839987, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.053997602, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.03974849, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.036663428, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.044155672, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.055560872, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.038400356, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.041955322, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.04091721, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.04274006, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.043605298, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.040662207, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.050232824, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.029636726, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.0349538, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.03953004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.024508415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.02105169, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 7400, training loss= 0.03029155, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.031336598, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.034684166, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.025541423, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.03532788, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 7900, training loss= 0.022854414, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.030738965, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8100, training loss= 0.037890665, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.029457714, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.04360929, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8400, training loss= 0.04626189, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.037148573, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.02436474, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.019846791, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.02362717, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.018589364, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9000, training loss= 0.036732897, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9100, training loss= 0.024368368, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.030120349, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.030905258, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9400, training loss= 0.0285738, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.037133116, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9600, training loss= 0.04420526, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9700, training loss= 0.033028167, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9800, training loss= 0.038126413, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.033418003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.036199853, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10100, training loss= 0.020830708, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.03761585, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.023358244, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10400, training loss= 0.03340243, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.030430425, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.021612924, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10700, training loss= 0.019133266, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.028589979, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.023740135, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.025115866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11100, training loss= 0.025320295, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.01980545, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11300, training loss= 0.027016044, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.017573817, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.020690277, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.02641952, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.035108052, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.03528678, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.017703597, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.02205283, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.029504627, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.01663076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.014369073, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.018285766, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.0292604, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.022260312, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.032437027, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12800, training loss= 0.025480844, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.023610823, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.029947441, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.024121767, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13200, training loss= 0.026361927, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 13300, training loss= 0.019279502, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13400, training loss= 0.01904984, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.016575584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.020972207, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.020140775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.020849638, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 13900, training loss= 0.021386875, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.027418358, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.011151484, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.031079529, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.014133865, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.018571835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 0.02478525, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.01738349, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 14700, training loss= 0.014946118, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 14800, training loss= 0.012625527, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14900, training loss= 0.008791333, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15000, training loss= 0.013799239, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15100, training loss= 0.017038124, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15200, training loss= 0.024408124, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15300, training loss= 0.024039496, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.009535156, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.019220825, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.010766844, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15700, training loss= 0.01924875, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.01911109, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.028691374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.023619657, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16100, training loss= 0.0153557435, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 16200, training loss= 0.017644985, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.01910955, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16400, training loss= 0.022100275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16500, training loss= 0.022450421, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.019442828, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.0150198, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.014517799, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.016511358, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.016697163, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.016969157, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.016055316, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.021946106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.017914504, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.012569819, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17600, training loss= 0.01857172, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.008003244, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.019013219, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.010971677, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.014892156, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.016087778, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.014522938, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.012253389, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.011656798, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.014509998, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.021897856, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18700, training loss= 0.012704536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.010701098, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.020208027, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.014336942, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.014091312, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19200, training loss= 0.0103018815, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.01613091, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.019247157, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.041416414, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19600, training loss= 0.009357972, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.011723786, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.011710806, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.014346253, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20000, training loss= 0.007923989, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.013327367, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.017618226, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.023182001, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.016448326, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.025551528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.012101314, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20700, training loss= 0.008649334, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.014905635, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20900, training loss= 0.01148735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.013398657, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.015999138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.0120517295, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.015816765, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21400, training loss= 0.009102916, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21500, training loss= 0.011533923, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21600, training loss= 0.01004234, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.01464729, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21800, training loss= 0.011231517, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.01812832, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22000, training loss= 0.007085887, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.014387313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22200, training loss= 0.010173404, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.011527283, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.013035789, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22500, training loss= 0.010891316, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.011740748, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.015929941, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22800, training loss= 0.0190987, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.010990529, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.007320029, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.0074603325, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.010047229, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 0.009467672, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.008828411, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.009201873, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.012942865, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23700, training loss= 0.016117733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.007902731, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.008746734, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.010419581, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.00799384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.0068303375, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24300, training loss= 0.00883973, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.011799014, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.01756072, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.015091921, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.015413112, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.0083941035, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.00937469, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.010550557, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.012145102, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.009291719, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25300, training loss= 0.008912378, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 0.0115541015, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25500, training loss= 0.011917374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25600, training loss= 0.004576125, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.011655848, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 0.01259453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25900, training loss= 0.005902989, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.009242399, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26100, training loss= 0.008049055, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.006400453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26300, training loss= 0.009023206, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.008093643, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.0057715992, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26600, training loss= 0.0077126166, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.0076763295, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.006687581, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.011891524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.03451803, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.009086368, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.009001529, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.008971746, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.00538036, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.008751391, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.01105715, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.007894777, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.010607449, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.008493347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.008063491, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28100, training loss= 0.009632906, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.016416587, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.008686729, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.006607392, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.009222898, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.008222865, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.009666843, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.0056702597, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28900, training loss= 0.008230327, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29000, training loss= 0.00761607, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29100, training loss= 0.008452607, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.010596691, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.010016727, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.010276915, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.01096054, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29600, training loss= 0.0070344037, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.009955031, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.009224809, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.0065589463, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 85.80060577392578 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.6910222, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.12634061, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.086127974, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.08244483, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.072484456, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.092086025, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.08286452, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.10371495, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.08041407, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.08284756, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.09458849, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.054139603, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.057740673, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.069471225, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1400, training loss= 0.08256349, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.07249882, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.064913206, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1700, training loss= 0.042819224, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.041108925, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.06480452, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.07673991, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.058541015, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.049615838, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.06307464, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.044901606, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.048309173, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.046380617, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.05969618, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.042787846, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.06388874, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.037498575, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.058336318, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.050081264, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3300, training loss= 0.049964353, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.046700403, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.036082126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.048572723, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3700, training loss= 0.051546786, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.051774256, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.037679043, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.055381913, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.046728525, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.027637426, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.048890863, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.04181381, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.074226834, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.05047165, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.026653793, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.064226195, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4900, training loss= 0.042274877, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.045299146, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.04956388, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5200, training loss= 0.04981409, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.055937003, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.035280313, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.034974094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.04073122, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.033935126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.05108482, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.05026086, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.036670893, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.031521674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.04366668, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.03862303, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.03194523, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.040652722, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.030939423, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.04116713, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.03252986, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.042062655, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.054515023, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.043818768, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.029430533, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7300, training loss= 0.033575974, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7400, training loss= 0.03094861, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.052598093, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.058919594, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7700, training loss= 0.06380771, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.040110417, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.028519439, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.048008725, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8100, training loss= 0.032593265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.032826472, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.028305924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.042765327, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.041461926, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8600, training loss= 0.035401687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.037060045, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.031027693, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.027211398, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.050495677, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.046158653, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.054427933, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.04150064, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.040705014, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.030829493, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.047766827, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.027699951, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9800, training loss= 0.039440654, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9900, training loss= 0.063275605, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.033968564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.028195314, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.04540739, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.032946303, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.049987104, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10500, training loss= 0.043167565, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.036594793, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.032790948, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.02687945, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.02724156, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.03499737, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.035099104, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11200, training loss= 0.027895674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.029312234, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.03381088, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11500, training loss= 0.03258963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.03328198, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.018383035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.038152423, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.03569206, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.0649205, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.03529891, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.039725818, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12300, training loss= 0.03133352, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.034844607, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12500, training loss= 0.02896287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.023859391, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.026281457, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.11062825, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.019089457, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.033082146, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13100, training loss= 0.029037721, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.015741235, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.03252503, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.015807958, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13500, training loss= 0.036811944, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.02877007, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.030327171, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.023213338, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.0238689, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.03984853, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.02567138, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.033296164, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.026004681, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.031146988, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.028274164, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.012867173, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.035572, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.040634267, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.032162055, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.024358604, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.023448633, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.023183752, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.02448732, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15400, training loss= 0.046868768, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.036699384, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.022537956, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.020209981, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.021303676, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.026740512, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.022564897, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.027323412, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.022734245, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.031426564, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16400, training loss= 0.02226772, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.03341048, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.023379114, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.025596073, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.024925042, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.029797781, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.027248964, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.022373222, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.029220225, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.026461476, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.024019249, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.032628573, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.026530903, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 0.026452113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.028455282, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.02486036, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18000, training loss= 0.027527126, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.02235252, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.026536915, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.018092616, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.02177956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.018016784, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18600, training loss= 0.018289885, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.023913132, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18800, training loss= 0.021907486, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18900, training loss= 0.04421305, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.035449784, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.022806076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.021037078, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.035080504, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.026699765, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.019640455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.020301033, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.032663777, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.023274513, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.02665285, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.02907892, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.015702743, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.04441728, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.02250528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.025172649, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.018081002, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20600, training loss= 0.031098414, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20700, training loss= 0.016369188, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.026690472, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.023440111, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.024033701, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.02723612, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.0118999025, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.024753522, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.04538123, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.041818324, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.023263063, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.029727887, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.020573739, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.016538205, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.013862501, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.016934758, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.023001986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.019885402, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.022249628, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.02764481, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.0155919455, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.02683636, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.025139894, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.023231592, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.0190704, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23100, training loss= 0.018204251, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23200, training loss= 0.023292778, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.024524953, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23400, training loss= 0.015009868, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.01944872, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.020130469, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.02081942, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.020040128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.019789878, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.018944878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.02456672, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.020115856, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24300, training loss= 0.03068626, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.0110666435, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.032708846, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.018404122, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.017428478, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.028140584, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.02360261, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.02809027, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.026655156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.02636459, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.015957402, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.020223742, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.01797528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25600, training loss= 0.01710143, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.013999306, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.020271325, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.019664716, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.019329613, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.01854362, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.025251871, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.014684692, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.019145494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.02104144, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.01636846, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.013543911, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26800, training loss= 0.018297417, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.02066567, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.017054735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.021007655, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.018144581, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27300, training loss= 0.015924988, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.020954646, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.012951384, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.019150801, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.022343213, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.024898877, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.022459222, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.014085703, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.019107187, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.020169865, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.015868086, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.019520024, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.018050913, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.033080097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.017239757, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.022027435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.016709682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.019399993, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.016728038, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.010050051, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.018540451, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29400, training loss= 0.01846153, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.020609487, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.016140569, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.022071084, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.024407677, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.01593845, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.154821, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.06686856, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.05382456, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.061040897, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.062164206, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.0704201, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.07172995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.047522344, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 800, training loss= 0.06617519, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.059244208, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.07467834, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.05981351, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.096689306, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.054600917, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.04036708, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.07574567, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.056315124, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.07014845, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.039326947, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.07015571, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.08654218, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.04183573, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.042246945, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.05590752, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 2400, training loss= 0.06968604, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.0648375, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.031522095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2700, training loss= 0.045488603, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.049262952, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.037642583, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.045085777, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.056916613, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.04885551, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.025193138, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.04689385, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.051001158, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.058652014, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.037247676, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.059900988, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.05219943, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.05668594, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.052471437, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4200, training loss= 0.03522668, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.049523942, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.048287265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.03829174, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.042009626, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.048602737, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.050124984, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.05334781, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.046689518, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.04791256, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.040445127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.056423385, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.03718715, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.03513031, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.039308116, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.04990563, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.06796573, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.030520951, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.02560546, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.04354854, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6200, training loss= 0.032638054, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.030006863, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.026625182, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.028986001, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.027647676, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.0223633, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.049875155, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.040352702, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.02205156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.034728415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7200, training loss= 0.045911785, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.028886963, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.027790772, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7500, training loss= 0.046224043, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.028322913, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.03656449, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.029686525, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.03816586, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.03889474, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.030493012, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8200, training loss= 0.017307673, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.03536648, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.022862863, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.030052114, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8600, training loss= 0.053972073, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.025336267, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.036081515, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8900, training loss= 0.030329129, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.04107491, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.043320067, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.030037701, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.046471722, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.025085723, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.02288389, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.020535946, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.030120483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9800, training loss= 0.012800077, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.024840198, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.035223607, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.0322783, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10200, training loss= 0.017145578, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.028508494, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.047635715, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10500, training loss= 0.037313364, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.028688254, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.036008194, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10800, training loss= 0.02379913, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.02080585, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.02934593, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11100, training loss= 0.028424777, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11200, training loss= 0.028654106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.02508857, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11400, training loss= 0.029655378, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.032037407, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.05248742, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.022638353, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.02727617, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11900, training loss= 0.018958926, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.020838669, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.024992201, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.027533438, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.028388837, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.018777445, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.018713113, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.025681129, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.029697634, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.028649226, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.02121045, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.018042559, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.016025214, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.021393003, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.027974984, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.026808135, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13500, training loss= 0.01920423, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.023750264, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.024216447, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13800, training loss= 0.030619368, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.023724623, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.032289304, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14100, training loss= 0.019699533, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.02596209, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.015135147, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.010603469, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.016739465, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.018211061, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.018197834, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.025725743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.023798276, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.013229757, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.024834095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.017521817, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15300, training loss= 0.020600412, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.018908272, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.012196953, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15600, training loss= 0.027357172, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15700, training loss= 0.023628956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.022430398, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.02183872, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16000, training loss= 0.022512512, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.014760537, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.013556809, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.024619631, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.013208358, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.020974373, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.018875651, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.020495689, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.021492055, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.017967526, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.01678627, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.022354905, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.025973223, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17300, training loss= 0.07627847, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17400, training loss= 0.027037805, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 0.020614633, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17600, training loss= 0.013457676, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17700, training loss= 0.019980032, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17800, training loss= 0.017603412, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.014876771, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.014363771, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.012373829, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 0.016082738, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18300, training loss= 0.010683188, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.024724137, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.021125872, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18600, training loss= 0.011090172, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.19772668, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.022649743, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.014116884, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.014832803, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.025316121, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19200, training loss= 0.022044282, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.014425085, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.017844906, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.014946502, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.017299294, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.017222326, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.020015782, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.011230378, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.014401458, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.010541139, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20200, training loss= 0.013959523, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20300, training loss= 0.009422645, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.016510941, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20500, training loss= 0.009895903, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.014899621, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 0.011010075, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 0.014901432, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.012067253, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.011910761, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.020900844, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.016976941, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.013121459, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.011554983, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.06284568, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.025519421, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.011863494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21800, training loss= 0.009801765, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21900, training loss= 0.01141352, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.018624913, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 0.013871509, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.010012401, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.012768289, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22400, training loss= 0.0150174275, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22500, training loss= 0.013809608, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22600, training loss= 0.015915796, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 0.012747143, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22800, training loss= 0.019412208, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22900, training loss= 0.011210043, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23000, training loss= 0.010747456, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23100, training loss= 0.01120386, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.008611745, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23300, training loss= 0.012236631, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 0.013207683, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.013704303, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23600, training loss= 0.008405029, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23700, training loss= 0.011839309, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23800, training loss= 0.017892804, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23900, training loss= 0.015623734, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24000, training loss= 0.011922349, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.012742414, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.012552951, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24300, training loss= 0.0085345665, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.008140419, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.00938414, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.009040362, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.02086184, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24800, training loss= 0.0176051, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24900, training loss= 0.0102844685, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25000, training loss= 0.009442763, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25100, training loss= 0.005423592, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25200, training loss= 0.014412777, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25300, training loss= 0.007476228, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.014071332, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 0.009958522, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.007960848, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.01013203, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25800, training loss= 0.015804682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.011043564, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26000, training loss= 0.007671769, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26100, training loss= 0.009734518, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26200, training loss= 0.014023144, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26300, training loss= 0.007952114, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26400, training loss= 0.017576898, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.016296571, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.014094025, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 26700, training loss= 0.011222468, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0135204885, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26900, training loss= 0.011532067, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 27000, training loss= 0.011229601, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.008399884, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27200, training loss= 0.010038612, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.0071497005, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27400, training loss= 0.008995173, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 0.010865317, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.009662775, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.013324786, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27800, training loss= 0.0054872264, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.010674658, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 0.008857736, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.04358949, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28200, training loss= 0.008726325, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.009608263, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.008124163, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.01218176, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28600, training loss= 0.008900096, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.008906886, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.01317696, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.005734512, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.011077698, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.0054035424, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.008902318, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.008621706, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.00980703, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.010422538, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0065441164, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.009571795, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.009586624, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.009681336, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "Valid acc= 91.0 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.4600041, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.099516794, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 200, training loss= 0.10845482, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.08027019, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 400, training loss= 0.09115183, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.071470626, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.06929095, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.05275506, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.05881581, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.046392363, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.05233991, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.04152917, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.06888244, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.057806555, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.058809146, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.074079186, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.047168273, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.053079903, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.04427859, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.06076863, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.068447836, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.05632098, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.041070983, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.05322871, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.05513995, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.026663354, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.055566564, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2700, training loss= 0.070191376, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.06325949, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.03553366, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3000, training loss= 0.048420537, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3100, training loss= 0.052754164, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.059016198, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.0741169, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.044407163, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.043358877, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.04286391, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.040783647, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.03949381, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.048212785, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.04231222, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.04348565, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.03405614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.036343977, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.027235452, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.05172558, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.041935906, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.03638131, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.105193846, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.057010036, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.041036263, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.051532675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.031565387, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.045545626, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.05763659, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.038337864, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.03848066, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.03165584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.044581957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5900, training loss= 0.040238522, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.031189892, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.037941262, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.032826237, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.022247711, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6400, training loss= 0.036371097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.031834155, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6600, training loss= 0.038400076, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.035129156, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.046329785, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6900, training loss= 0.04413412, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.11111733, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.03597795, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.030851036, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.02406058, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.03885946, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.04522805, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.029927455, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.024822662, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.056732338, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.059428755, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.0292813, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.023655973, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.036303204, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8300, training loss= 0.023741575, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.025787193, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.021139733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.036106776, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.039807532, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.032729592, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.03342551, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.038594812, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.04333035, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.029242642, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.037278134, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.033125065, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9500, training loss= 0.022780022, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.030402292, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.031419713, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9800, training loss= 0.02763766, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.032952998, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10000, training loss= 0.04096303, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.029581506, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.030040074, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.031787794, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.03016922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.03487411, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.034921136, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.02773805, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.02875647, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.03137618, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.035174415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.02717566, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11200, training loss= 0.04083295, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.073108636, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11400, training loss= 0.047912765, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.026811814, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.034471367, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11700, training loss= 0.025559502, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.026044719, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.0368807, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.023190884, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.027957315, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.035932228, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.017928988, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.030461643, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.03123767, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.02866694, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12700, training loss= 0.02945262, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.029135484, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.026440019, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13000, training loss= 0.01910974, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.021788763, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.016921245, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.03544371, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.030689662, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.031322014, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.03614411, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.021923693, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.040525917, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.0379568, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.024058845, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.04291899, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.05023644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.019141974, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.024238868, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 0.03216469, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.03772756, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.018713905, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.018284252, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14900, training loss= 0.019305853, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.03382721, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.02735986, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.023258504, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.020492958, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15400, training loss= 0.021965588, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.037781622, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15600, training loss= 0.016470056, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.03122895, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.037608825, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.035413828, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.03119977, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.01798397, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.022714853, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.021146735, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.022436246, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.022221329, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.025008284, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.024694057, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16800, training loss= 0.019116728, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.019783333, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.017210888, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.019675892, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.035548992, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.034865286, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.018098624, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17500, training loss= 0.08878564, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.02362789, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.019038975, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.029346999, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.01229364, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.028616484, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.032303717, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.021378288, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18300, training loss= 0.038123317, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.021365128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.020857574, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.030840004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.023209382, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.025801003, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.019814363, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.018953906, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19100, training loss= 0.01957141, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.020679817, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.026216574, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.026503012, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.024386583, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19600, training loss= 0.01935272, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.03324947, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19800, training loss= 0.01708971, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19900, training loss= 0.013899783, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.020324035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.026794327, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.021719547, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.02292092, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.02095617, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.024102246, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.016826417, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.016847847, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.014607906, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.025275035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.016086267, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.021164637, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.01898309, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.013434625, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.025213739, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.026236085, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.020864038, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.023623055, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.031344, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.01369842, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.025216559, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.013218607, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.023964327, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.019389339, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.017465465, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.014437238, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22600, training loss= 0.015682288, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.01736637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.023882004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.02014572, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.04928393, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 23100, training loss= 0.02164362, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.026311878, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.026468126, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.023843832, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.013620509, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23600, training loss= 0.018977396, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23700, training loss= 0.018243153, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23800, training loss= 0.018138941, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.017075967, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24000, training loss= 0.018319618, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.015249201, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.01816903, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.01531789, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.016992424, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.012220264, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.024068957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.02087076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.021810057, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.013422052, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.019767484, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25100, training loss= 0.014373528, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25200, training loss= 0.022143174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.019845802, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.01508396, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.01668569, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.019007703, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25700, training loss= 0.016418297, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25800, training loss= 0.017047638, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.021575993, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26000, training loss= 0.013954838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.14139238, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.062433448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 26300, training loss= 0.014288364, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.024590923, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.020595413, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.022924064, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.01801863, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.016265094, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.019505829, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.016375965, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.013776389, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.014260196, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.016803911, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.012365976, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.0146479495, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.011643076, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.025895152, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 0.018280556, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.017193107, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.013186591, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.013496871, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.01170477, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.01406455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.013373308, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.02079527, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.012989026, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.013690168, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.02050619, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.015422827, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.014187707, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.015538809, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.018188903, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.01264618, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29400, training loss= 0.019806769, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.011192613, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.010365136, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.02265916, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 29800, training loss= 0.0666106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.013501136, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 86.10271453857422 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.151212, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.069092184, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.09514454, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 300, training loss= 0.09016178, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 400, training loss= 0.0819884, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.09377983, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.038995247, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.05454987, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.06967211, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.04871671, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.053923078, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.059464235, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.07672534, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1300, training loss= 0.056522116, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.056435823, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.042563815, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.050738283, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.067625254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.057801433, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.051001415, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.07407813, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.08541341, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.033928398, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.040957786, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.045010775, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.04565454, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.05400469, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2700, training loss= 0.03620016, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.05169726, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.047601663, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.035810813, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.03545414, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.036559634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.05060651, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.05196532, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.023154775, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.05903084, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.047919504, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.044106476, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.043217156, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.030511424, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.034307398, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4200, training loss= 0.06324069, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.035200644, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.041405637, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.044606376, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.031813674, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.035026934, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.026479617, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.02780685, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.03672036, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.033130765, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.031593706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.029012963, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.03547657, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.050131314, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.027179807, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.024257015, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.027246961, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.03874767, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.06065173, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.030617684, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.035630632, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.029740326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.0426661, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.03883137, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.026329873, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6700, training loss= 0.031348787, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.028820679, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6900, training loss= 0.02543792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.026996458, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.025002277, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.02239541, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.04378281, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.023512239, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.030581892, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.032501623, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.028342582, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.03584594, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.061335362, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.024739372, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.04120011, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.026660997, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.028830806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.028060198, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.022373473, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.02636105, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8700, training loss= 0.021048293, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.020540128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.024759196, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.033863835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.03366579, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.033231538, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.028997434, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.020396832, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.028626943, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9600, training loss= 0.02610593, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9700, training loss= 0.02600528, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9800, training loss= 0.019218475, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.014304756, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.027087726, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.032359198, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.032023817, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.029549083, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.032251514, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.024224162, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10600, training loss= 0.019914834, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.03794596, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.06551088, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.021825204, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.022310961, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.023376236, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.021609642, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.01849536, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.028488295, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11500, training loss= 0.015883557, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11600, training loss= 0.023837259, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.032160927, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.026033364, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.028028037, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.021672959, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.02522803, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.020226395, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.040355302, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 12400, training loss= 0.02012788, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12500, training loss= 0.023181759, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.024285093, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.024437027, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.018625407, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.021682581, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.020881167, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13100, training loss= 0.021156706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.028855063, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13300, training loss= 0.023896758, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13400, training loss= 0.027331272, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.017576648, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13600, training loss= 0.020745153, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.014501275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13800, training loss= 0.027537124, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.013250029, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.023071613, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.020595398, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.027491337, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.013521495, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14400, training loss= 0.021101411, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14500, training loss= 0.031395495, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14600, training loss= 0.022113865, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.021963123, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.020002622, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.022513287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.028048988, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15100, training loss= 0.019728592, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.02216562, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15300, training loss= 0.017470943, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.013824357, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15500, training loss= 0.020955252, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.023754412, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.0356689, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.028332762, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.016360402, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.023134701, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.0164211, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.019726375, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.023285052, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.02263886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16500, training loss= 0.019379092, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.019698966, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16700, training loss= 0.017872596, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.023016421, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.024541782, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.018646615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.029403033, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17200, training loss= 0.01495314, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.030432545, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17400, training loss= 0.017117955, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.054974087, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.037741292, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.01903077, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17800, training loss= 0.021626508, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.017866721, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18000, training loss= 0.013757831, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.023814583, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.018355949, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.014402142, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.015392826, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.010913406, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18600, training loss= 0.014832142, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.021823393, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.010099823, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18900, training loss= 0.023374243, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.023674082, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.019305754, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19200, training loss= 0.011745123, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.024434868, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.01322727, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 0.019521803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.023509149, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.037158303, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.03231181, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.024214938, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 0.013056924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.022148078, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20200, training loss= 0.0154564455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.014455228, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20400, training loss= 0.012103123, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.013507918, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.0152047705, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20700, training loss= 0.010120151, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 0.014178375, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20900, training loss= 0.016842933, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.017571116, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21100, training loss= 0.017196193, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.010446533, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.012269219, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.014104457, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21500, training loss= 0.014032877, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21600, training loss= 0.016760081, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 0.0123713445, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21800, training loss= 0.012743494, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 0.009803966, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.025591651, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.012485848, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.01777468, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.012409562, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22400, training loss= 0.010469179, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.017065577, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22600, training loss= 0.010842514, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.016125284, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.01600426, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.010738075, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.015992923, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23100, training loss= 0.01705964, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 0.009713589, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23300, training loss= 0.015375808, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23400, training loss= 0.014151165, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.0136699015, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.013887153, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23700, training loss= 0.012449192, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23800, training loss= 0.009481293, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.034034368, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.012954241, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.010849333, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24200, training loss= 0.011417694, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.014245765, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.012473004, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.017686743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.011824587, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 0.018965637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.01717996, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.0119357845, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.013398939, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.017228516, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25200, training loss= 0.011347387, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25300, training loss= 0.013143313, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.010966026, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 0.016284715, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.0065028802, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.018033374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.00930224, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.00785042, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.012302049, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26100, training loss= 0.009754889, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.012174477, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.011247121, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.009684255, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.0078067863, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.008919603, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.011713958, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.009905294, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.009363652, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.016545739, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.008824647, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.0111228665, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27300, training loss= 0.006673789, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.010833452, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.017094983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.017075637, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.015894633, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.012459993, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.011706206, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.01530888, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.008018227, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.008748656, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28300, training loss= 0.010935532, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.0064320164, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.011506085, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.011549822, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28700, training loss= 0.009446657, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.008535743, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.013576226, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.014084494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.006670929, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.0108103035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.012370246, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29400, training loss= 0.009642637, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.011549875, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0066732285, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29700, training loss= 0.006820493, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29800, training loss= 0.008597994, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.01289574, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.6808566, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.121945806, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.18836392, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.11763544, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 400, training loss= 0.12386129, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.029345354, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 600, training loss= 0.07616571, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.046979655, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.061802164, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.07906088, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.037536286, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.04404385, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.068845995, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.027559603, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1400, training loss= 0.06546269, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 1500, training loss= 0.055627353, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.051655803, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.03858389, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.038730223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.0668953, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.047718376, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.05557653, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.06896432, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.061703373, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2400, training loss= 0.045920067, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.048324555, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.038383473, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.06867917, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.047148157, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.05355394, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.04780364, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.03905067, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.054807153, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.048605878, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.044528384, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.06710945, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.036424614, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.040442985, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.046906162, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.050357018, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.03486534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.04827981, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4200, training loss= 0.032968346, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.040666718, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.028604634, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.04542396, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.11609326, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 4700, training loss= 0.030796954, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4800, training loss= 0.024943344, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.02571546, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.033486534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.03913932, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.03313558, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5300, training loss= 0.035515703, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.027759625, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.039802913, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.041432165, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5700, training loss= 0.051677693, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5800, training loss= 0.045411844, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.02810156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.037767883, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.03574423, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.04446423, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.038663086, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.04359866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.03782093, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.024428077, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.03950731, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.03908129, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.028299812, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.03835529, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.032203175, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.044489387, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7300, training loss= 0.043279752, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7400, training loss= 0.030874584, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.02830536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.030782511, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.030127887, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.033084743, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.026672266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.0303797, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.030182885, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.027808944, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.031380627, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8400, training loss= 0.031961456, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.027755948, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8600, training loss= 0.03608681, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.026227364, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.045537196, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.025440913, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.03207372, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.0412504, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9200, training loss= 0.0330252, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.023278588, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.03162832, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.023359273, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.021436473, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.019514183, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.1639654, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.04197972, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10000, training loss= 0.028072635, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.03732987, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10200, training loss= 0.024456931, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.024916919, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.026550055, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.013925357, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.024718285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10700, training loss= 0.030389752, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.03361175, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.023485964, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.036268137, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.025139073, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.026495388, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11300, training loss= 0.021890083, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.031325404, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.028801624, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11600, training loss= 0.025456872, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.03118102, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.025556244, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.019072877, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.03638498, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.031202568, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.018773207, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.023465775, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.027033458, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.022601783, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.028492428, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.022196958, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.035215396, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.024030304, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.021392025, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13100, training loss= 0.025101058, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.023570357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.024295846, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.0312656, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.025892556, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.030930098, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.042706598, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.034601707, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.019134922, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.027946658, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.022295894, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.025698211, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.020958984, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14400, training loss= 0.02421367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.017267639, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.023312181, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.021958917, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.030219125, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.02377667, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.022877542, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.013601777, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15200, training loss= 0.019599074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.022802731, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.021527113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.016631309, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.030699214, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.024234638, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15800, training loss= 0.01816189, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.025722416, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.013527934, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.019513711, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.02290054, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.017972207, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16400, training loss= 0.016429884, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.017421337, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16600, training loss= 0.0241969, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.027833227, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.021657163, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.022264306, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17000, training loss= 0.025785936, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.024707835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.021707067, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.15929314, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.03215729, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17500, training loss= 0.03464028, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.014259419, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17700, training loss= 0.027769525, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.026122143, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.028760957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18000, training loss= 0.022039283, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.016884567, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.016128104, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18300, training loss= 0.021267977, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.021567022, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.020094106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18600, training loss= 0.023574378, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.022469113, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.039470095, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.03561247, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.022883525, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.02230574, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.02094917, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.016832342, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19400, training loss= 0.022548331, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.018910017, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.019433659, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19700, training loss= 0.018593743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.018463457, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.021803956, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.014566028, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20100, training loss= 0.019138219, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20200, training loss= 0.018291105, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.011071659, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.019537637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.01438583, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20600, training loss= 0.0140990205, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20700, training loss= 0.017429883, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.021139102, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.02251609, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.032936037, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.019658705, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.017835915, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.015310175, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.011219568, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.019245947, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.015015932, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.020980941, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.018396212, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21900, training loss= 0.020669645, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.0112508815, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.015305132, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.015982544, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.022447025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.10359361, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.021415057, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22600, training loss= 0.02766768, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.01961116, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22800, training loss= 0.013551343, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.022459637, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.026054049, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.01765982, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.027030142, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.01872452, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.018956302, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.018069293, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.020288244, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.013822025, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.015134347, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.01344451, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.014046863, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.013986649, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.014874195, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24300, training loss= 0.018609637, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.008787714, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.014280049, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.01053903, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 24700, training loss= 0.0205443, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24800, training loss= 0.012594715, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.022396626, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.019448549, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.016021807, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.023620725, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.01798275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.016450146, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.01570753, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.012047356, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.01925543, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25800, training loss= 0.017657764, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.009850022, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.008805677, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.014355291, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26200, training loss= 0.023937894, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.018094223, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.014440934, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.014893625, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26600, training loss= 0.0144644715, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.023427999, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.026105389, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26900, training loss= 0.020375306, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.020960534, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.023740767, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.01558353, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.01173058, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.012386858, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27500, training loss= 0.014963892, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.01677137, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.017029995, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.013406922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.01996784, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.011332486, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.015207244, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.01578368, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.014784802, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.15199974, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 88.70000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.021163931, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.0198779, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28700, training loss= 0.0121467225, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.015840942, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.012480407, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.025455488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29100, training loss= 0.016436415, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.014980835, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.015311314, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.014689115, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.010994701, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.013336208, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29700, training loss= 0.022443319, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.010281541, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.013954171, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 85.80060577392578 ...\n",
            "==================================================\n",
            "W1 = 4 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.4286364, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.09626642, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.08443393, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 300, training loss= 0.104189694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 400, training loss= 0.10190071, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.07185095, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.08535507, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 700, training loss= 0.06849791, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.07776916, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 900, training loss= 0.09125086, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.06244898, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.06586602, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.09448488, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.050584447, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.047060438, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.04834775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.07015855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 1700, training loss= 0.027926682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.05843469, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.060557317, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.040728416, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.074521184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.048597716, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2300, training loss= 0.062046856, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2400, training loss= 0.049616277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.04531103, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2600, training loss= 0.048837714, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.049755134, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.053162634, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.034683347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.043549858, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 3100, training loss= 0.031840023, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3200, training loss= 0.050336137, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 3300, training loss= 0.05460915, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.058245223, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.046018116, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.049276114, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 3700, training loss= 0.05048781, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.037302084, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.05160395, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.04354638, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.040742487, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.04137101, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.073644705, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.04843561, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.053402334, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.042904373, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.051716637, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.06502189, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.029331757, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5000, training loss= 0.043930687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.051074065, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.032180972, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5300, training loss= 0.033928934, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.027874757, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.03838282, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.026057146, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5700, training loss= 0.04257963, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.025526598, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.028521676, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.027991412, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6100, training loss= 0.042166498, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.03585358, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.06882778, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6400, training loss= 0.02890722, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.04449768, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.034185454, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.029433895, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.02752455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.038003415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.031760674, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7100, training loss= 0.044368066, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 7200, training loss= 0.041514903, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.04328313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7400, training loss= 0.027514284, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.03481888, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 7600, training loss= 0.04283179, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7700, training loss= 0.033746436, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.026519835, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7900, training loss= 0.034278627, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8000, training loss= 0.026198393, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8100, training loss= 0.036533862, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.03738115, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8300, training loss= 0.030224085, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.03821291, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.033924352, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.025642566, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8700, training loss= 0.02865058, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8800, training loss= 0.020877328, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.032194246, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.02777709, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.026574757, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.016939297, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9300, training loss= 0.028365366, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9400, training loss= 0.0314773, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.024879478, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.025892608, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.028541211, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.020446854, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.02044765, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10000, training loss= 0.01427961, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.023667373, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.021996481, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.01752243, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.030454297, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.027848808, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.02110149, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.018651705, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.018144935, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.016353823, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.015194557, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.019419359, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11200, training loss= 0.01690998, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.01463045, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11400, training loss= 0.023855831, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11500, training loss= 0.016222123, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11600, training loss= 0.016072584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.027636524, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11800, training loss= 0.014651464, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11900, training loss= 0.019822128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12000, training loss= 0.01639552, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.01885251, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.014306723, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.008091541, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.02215594, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12500, training loss= 0.019364644, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.016046897, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.026643679, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.017935194, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.010842013, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.014550357, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13100, training loss= 0.016290456, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 13200, training loss= 0.0179071, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.025449572, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.010886709, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13500, training loss= 0.01516769, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13600, training loss= 0.011285893, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.0105069205, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13800, training loss= 0.018867001, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13900, training loss= 0.020856503, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.013096152, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14100, training loss= 0.02171382, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14200, training loss= 0.014852816, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.012352998, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.014520705, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14500, training loss= 0.011477897, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.014381348, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14700, training loss= 0.011310672, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14800, training loss= 0.010497353, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14900, training loss= 0.01786397, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.009040455, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.010585919, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.010246331, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15300, training loss= 0.011234211, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.019935202, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.0135383, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.013602718, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.011045756, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.011818964, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.00944568, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.010184117, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16100, training loss= 0.0085046645, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.011375202, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.01170446, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.011911694, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.012760719, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.012374009, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.02303962, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.011683213, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.011278799, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.011368467, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.008018572, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17200, training loss= 0.008384967, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.011291399, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.012922416, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.009323323, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17600, training loss= 0.008118543, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17700, training loss= 0.0069429744, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.008282274, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17900, training loss= 0.011666684, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.00832436, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18100, training loss= 0.012623541, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.00547162, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.0057062544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18400, training loss= 0.010199491, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.0055264076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.0066435575, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.009922966, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18800, training loss= 0.008486798, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.009892492, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.012269691, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.014926693, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19200, training loss= 0.0050817984, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.009751024, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.008228384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19500, training loss= 0.00790198, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.007709819, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.007819959, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.005903363, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.004854296, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20000, training loss= 0.010156129, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.006684404, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.011309445, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20300, training loss= 0.010336101, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.011496024, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20500, training loss= 0.010050573, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20600, training loss= 0.0064717727, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20700, training loss= 0.011184415, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.0069003673, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.0063196076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.004262897, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.009565894, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.007042585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.0066421535, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.004586861, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.007846728, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.0042561553, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.007931162, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.006979873, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.0064548585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.008610106, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.010151637, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.006005214, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22300, training loss= 0.004305604, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.008216838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.0066326875, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22600, training loss= 0.009879082, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 0.007168604, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.008503353, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.0077657737, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.0051027527, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.00620974, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.0052504446, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.0060582813, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.005430783, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.0051832874, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.0071677268, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.0023496118, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.0049120146, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.0036283606, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.0058117546, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.0064764414, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24200, training loss= 0.0029685223, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.0050633503, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.00508025, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.004010951, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.0020130896, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.0045756907, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.003547674, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.0024865759, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.005639986, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25100, training loss= 0.005626876, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25200, training loss= 0.0026250319, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.005531539, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.005105002, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 0.0061469376, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.0036529154, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.0040078666, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.0060584396, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.0053679943, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.004962544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.0031769732, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.0037997437, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.0033541906, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.0039158165, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.0044530244, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.0044951458, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.003181539, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26800, training loss= 0.0023207199, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.004881124, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.0034095868, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.004619397, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.0035491749, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.004190054, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.0029912214, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.029830998, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27600, training loss= 0.005617961, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27700, training loss= 0.0034557404, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.004621936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27900, training loss= 0.003589721, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.0028313175, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.0027888145, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.0021810727, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28300, training loss= 0.004313794, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.0030448856, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.0030406779, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.003620846, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.003756087, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.002733965, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28900, training loss= 0.0027682006, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.0041747196, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.0030601684, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29200, training loss= 0.0025547533, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.0031793108, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.0039458093, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.003998509, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29600, training loss= 0.003836852, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.0037763696, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.001731955, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29900, training loss= 0.0033325073, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.8 %\n",
            "Validation Accuracy Test 84.59214782714844 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.6837928, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.109619774, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.1420051, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 300, training loss= 0.06091598, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.054297313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.07512573, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.11621174, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 700, training loss= 0.063582435, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.11229813, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.08228683, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.094041094, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.07345849, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.05771748, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.03785322, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.11295122, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.08421769, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.07857597, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1700, training loss= 0.061554722, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.066552274, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.066043735, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.035940483, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.05758051, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.057854865, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.084829226, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.071442276, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.06455927, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.08397145, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.06520184, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.06481783, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.0714099, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.050288815, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.05203729, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.03795664, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 3300, training loss= 0.049313825, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 3400, training loss= 0.06313677, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.042959638, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 3600, training loss= 0.061956607, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.065071106, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3800, training loss= 0.04726868, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.068622045, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.08637113, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.06257717, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4200, training loss= 0.050012287, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.047936615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.047820594, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.05361367, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.09979417, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.06625464, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.055843834, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.059038322, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.054903362, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.043379046, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.040554307, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.05728481, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.04924642, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.058498103, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.06739864, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.046786066, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.048134048, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.04104172, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.07128857, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6100, training loss= 0.06631349, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.042102434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.17023334, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.055401057, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.05577734, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.067747556, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.032637265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.045383774, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.044520054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.037892114, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.0612999, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.052739, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.05020599, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.05984099, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.08517074, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.048795734, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.047531392, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.03523024, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.040354244, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.034423407, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.030056866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8200, training loss= 0.051024035, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.05370108, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8400, training loss= 0.043605287, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.041083053, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.03446057, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.04746737, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.04024754, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8900, training loss= 0.029170867, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9000, training loss= 0.037327215, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.027475096, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.051180787, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.03132513, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.057689894, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.04848936, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.039177854, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.03969535, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.039527893, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.05453822, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 10000, training loss= 0.042234786, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10100, training loss= 0.02555363, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.034928355, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.0691818, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10400, training loss= 0.044310085, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.05268629, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.030960599, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10700, training loss= 0.055494163, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10800, training loss= 0.039663244, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.02381239, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.04435091, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.03717084, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.025343066, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.025949992, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.021449603, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.033781365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.04048608, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11700, training loss= 0.026476705, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11800, training loss= 0.04838254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.042282004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.04450754, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.035598636, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12200, training loss= 0.02737191, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.045499634, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.029307075, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.06988346, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.036528133, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 12700, training loss= 0.041662928, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.07394353, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.033976622, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.042538103, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.04498874, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.04356272, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.05004503, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.02863697, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.030482326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.027558528, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.03170207, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.025626441, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.02603481, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14000, training loss= 0.026216634, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14100, training loss= 0.031871334, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.046746407, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.037560243, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14400, training loss= 0.03227971, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.041787934, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.04445837, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.029290091, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.030517824, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.042666037, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15000, training loss= 0.040666535, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.024995364, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.037732206, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.032024723, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.01738247, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.027934205, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.030294899, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15700, training loss= 0.04448004, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.03460465, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.026429329, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16000, training loss= 0.027192103, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.022231946, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.036251504, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.026375495, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.034597404, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.04435204, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16600, training loss= 0.023824511, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16700, training loss= 0.022838203, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.038167313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.03087953, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.026748516, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.018285803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.021421215, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.025582006, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17400, training loss= 0.02494796, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17500, training loss= 0.022954259, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17600, training loss= 0.014632608, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.025524158, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.020460583, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.0341129, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.03222654, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.06791145, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.013107929, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.035232358, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18400, training loss= 0.033636004, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18500, training loss= 0.023346765, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.02483146, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.024250286, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.020336352, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.026688246, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.022068797, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.046166517, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.025911665, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19300, training loss= 0.027159438, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.025800148, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19500, training loss= 0.021929238, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.023203554, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.044072617, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.013755752, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.028066494, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.015440407, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20100, training loss= 0.032631747, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.008262167, training acc= 100.0%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.024097528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.026085772, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.02125255, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.029480606, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.020506669, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.013817998, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20900, training loss= 0.020221857, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.022288505, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.018969782, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.025350858, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.060587157, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.026117068, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.020443855, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21600, training loss= 0.025838621, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.02300657, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.033492938, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21900, training loss= 0.02120137, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.02966002, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.026193235, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22200, training loss= 0.013512838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.026908636, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22400, training loss= 0.020518625, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.018862111, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22600, training loss= 0.017921492, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.016578143, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.019336544, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.017236566, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23000, training loss= 0.017740406, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23100, training loss= 0.01660293, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23200, training loss= 0.028238777, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 0.023306657, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.01721111, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.023238074, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.026543764, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.025126023, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.015914485, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23900, training loss= 0.018065311, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.09905667, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.026432358, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24200, training loss= 0.020947685, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.023504628, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.014538983, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24500, training loss= 0.02620076, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24600, training loss= 0.017773703, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.017770007, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.016172742, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.025364047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25000, training loss= 0.018637335, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.018318528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.011560755, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.0138965575, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.01870162, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.02312847, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25600, training loss= 0.02012528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.025861835, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.015569968, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25900, training loss= 0.029427767, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.014897157, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.02113753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26200, training loss= 0.015159662, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26300, training loss= 0.015595564, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.013282425, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.012644396, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.021404792, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 0.023847628, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.022099046, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.018925795, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.017241223, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27100, training loss= 0.020777423, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27200, training loss= 0.01576577, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.010297274, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.019859374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 0.017361507, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27600, training loss= 0.018187117, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27700, training loss= 0.015113823, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.014819708, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.010659275, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.020213839, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.016997691, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.023354549, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.019969935, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.011397703, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.023202924, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28600, training loss= 0.021022264, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.016363718, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.013094103, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28900, training loss= 0.021040019, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.009193278, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.014634084, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29200, training loss= 0.016447535, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.010353838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.01830969, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29500, training loss= 0.012827623, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29600, training loss= 0.014888849, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 0.025334662, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29800, training loss= 0.0139764575, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29900, training loss= 0.015214191, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.7278155, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.10537525, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.08351331, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.07427679, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 400, training loss= 0.07119489, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.04505454, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.071258366, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.071286485, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.07215151, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.059845597, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.07498288, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.059063982, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.07169565, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.095561914, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.06491299, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.06964443, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.061722197, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.07057657, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1800, training loss= 0.05250161, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.050921522, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.07928045, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.06895116, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2200, training loss= 0.03671352, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.06260835, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.06440984, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.035232812, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.059403233, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.059080645, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2800, training loss= 0.042351533, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.098043524, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3000, training loss= 0.051704273, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.055100948, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.045321133, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.10031244, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.045037672, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.04322545, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.041401133, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.09800704, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.045167405, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.058469057, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.047811765, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.039713543, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.06246572, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.04268079, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.04052198, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.058346026, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.03631271, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.06575074, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.043631624, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.05236728, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5000, training loss= 0.044188637, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5100, training loss= 0.036193058, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 5200, training loss= 0.038313217, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.044249542, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5400, training loss= 0.029788591, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.03402083, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.04351445, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.03416286, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.045551233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.03208273, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.04247113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6100, training loss= 0.034541886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.03933128, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6300, training loss= 0.021298628, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6400, training loss= 0.031517006, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6500, training loss= 0.037348807, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.040363684, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.01579654, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6800, training loss= 0.05294953, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.031060584, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7000, training loss= 0.06259649, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.023658324, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.033078644, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7300, training loss= 0.044211406, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7400, training loss= 0.061733104, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.022496935, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.054826308, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.036417335, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7800, training loss= 0.038348638, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.02603216, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8000, training loss= 0.03739492, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8100, training loss= 0.031128783, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.024233822, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.030259358, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.023309851, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.043897357, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.041601047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 8700, training loss= 0.026933264, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8800, training loss= 0.03833392, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.024696952, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.025687091, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9100, training loss= 0.024368469, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.022756401, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9300, training loss= 0.037827082, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.037233677, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.024122735, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.027366716, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9700, training loss= 0.027506413, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.042441275, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 9900, training loss= 0.027100956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10000, training loss= 0.02155108, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10100, training loss= 0.023733713, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.014642455, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.012136246, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 10400, training loss= 0.029391604, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.03011049, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.0231885, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.021010833, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.026320646, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10900, training loss= 0.019732427, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.022656767, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.01622826, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.02127046, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.040422767, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.02651036, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11500, training loss= 0.026554469, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.030104112, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.029759582, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.023376374, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11900, training loss= 0.029491387, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.029884094, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.01834838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12200, training loss= 0.01996986, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12300, training loss= 0.036250282, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.010871244, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12500, training loss= 0.028479885, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 12600, training loss= 0.014882427, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12700, training loss= 0.020125529, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12800, training loss= 0.023779985, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12900, training loss= 0.03537239, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.019231923, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13100, training loss= 0.022213565, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.013772824, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.013563556, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.017164866, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.0232309, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13600, training loss= 0.020974679, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13700, training loss= 0.030886862, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13800, training loss= 0.021159025, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13900, training loss= 0.026260385, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.020475162, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14100, training loss= 0.012838053, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.025085917, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.02090532, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.020221502, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14500, training loss= 0.022395136, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.03376769, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14700, training loss= 0.024011482, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.029348943, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.0138928965, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 0.01663454, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.015160076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.017857987, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15300, training loss= 0.009482684, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.01498529, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15500, training loss= 0.022670168, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.013326927, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.01299595, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.018586677, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 15900, training loss= 0.010938032, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16000, training loss= 0.017340643, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16100, training loss= 0.013932337, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16200, training loss= 0.02113268, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16300, training loss= 0.015263734, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16400, training loss= 0.017071337, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.014833967, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 16600, training loss= 0.009234101, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.008814435, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.019722927, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16900, training loss= 0.009705333, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.019496866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17100, training loss= 0.01887669, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17200, training loss= 0.015886243, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 17300, training loss= 0.010162789, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17400, training loss= 0.0109525295, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 0.013749538, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 0.0117604155, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 0.015735911, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.012558091, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.012436105, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18000, training loss= 0.012289237, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.016697176, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.0137258805, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.011409152, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.011960162, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18500, training loss= 0.014313224, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.020027777, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.016555384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18800, training loss= 0.0111702895, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.014553539, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19000, training loss= 0.013081422, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19100, training loss= 0.012559873, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.013192938, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19300, training loss= 0.0149824815, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19400, training loss= 0.015003816, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 0.023392323, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19600, training loss= 0.014550485, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19700, training loss= 0.006430513, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.016116453, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.012042197, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.009987662, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 0.011072656, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20200, training loss= 0.015662298, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.013192871, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.011328313, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.011691376, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.044211295, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.009984179, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.009790453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20900, training loss= 0.010237593, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21000, training loss= 0.011239184, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.007931872, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21200, training loss= 0.008597153, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 21300, training loss= 0.009649014, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21400, training loss= 0.009733228, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.0066993437, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21600, training loss= 0.011775929, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21700, training loss= 0.011669251, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21800, training loss= 0.005913431, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 0.012841933, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22000, training loss= 0.012706398, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 0.008843793, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22200, training loss= 0.008529823, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22300, training loss= 0.01743002, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 0.01237015, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22500, training loss= 0.009626444, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22600, training loss= 0.0044860463, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22700, training loss= 0.011921355, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22800, training loss= 0.010095013, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22900, training loss= 0.010051351, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.00925697, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23100, training loss= 0.008118796, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 0.00995846, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.009328252, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23400, training loss= 0.010382808, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.010216636, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.010242799, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23700, training loss= 0.008972307, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 0.008089878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.0058445665, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24000, training loss= 0.004712279, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24100, training loss= 0.009058114, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24200, training loss= 0.005959541, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.007673357, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24400, training loss= 0.007966985, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.01241682, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24600, training loss= 0.0060626077, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.006880032, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24800, training loss= 0.007293474, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 0.006185564, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.0073422138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25100, training loss= 0.007845519, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25200, training loss= 0.005261411, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25300, training loss= 0.0071227476, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.005657888, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 0.00596754, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 0.0057669054, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25700, training loss= 0.011009506, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 0.0056834016, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.0059365747, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.007469947, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26100, training loss= 0.008139397, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.010469957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.0061441455, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.009872054, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26500, training loss= 0.011528049, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26600, training loss= 0.0084904, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.008932981, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26800, training loss= 0.004671081, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.0059973844, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.0057612187, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27100, training loss= 0.0063488754, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.008547767, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27300, training loss= 0.004812783, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27400, training loss= 0.004284051, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27500, training loss= 0.0068403482, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27600, training loss= 0.008600944, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27700, training loss= 0.007635868, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 0.005921587, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.007900528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.006093925, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28100, training loss= 0.019483145, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.008321186, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28300, training loss= 0.007819157, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28400, training loss= 0.004944338, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28500, training loss= 0.0047470066, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.005090936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28700, training loss= 0.005483103, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28800, training loss= 0.0069062533, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28900, training loss= 0.005521749, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.0030196263, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29100, training loss= 0.0071758265, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 0.006774465, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 0.004607366, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29400, training loss= 0.007426427, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29500, training loss= 0.0061639743, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29600, training loss= 0.005614857, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 0.007848125, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29800, training loss= 0.003328863, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29900, training loss= 0.0054415404, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.4464488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.088471934, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.11733332, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.087916136, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 400, training loss= 0.080758706, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.11559242, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.1025536, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.049559016, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.13356394, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.08768502, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.057810664, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.060228657, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.08031139, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.063471556, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.059032865, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.0652229, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1600, training loss= 0.06963985, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.092517406, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.08909907, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.03959559, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.058834635, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.060671207, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.053989045, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.04124887, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.060027417, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.050677896, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.063858375, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.041778676, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.043057416, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.05738443, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.058359515, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.032246217, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.037648167, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.05095599, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3400, training loss= 0.06067974, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.048160225, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.067772314, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3700, training loss= 0.072414584, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.050093412, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.034045916, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.03738558, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.033931147, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.046778243, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.0778197, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.07015834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.0573933, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.047826666, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.03995106, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.05281713, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.050720356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.048184603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.0653233, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.07294981, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.046191517, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.037211265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.049479064, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.04300964, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.038644392, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.036994975, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.038884096, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.039209638, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.026381532, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.055357065, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.04139585, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.047357157, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.043327853, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6600, training loss= 0.057762418, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.044247635, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.038494986, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.039246745, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.04047693, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.05937255, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.044127516, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.043938324, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7400, training loss= 0.033597108, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7500, training loss= 0.032347713, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.028233433, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.040837176, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.037126537, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.05357341, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8000, training loss= 0.057555955, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8100, training loss= 0.04035816, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.043285016, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8300, training loss= 0.02873782, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.03434723, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8500, training loss= 0.042234745, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.056620438, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8700, training loss= 0.03449622, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8800, training loss= 0.038773138, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8900, training loss= 0.043323144, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.052495543, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9100, training loss= 0.042021237, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.056992617, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.04023016, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.04197355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.038298536, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.039203092, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9700, training loss= 0.04178429, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.061958127, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.041345827, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.03096193, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.067402266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.034506287, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10300, training loss= 0.05112182, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.043594554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.030895986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.017841725, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.0403817, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.03524359, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.022205066, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.039752156, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.034251414, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11200, training loss= 0.03554638, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.032267477, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.05114974, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.05432988, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11600, training loss= 0.022094276, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.03879094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.028338972, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.030862091, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12000, training loss= 0.03701304, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.040455192, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.05172836, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.017888546, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.037250005, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.036253408, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.022650447, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.021843422, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.031223848, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.035277277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.026058102, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.024598833, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.037657756, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.04782304, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.02195789, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.02358605, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13600, training loss= 0.031405672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.030991046, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.035817564, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13900, training loss= 0.03009174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.026985686, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.027013345, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.028090179, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.02844222, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14400, training loss= 0.04044966, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14500, training loss= 0.032979295, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.04113892, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.02711207, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.025586002, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.062273268, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.0262296, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.03696221, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.03182675, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.024373723, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.023769932, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15500, training loss= 0.019275852, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15600, training loss= 0.01609263, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.028974514, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.025600202, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.030572355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.029150363, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.03395394, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.023377392, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.022860035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16400, training loss= 0.023772111, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.021142377, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.02721145, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.02677097, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.034179468, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.028763417, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.021689119, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.034681335, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17200, training loss= 0.023149136, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.02028339, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.03237459, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17500, training loss= 0.014700929, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.016727984, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.020161718, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.025297565, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.045420296, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.0342338, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.03275527, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18200, training loss= 0.030712564, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18300, training loss= 0.022247864, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.026262404, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.027900245, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.024939599, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.019187767, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.022246541, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.023295635, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.02864275, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19100, training loss= 0.014730774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19200, training loss= 0.023799505, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19300, training loss= 0.025382714, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19400, training loss= 0.029391505, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.017106611, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19600, training loss= 0.017519794, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19700, training loss= 0.025938174, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.01928273, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19900, training loss= 0.023726394, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20000, training loss= 0.023984376, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.022491688, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20200, training loss= 0.03458694, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20300, training loss= 0.02060378, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.026765218, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.03345297, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.018571818, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.029701816, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.019205924, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.019596599, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.050050646, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21100, training loss= 0.021239508, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.030126758, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.024191087, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.022391006, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.030297346, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21600, training loss= 0.0250928, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21700, training loss= 0.02630062, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21800, training loss= 0.02141864, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.014192382, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.020292949, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.02300802, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22200, training loss= 0.027550695, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22300, training loss= 0.027376788, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22400, training loss= 0.01637403, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22500, training loss= 0.015494587, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.026087213, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.025152918, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22800, training loss= 0.019653687, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.029156733, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23000, training loss= 0.02328522, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23100, training loss= 0.022653563, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.011511633, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23300, training loss= 0.01818374, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23400, training loss= 0.016717386, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.019492576, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.018656734, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23700, training loss= 0.012319891, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.014801058, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23900, training loss= 0.020582404, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24000, training loss= 0.015526791, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.019662699, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.027651817, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24300, training loss= 0.014273547, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24400, training loss= 0.0207261, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.015789919, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24600, training loss= 0.01807197, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.017774617, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24800, training loss= 0.027590511, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 0.021735229, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25000, training loss= 0.017005278, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25100, training loss= 0.022675427, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.017002916, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.018355, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.026314314, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.016570233, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.016252963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.019434175, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.01671181, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.017514966, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.016840594, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.010242149, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.0159592, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.011186329, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.018862473, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.013076952, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.020813951, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.010572053, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.021983817, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.02109831, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.015716892, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27100, training loss= 0.01984515, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.013559732, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.016447553, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.012704163, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.018900992, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.011570644, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27700, training loss= 0.014110379, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.01765645, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.022140129, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.014334767, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28100, training loss= 0.023869772, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.013457544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 0.0133383265, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28400, training loss= 0.01677763, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.017374804, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.012667755, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28700, training loss= 0.012199625, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28800, training loss= 0.01303862, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.012505122, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.016137471, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29100, training loss= 0.012699504, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.01364775, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.019902866, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29400, training loss= 0.017133402, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.022477377, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.013170126, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.015815133, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.014262774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29900, training loss= 0.016383504, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.78991175, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.07729721, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.122948274, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.09025456, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.06662451, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 500, training loss= 0.07321033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.052018274, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 700, training loss= 0.052623183, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.06368032, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.039700147, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.08867916, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.06868669, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.08962828, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.069490254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1400, training loss= 0.06567146, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.04400608, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.07751183, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.06979399, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.07794311, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1900, training loss= 0.06512258, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.059435353, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.051385254, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.049493447, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.071546726, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.041129168, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.054925077, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.04184889, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.052205823, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.059939545, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.048164163, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.04625349, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.046188213, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.05676865, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.0420307, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.049223386, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.046710312, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.05557027, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.049696002, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.044661537, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.056402605, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.03773758, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.054537944, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.03558474, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.053173296, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.041201744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.045088828, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.049579207, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4700, training loss= 0.031785473, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4800, training loss= 0.03894667, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.053332184, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.064400166, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.04243498, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.04446041, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 5300, training loss= 0.024543818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.042702597, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.029740822, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.060901582, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 5700, training loss= 0.022700168, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.035628155, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.020514518, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.040594716, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.026889997, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.028890103, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6300, training loss= 0.033176303, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.04164949, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.03247018, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.026305817, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6700, training loss= 0.027580375, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.03842101, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.033120148, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.018977437, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.037599567, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.036371093, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7300, training loss= 0.02783507, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.025334453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7500, training loss= 0.05263214, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.028302774, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7700, training loss= 0.028718093, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.026007243, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.06467379, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.032667536, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.027693253, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.032652702, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8300, training loss= 0.03626358, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.04485508, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8500, training loss= 0.03904189, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.026507141, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.035742883, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.047078952, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.05055837, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.039101698, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9100, training loss= 0.029170759, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.024503555, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.020810202, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9400, training loss= 0.033154607, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9500, training loss= 0.025028612, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.025209658, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.025344513, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.026315212, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.027161354, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.023330517, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10100, training loss= 0.043853037, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.01986959, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 10300, training loss= 0.025833057, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.04512515, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10500, training loss= 0.0350552, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.03366303, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10700, training loss= 0.023021791, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.021397874, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.029241337, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.014520576, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.045459934, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.022115018, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.02677563, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.033452906, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.024021426, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.031729, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.024895089, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.06205389, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11900, training loss= 0.024037186, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.017048977, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.02186303, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12200, training loss= 0.019102545, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.02674776, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.020706609, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12500, training loss= 0.02672169, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12600, training loss= 0.025219915, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12700, training loss= 0.021368831, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12800, training loss= 0.021226743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.017137846, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13000, training loss= 0.022701753, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13100, training loss= 0.020527015, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13200, training loss= 0.02643837, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.029469179, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.017230853, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.025287364, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.024227826, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.022936348, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.020695193, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.014990779, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.033938423, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.018944016, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.013143588, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14300, training loss= 0.019522741, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.020039333, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.024821483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.027146071, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14700, training loss= 0.015456578, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.022068687, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.013910336, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.032633796, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.01883636, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.016518673, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.031100485, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.010944442, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.01900999, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.022968678, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.021729602, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.016600676, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.018429631, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.019024584, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.02059602, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.0233494, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.018704185, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16400, training loss= 0.020722361, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.01604247, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16600, training loss= 0.01883982, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.017044635, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.013900821, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.017691892, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.025378415, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.018623998, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17200, training loss= 0.0153477425, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17300, training loss= 0.011544761, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 17400, training loss= 0.015816316, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17500, training loss= 0.017635545, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.02445741, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 0.012625412, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17800, training loss= 0.012415975, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.014834258, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 0.018685646, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.022465609, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 0.012716719, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18300, training loss= 0.011717867, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.017024301, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18500, training loss= 0.06236321, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.017664224, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18700, training loss= 0.01217682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.018341769, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18900, training loss= 0.013964803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19000, training loss= 0.020055803, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19100, training loss= 0.020523295, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19200, training loss= 0.022882769, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.013145727, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19400, training loss= 0.015457838, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19500, training loss= 0.011994971, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19600, training loss= 0.013355675, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.018044768, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.012884758, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.010599161, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.012757102, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20100, training loss= 0.019520698, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20200, training loss= 0.01588511, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20300, training loss= 0.012366923, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.013766955, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.016072007, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20600, training loss= 0.039811447, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20700, training loss= 0.03035995, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.0202908, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.014182271, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.018543521, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.009449936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21200, training loss= 0.016625388, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.013746321, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.016852213, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.012773315, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21600, training loss= 0.012030666, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21700, training loss= 0.008221499, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21800, training loss= 0.009459379, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21900, training loss= 0.011799317, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 0.011792468, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22100, training loss= 0.0127482945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22200, training loss= 0.016291123, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.012775798, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.013192207, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22500, training loss= 0.010668143, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.013237954, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.016118756, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.013426624, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22900, training loss= 0.013023795, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23000, training loss= 0.017654639, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23100, training loss= 0.01631794, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23200, training loss= 0.010685864, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23300, training loss= 0.017604126, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.010698008, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23500, training loss= 0.009240669, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23600, training loss= 0.013945115, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.012368774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.008220721, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23900, training loss= 0.006477278, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24000, training loss= 0.009352484, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24100, training loss= 0.012803379, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24200, training loss= 0.011391387, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24300, training loss= 0.017849466, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24400, training loss= 0.011301305, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24500, training loss= 0.013408254, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.011341564, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24700, training loss= 0.0116909295, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24800, training loss= 0.0072576343, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24900, training loss= 0.011649326, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.014295237, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 0.009249186, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 0.011262689, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.013257044, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25400, training loss= 0.007692072, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 0.011595385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.004864239, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25700, training loss= 0.012774936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25800, training loss= 0.013176531, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25900, training loss= 0.010022104, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.013106622, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26100, training loss= 0.008621716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.0069565168, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26300, training loss= 0.009084388, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26400, training loss= 0.008845954, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26500, training loss= 0.00943381, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26600, training loss= 0.00822301, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26700, training loss= 0.011435204, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26800, training loss= 0.009051373, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26900, training loss= 0.007028013, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27000, training loss= 0.009941706, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27100, training loss= 0.007987878, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27200, training loss= 0.014181472, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27300, training loss= 0.016292624, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.012994209, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27500, training loss= 0.011586478, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27600, training loss= 0.005822342, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27700, training loss= 0.008508177, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.010495569, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.007086176, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28000, training loss= 0.009890952, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.0046647, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28200, training loss= 0.007847692, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28300, training loss= 0.010797077, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.008343827, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.009317506, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.009180544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.0069828783, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.011600153, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.0065933457, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.008854309, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.010304325, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.0061590606, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29300, training loss= 0.008509339, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.0077414764, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.007195307, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.009122717, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.00890176, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.0060458733, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29900, training loss= 0.005822593, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.372586, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.15469186, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.11458238, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.09930775, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.07944683, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.08650813, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.04809439, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.071874924, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.055880535, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.070742615, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1000, training loss= 0.07398845, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.06441258, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.06515102, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1300, training loss= 0.053264815, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.052031584, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.047133688, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.049829494, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.08333813, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.066349685, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.07625624, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.055850003, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.06909851, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.04466676, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.04638343, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.024062073, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.04329985, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2600, training loss= 0.035973657, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.054821838, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2800, training loss= 0.07922011, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.054356772, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.050247055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3100, training loss= 0.034131035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.04302873, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.050976984, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.05677167, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.06571394, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.036766045, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.040755123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.04585847, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.04022033, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.043400753, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.044464182, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.066521935, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.046206687, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.03339605, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.04133171, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4600, training loss= 0.049292352, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.043063093, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.028516183, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.038709085, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.05429271, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.03996234, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5200, training loss= 0.07270065, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.036624957, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.042271465, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.022411445, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.039177027, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.033220638, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.043137807, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.0292635, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.04193212, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.031068703, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.03523345, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.028893653, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.022553043, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.040769756, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.058038805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.03247355, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6800, training loss= 0.029911736, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6900, training loss= 0.04975186, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7000, training loss= 0.042255845, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7100, training loss= 0.049724285, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.041794818, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.026411701, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.025201071, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.034933437, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.06140255, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.045763034, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.041938253, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7900, training loss= 0.029159797, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.025951216, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.022665802, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.026417466, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.045037143, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.024259513, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8500, training loss= 0.033733968, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.038071238, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.028980603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.026922464, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.04879569, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.044144858, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.036876675, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.03551309, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9300, training loss= 0.025100825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.022667957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9500, training loss= 0.025350329, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.049944315, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9700, training loss= 0.03007559, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.034257162, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9900, training loss= 0.02688869, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10000, training loss= 0.025267579, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.03086615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.035572857, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.04127431, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10400, training loss= 0.054336857, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.02845129, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.017712796, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10700, training loss= 0.034054395, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.02278552, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10900, training loss= 0.022233957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.02528991, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.041905392, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.03322814, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.02366175, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.06701639, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.024735672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.03004969, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.0430143, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11800, training loss= 0.038466036, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.02611988, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.034029234, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.031246776, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.026758458, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.025885556, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.02951984, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.029357923, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.04159855, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12700, training loss= 0.1164422, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12800, training loss= 0.0308776, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.037582796, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.036779113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13100, training loss= 0.03456922, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13200, training loss= 0.023077324, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.025958072, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13400, training loss= 0.03553706, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13500, training loss= 0.026297918, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13600, training loss= 0.035793196, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.016924106, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.03710226, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.028198518, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.0243541, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.06541345, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14200, training loss= 0.024821738, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.029284902, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.026324267, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.027234398, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.029809846, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14700, training loss= 0.024174714, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14800, training loss= 0.022803439, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.025708674, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.028608501, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15100, training loss= 0.026816512, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.028997788, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.02970061, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.041055422, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15500, training loss= 0.043773465, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.040436685, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.025182987, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.020098574, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.026022473, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.017608957, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16100, training loss= 0.022752667, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.014736597, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.027390514, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16400, training loss= 0.020330228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16500, training loss= 0.014946678, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.024677232, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.028782096, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.01898294, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16900, training loss= 0.022061327, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.026133988, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.020454729, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.016681451, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.036369123, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.023246385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.031175336, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17600, training loss= 0.036150943, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.018967574, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.026222276, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17900, training loss= 0.023227597, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18000, training loss= 0.019179242, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.023549138, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.021795303, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.026845587, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.025322512, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18500, training loss= 0.01632292, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.019706914, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.01903981, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.025810609, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.04860159, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.022648076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.021886257, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.018954793, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19300, training loss= 0.025332322, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19400, training loss= 0.028019233, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19500, training loss= 0.02170596, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19600, training loss= 0.024237568, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19700, training loss= 0.02662901, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.021404732, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.015202428, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.058091395, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.018813806, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20200, training loss= 0.017098779, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.023477796, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.02229185, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.017667066, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.014098225, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.014297072, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.012820163, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20900, training loss= 0.015104304, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21000, training loss= 0.021449108, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.04506255, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.024075897, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.01810282, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.024814587, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21500, training loss= 0.018391313, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.018773563, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.021495398, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.012386602, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21900, training loss= 0.02253859, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.020984806, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.027962025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.050237734, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.021177122, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.024832528, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.015977426, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.023775363, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.018788738, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22800, training loss= 0.022281192, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.02207938, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23000, training loss= 0.01882204, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.022605289, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23200, training loss= 0.02077114, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23300, training loss= 0.018482113, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.023526477, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23500, training loss= 0.027362932, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.021927515, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.02273923, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.014935785, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23900, training loss= 0.020526398, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.013430816, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.013983298, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.018848944, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.014533532, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.0412989, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.019157173, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.0152012985, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.020762488, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24800, training loss= 0.023005774, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24900, training loss= 0.020311544, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25000, training loss= 0.026207367, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.017448517, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25200, training loss= 0.01984728, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25300, training loss= 0.019081745, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.020998439, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.020249255, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25600, training loss= 0.03576794, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 25700, training loss= 0.024958028, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25800, training loss= 0.019708013, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25900, training loss= 0.012467136, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.013196128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26100, training loss= 0.014705975, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.015162123, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.01401518, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26400, training loss= 0.019684443, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.01794862, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.013442774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26700, training loss= 0.016058192, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.008310867, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.016300648, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27000, training loss= 0.02023602, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.021396728, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27200, training loss= 0.026865495, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.019248087, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27400, training loss= 0.018898021, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27500, training loss= 0.017770786, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.010343278, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27700, training loss= 0.0127483215, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27800, training loss= 0.023954347, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.01750327, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28000, training loss= 0.022913003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.021291742, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28200, training loss= 0.018782897, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.023245752, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.019727942, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28500, training loss= 0.015791409, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.014804421, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.01581628, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.016189672, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28900, training loss= 0.017001292, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29000, training loss= 0.016643632, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29100, training loss= 0.024830434, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.01759016, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.019552602, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.015420038, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29500, training loss= 0.020571122, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0075602797, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.016132526, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.00911138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.0116761755, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.0579469, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.09669308, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 200, training loss= 0.11509768, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.048422053, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.04992126, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 500, training loss= 0.078325406, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.074703805, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.057101063, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.107412696, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.06395577, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.046595138, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.055792212, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.056486394, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.05973753, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.057793897, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.046897937, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.054690335, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.04373352, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1800, training loss= 0.032163624, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.044814825, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2000, training loss= 0.07707463, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.054313418, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.062426288, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.056433875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.041238982, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.053910654, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.057744272, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.03959934, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2800, training loss= 0.04556271, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.036420207, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.036985327, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3100, training loss= 0.038413007, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3200, training loss= 0.037875846, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3300, training loss= 0.047660153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.022482619, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3500, training loss= 0.043626763, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.026978144, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.03914779, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.045212317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.051132426, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.058999956, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.042280313, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.033519775, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4300, training loss= 0.030238904, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.031155407, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.036823627, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.03039216, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4700, training loss= 0.0457611, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.042868484, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4900, training loss= 0.03230643, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.03860688, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.03682487, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5200, training loss= 0.040616065, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.028875018, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5400, training loss= 0.03668562, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.027841674, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.036973998, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.018998602, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5800, training loss= 0.04415522, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5900, training loss= 0.03220623, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.017783137, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.03935282, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.030251566, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.02991482, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.03943336, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.034506463, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6600, training loss= 0.026920287, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.034364685, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.03518792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6900, training loss= 0.030138215, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.036798287, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.027313048, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.0387119, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.03716241, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.038254414, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.049513187, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.059570353, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7700, training loss= 0.033128317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7800, training loss= 0.020014668, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.03853869, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.027193666, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.029222403, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.034017544, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.02539064, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.025941549, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8500, training loss= 0.029700309, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.030333115, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8700, training loss= 0.028109694, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.047120955, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.031047741, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.028820852, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.030218307, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.032558, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9300, training loss= 0.04012243, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.019761613, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.034745313, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.024616104, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9700, training loss= 0.029675087, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.03638005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.02768857, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10000, training loss= 0.019151907, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.032927267, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.024781624, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.024017481, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.026723817, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10500, training loss= 0.021750048, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.025888482, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10700, training loss= 0.015575792, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10800, training loss= 0.03259709, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.022147385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11000, training loss= 0.020965042, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.023896672, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11200, training loss= 0.023851208, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11300, training loss= 0.031625774, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.021649603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.031675808, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.026452111, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.029462967, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.022323824, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.023382107, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.021679567, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.019188039, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12200, training loss= 0.024239754, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.018448927, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12400, training loss= 0.030914422, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.032614104, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12600, training loss= 0.023617083, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12700, training loss= 0.029078998, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.022802137, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.021085568, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13000, training loss= 0.017246528, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.020353043, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.017260442, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13300, training loss= 0.04078528, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.020422572, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13500, training loss= 0.020306656, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.021754054, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.02161249, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.019030914, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.01778484, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.023683866, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.030643536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14200, training loss= 0.020142065, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14300, training loss= 0.020481313, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14400, training loss= 0.027138503, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.011168492, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.016581615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.02305676, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.024466608, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.029158268, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.017775336, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.013830339, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15200, training loss= 0.0118700415, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15300, training loss= 0.019495133, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.022527607, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.019739265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.019396825, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.01760044, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.014519421, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.01734161, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.015390618, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.014398149, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.0218361, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.024790486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.019836115, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.012448538, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.018538248, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.019287677, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.017433556, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.013475935, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.025477538, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.011081829, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17200, training loss= 0.021368733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.016072692, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17400, training loss= 0.0106943, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.015184436, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17600, training loss= 0.02387802, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.011582975, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17800, training loss= 0.016053932, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.011836802, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.016804576, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18100, training loss= 0.013522571, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.024234029, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18300, training loss= 0.021013277, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18400, training loss= 0.009656859, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.022757024, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.068229094, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18700, training loss= 0.03710218, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18800, training loss= 0.019436203, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.020249838, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.014369162, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.021086711, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.015497012, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.016184958, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.014855623, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.014542041, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.019155974, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19700, training loss= 0.012779905, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.016574023, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19900, training loss= 0.052443717, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.015618273, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.016675554, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.011891004, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20300, training loss= 0.01771851, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.020314826, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.019058028, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.010118677, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.009019499, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20800, training loss= 0.012921837, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20900, training loss= 0.013955989, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.013224651, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.014325174, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.014543663, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.015062829, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.012871548, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.008527281, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.0147335315, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21700, training loss= 0.011562153, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.07577465, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.018387357, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22000, training loss= 0.011154414, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22100, training loss= 0.011365825, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.01231, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.018423168, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.018361753, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.016483014, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22600, training loss= 0.013270047, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.012015854, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22800, training loss= 0.013760473, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.011933795, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.014659812, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.012943834, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23200, training loss= 0.011866657, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23300, training loss= 0.01561428, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.01596249, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23500, training loss= 0.013615632, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.016080951, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.012385025, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23800, training loss= 0.00976269, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23900, training loss= 0.008560019, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.009597566, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.009449236, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.017652543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.015103814, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.012810783, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.016192298, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.012823543, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24700, training loss= 0.0114444485, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24800, training loss= 0.011559761, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.014399007, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25000, training loss= 0.009188999, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25100, training loss= 0.018168977, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25200, training loss= 0.009619066, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.0068685412, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.009272898, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25500, training loss= 0.0093242405, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25600, training loss= 0.010601544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25700, training loss= 0.011435849, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25800, training loss= 0.008516912, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.008860213, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.008008717, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.009863212, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26200, training loss= 0.009706607, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.014490308, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.010771882, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26500, training loss= 0.0093786325, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.010570292, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26700, training loss= 0.011130926, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.012802158, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.008762654, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27000, training loss= 0.0118273245, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.012936759, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.008442362, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.016701631, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.0070082876, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.014443774, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.01634464, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.012434833, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27800, training loss= 0.0153397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.009004911, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.01233677, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.01178966, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.008614232, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.0058867484, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.0108241895, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.008693988, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.008190344, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.015000711, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28800, training loss= 0.0072659263, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.0069472557, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.004596428, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.012398336, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.010490946, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.0086394, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.0101861, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.0062034186, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.014404287, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.005154661, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.008352949, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.0058830446, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.6 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.4266738, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.0836825, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.10537106, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 300, training loss= 0.08724191, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.07831102, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 500, training loss= 0.11268612, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.06651803, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.07262382, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.08025168, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.04952827, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1000, training loss= 0.07435621, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1100, training loss= 0.060358018, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.049409725, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.06579163, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.060708683, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1500, training loss= 0.07177728, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.048665352, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.064877935, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.07201656, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.068152435, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.060330868, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 2100, training loss= 0.05004638, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.044834875, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.04941469, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.041626837, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.047043685, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.059289493, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.049363773, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2800, training loss= 0.04265004, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2900, training loss= 0.044419076, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.07273935, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.055337843, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.055204142, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.049520962, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.058208138, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.05027772, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.04270423, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3700, training loss= 0.038889375, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.0523127, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.07980867, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.04529332, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4100, training loss= 0.035681784, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.048241567, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.044114664, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.0414406, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.047932178, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.038029313, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.025375996, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.03489664, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4900, training loss= 0.0446557, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5000, training loss= 0.04431851, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.046121445, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.04230413, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5300, training loss= 0.03592513, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.04065701, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.026325608, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.048331313, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.031128515, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.030660143, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5900, training loss= 0.0375903, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.0474152, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.03622471, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.037703723, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.023297627, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.03034176, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6500, training loss= 0.05452304, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.034521926, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6700, training loss= 0.045708533, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.035037264, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.031016802, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.038467918, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.033380482, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7200, training loss= 0.03220836, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7300, training loss= 0.024541503, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.03614971, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.040192228, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7600, training loss= 0.025157917, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.030348947, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.03297431, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7900, training loss= 0.027936755, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8000, training loss= 0.03012693, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.0375286, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8200, training loss= 0.050748553, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.031192053, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.022305798, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.02180906, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8600, training loss= 0.03016167, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.037210952, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8800, training loss= 0.03309678, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.03278484, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.03106208, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9100, training loss= 0.035166413, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9200, training loss= 0.03148328, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9300, training loss= 0.035777595, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9400, training loss= 0.03582222, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.028769318, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9600, training loss= 0.034855764, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.026020983, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9800, training loss= 0.05892072, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.031093646, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.02754519, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10100, training loss= 0.028334532, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.021272736, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.02952811, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.040936634, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10500, training loss= 0.019481277, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.04582276, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.033331033, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.020823227, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.027827058, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.035738584, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.030493725, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.025883455, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.025492853, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.025514258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11500, training loss= 0.05517443, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11600, training loss= 0.03160801, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.019386282, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11800, training loss= 0.021914175, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11900, training loss= 0.027136719, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.030746957, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.019869057, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12200, training loss= 0.037536528, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12300, training loss= 0.013985, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.029244391, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.029859403, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.022733567, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12700, training loss= 0.01840361, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12800, training loss= 0.025220731, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12900, training loss= 0.03931852, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.044621896, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13100, training loss= 0.029895304, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.03507363, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.027284851, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13400, training loss= 0.01885174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.030261371, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.023518546, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.025183996, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.02629046, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.02584432, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.026056383, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14100, training loss= 0.034546874, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.022071835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.017851748, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.038887676, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.033108696, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 14600, training loss= 0.044575896, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14700, training loss= 0.020384992, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.034275327, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.023356175, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15000, training loss= 0.025879268, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.02856097, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15200, training loss= 0.020635428, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15300, training loss= 0.016895978, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.024410835, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.022472128, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.027721737, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.028188933, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15800, training loss= 0.028853944, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.02067693, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.021808041, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.021967445, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16200, training loss= 0.03575748, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16300, training loss= 0.019362554, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16400, training loss= 0.025951827, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.017573256, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.015439898, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.020164233, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.023193074, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.023197234, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17000, training loss= 0.017166324, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.050354987, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17200, training loss= 0.013642286, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.044663, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.028269222, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.022800408, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.016927505, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 17700, training loss= 0.029437173, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.026233152, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17900, training loss= 0.024319554, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.015277664, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.028717598, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18200, training loss= 0.029770145, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.016408766, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.017938113, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.022550136, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.028706519, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.026884442, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.030869676, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.021318361, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.024135647, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.015352748, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19200, training loss= 0.034880787, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.057224315, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.019801406, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.019106977, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19600, training loss= 0.02463035, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.021400452, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.025416804, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.018909138, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20000, training loss= 0.026188402, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20100, training loss= 0.015675327, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.019687852, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.0199719, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.023804525, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20500, training loss= 0.022171615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.021089543, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.020399919, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.018018937, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.023087658, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.016908485, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21100, training loss= 0.02244098, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.026842868, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.026500035, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.015039769, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21500, training loss= 0.01877961, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.0212277, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.026014376, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.03258617, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.030304044, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 22000, training loss= 0.025238026, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.016760148, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.00854238, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.022402005, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.030389816, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22500, training loss= 0.016809456, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.02456765, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.024454283, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.014948279, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22900, training loss= 0.023805512, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.016014876, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23100, training loss= 0.011745348, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23200, training loss= 0.02028079, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.014302705, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23400, training loss= 0.01763275, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.017444355, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.012813813, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.03043673, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.01768609, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.016552802, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24000, training loss= 0.029408498, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.022344189, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24200, training loss= 0.0183551, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24300, training loss= 0.016859, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24400, training loss= 0.02086546, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.025005475, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.020506412, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.012593645, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.020378446, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.016751833, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.021340532, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25100, training loss= 0.015560614, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25200, training loss= 0.01838018, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.0112242745, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25400, training loss= 0.01908123, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.025064621, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.01603522, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.019784745, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25800, training loss= 0.02504398, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 25900, training loss= 0.017680956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.018618172, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.019813772, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 26200, training loss= 0.019044919, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.0144814355, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.015400167, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.016405158, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.016699124, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.017248953, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.015718458, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.020023871, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.0153768305, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27100, training loss= 0.024583418, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.022140468, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.012951416, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.01967941, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.025667334, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.00748416, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.015971025, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.013581309, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.011371695, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.012906526, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.009577648, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28200, training loss= 0.01758469, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.008794835, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.010247004, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.012009858, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.01964237, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.0112902885, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.014353181, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.01562802, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.018637868, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29100, training loss= 0.11796433, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.018226748, training acc= 100.0%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.011999344, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.016070385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29500, training loss= 0.01372645, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.017188868, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29700, training loss= 0.014887082, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29800, training loss= 0.014436156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.011434111, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 85.19637298583984 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 4 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.0897518, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.18402572, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 200, training loss= 0.05603996, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.11307518, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.04799078, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.06436995, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.0707798, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.054266445, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.049427863, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.032779366, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.04712554, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.07484413, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.06617866, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1300, training loss= 0.06494311, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.057002142, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.04612465, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.05561436, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1700, training loss= 0.043473247, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.05324319, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.036452785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.044939384, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.055017374, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2200, training loss= 0.053233065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.06090476, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.044526964, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2500, training loss= 0.044642124, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.043740917, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.041510724, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2800, training loss= 0.04887946, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2900, training loss= 0.039903693, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.036635786, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.06189572, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.037270386, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3300, training loss= 0.037785172, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.03996092, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3500, training loss= 0.028242541, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.05084797, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.049179003, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.018189501, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3900, training loss= 0.03357748, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4000, training loss= 0.039596222, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.04063075, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4200, training loss= 0.040951014, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.04025677, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.04086418, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.04422808, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4600, training loss= 0.03758775, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4700, training loss= 0.028532704, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.046227265, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.052131575, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.025851278, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.04402566, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.03370759, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.031560045, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.042251356, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5500, training loss= 0.039970588, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5600, training loss= 0.045656458, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.030409992, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.026850587, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.033232275, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.026670324, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.03793434, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.02371483, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.02404541, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6400, training loss= 0.046663675, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 6500, training loss= 0.041954976, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6600, training loss= 0.03811911, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6700, training loss= 0.035017226, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.052006662, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6900, training loss= 0.041380554, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.031309012, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.02251157, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.038504336, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.026030771, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7400, training loss= 0.029743234, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.03123748, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7600, training loss= 0.058416955, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.025413098, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7800, training loss= 0.02260386, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.02365851, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8000, training loss= 0.028546073, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.03653306, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.02630398, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.020614164, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8400, training loss= 0.03027328, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8500, training loss= 0.031412005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.02755438, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8700, training loss= 0.018024018, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8800, training loss= 0.020931378, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.020735824, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.038494978, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.03460021, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9200, training loss= 0.020530228, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9300, training loss= 0.020435892, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9400, training loss= 0.024025125, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9500, training loss= 0.026011826, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.030705245, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.01542835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9800, training loss= 0.016652025, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9900, training loss= 0.02815812, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.039334044, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.043818038, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.037570506, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.019127602, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.03508276, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.029155303, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10600, training loss= 0.025306597, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.019837404, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.023144493, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.020848194, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11000, training loss= 0.021316973, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11100, training loss= 0.027424544, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.025155518, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11300, training loss= 0.038509265, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.021712804, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.043979883, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.032538544, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11700, training loss= 0.032745667, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11800, training loss= 0.018931463, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 11900, training loss= 0.02846467, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12000, training loss= 0.016206231, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12100, training loss= 0.02915211, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.03225734, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.014802085, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12400, training loss= 0.027037958, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.029236557, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.027217375, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.020432599, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.026979124, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.026531264, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.02598371, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.021421093, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.028813373, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13300, training loss= 0.023061456, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.0212121, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13500, training loss= 0.027298791, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.08535156, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 88.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.027012369, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.022111936, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.019868277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.023252357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.01913512, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.018061945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14300, training loss= 0.01891331, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14400, training loss= 0.018937891, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14500, training loss= 0.016945165, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14600, training loss= 0.027593479, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.02309022, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14800, training loss= 0.021339059, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.02339687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.01426994, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15100, training loss= 0.02014051, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15200, training loss= 0.023165818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15300, training loss= 0.027511023, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.023827959, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15500, training loss= 0.01909704, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15600, training loss= 0.021459956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15700, training loss= 0.02333805, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.019251777, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15900, training loss= 0.020123048, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16000, training loss= 0.022908922, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.027518641, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.017137472, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16300, training loss= 0.027443334, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.017376691, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16500, training loss= 0.027140008, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.020593477, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.023340259, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.013779286, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16900, training loss= 0.020301854, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.015532165, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.031150289, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.020393334, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17300, training loss= 0.016486386, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17400, training loss= 0.012613377, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17500, training loss= 0.027175168, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.026205178, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17700, training loss= 0.023803215, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.01566111, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17900, training loss= 0.016817626, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.013581271, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18100, training loss= 0.018048096, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.014556052, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18300, training loss= 0.02559958, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.01795055, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.029044421, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18600, training loss= 0.01318382, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.014466651, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.010192247, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18900, training loss= 0.01894589, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19000, training loss= 0.017138973, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19100, training loss= 0.014781055, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.015743792, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19300, training loss= 0.042997453, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.013840727, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 0.009832229, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.010929228, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.012583451, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.010597724, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.024431303, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.014205928, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.013112554, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.016426412, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.015220279, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.017418586, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.015862491, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20600, training loss= 0.010633544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20700, training loss= 0.01732503, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.014366848, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20900, training loss= 0.017704524, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21000, training loss= 0.016970066, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.034435853, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21200, training loss= 0.017589374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.020837113, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21400, training loss= 0.014421062, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.011314893, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.013359789, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.018471282, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21800, training loss= 0.011996679, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21900, training loss= 0.008123561, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.014296514, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.013550676, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 0.017343622, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.008587823, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22400, training loss= 0.013265114, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22500, training loss= 0.015639579, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22600, training loss= 0.016853342, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.017917829, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22800, training loss= 0.009523531, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22900, training loss= 0.017724292, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.012569052, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.017168833, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23200, training loss= 0.067765534, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23300, training loss= 0.009608697, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23400, training loss= 0.012614857, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.013381283, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.011506774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23700, training loss= 0.014903139, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23800, training loss= 0.009775699, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.013992892, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24000, training loss= 0.013982909, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24100, training loss= 0.012304796, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24200, training loss= 0.013756018, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24300, training loss= 0.0147266835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24400, training loss= 0.009982835, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.013389488, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24600, training loss= 0.01706649, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24700, training loss= 0.009951329, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24800, training loss= 0.0076331524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.009655334, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25000, training loss= 0.015226923, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25100, training loss= 0.01245277, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25200, training loss= 0.015434793, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25300, training loss= 0.010455364, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 0.0093805315, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.009578925, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25600, training loss= 0.012758708, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.021756833, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25800, training loss= 0.013971063, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.009319582, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.008312943, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26100, training loss= 0.017789446, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26200, training loss= 0.011507679, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.012254089, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.010134067, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26500, training loss= 0.008078465, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.01870522, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.009947596, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.013268736, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26900, training loss= 0.0077964007, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.013068843, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.00888913, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.009666236, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27300, training loss= 0.010488701, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.01353805, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27500, training loss= 0.0074163624, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27600, training loss= 0.0085598165, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27700, training loss= 0.010701151, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27800, training loss= 0.011306128, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27900, training loss= 0.0068516457, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.010081878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.014486305, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.0067667738, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28300, training loss= 0.013375428, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.010300094, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.0090149, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28600, training loss= 0.028013192, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.018276203, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.0074502896, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.010382395, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.014914166, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.0090607805, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29200, training loss= 0.008082466, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.0074183187, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29400, training loss= 0.011598963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29500, training loss= 0.010049187, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.015440704, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 0.009651555, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29800, training loss= 0.01123728, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29900, training loss= 0.011041618, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 84.89425659179688 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.2780415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.09569981, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 200, training loss= 0.13006637, training acc= 94.49999928474426%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 300, training loss= 0.10582327, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.025777826, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.10079241, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.115793034, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.042445283, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.037471026, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.06235779, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.052075636, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1100, training loss= 0.07219203, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.052870844, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.054769814, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 1400, training loss= 0.051101487, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.084106, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.05767748, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.030721055, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.062285714, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.084393375, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.060008895, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2100, training loss= 0.057509907, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.04833291, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2300, training loss= 0.050109074, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2400, training loss= 0.04658973, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.029632092, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2600, training loss= 0.05427477, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.031025885, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.026333084, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.058503326, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3000, training loss= 0.05237001, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.05483836, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3200, training loss= 0.040822554, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3300, training loss= 0.028811783, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.0339898, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.028648943, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3600, training loss= 0.024101572, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3700, training loss= 0.031036083, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.03952367, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.02819927, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.045217402, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.034512002, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4200, training loss= 0.044050366, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.05780217, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4400, training loss= 0.05453546, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4500, training loss= 0.049914252, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4600, training loss= 0.03243618, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4700, training loss= 0.028247772, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.0451837, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.029661015, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.038481332, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5100, training loss= 0.034983903, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5200, training loss= 0.030138567, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.027533518, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.03139618, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5500, training loss= 0.025344394, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.038161684, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5700, training loss= 0.037615385, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.049490247, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5900, training loss= 0.040746402, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6000, training loss= 0.057933852, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6100, training loss= 0.042481687, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.0378502, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.026063435, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6400, training loss= 0.030577468, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.042185653, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6600, training loss= 0.027369153, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.03421153, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.046684787, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6900, training loss= 0.039163794, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.028008562, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.015877733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7200, training loss= 0.036234636, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.0418369, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.02581962, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.030710403, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.043778677, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7700, training loss= 0.029555853, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.021291992, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.034842134, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8000, training loss= 0.027116183, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.024762973, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.035437413, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8300, training loss= 0.028529469, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.021593142, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.039496593, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.05638399, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.01914615, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.04257093, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.018791823, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9000, training loss= 0.026876228, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9100, training loss= 0.02826306, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.02799445, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.03500727, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.039499495, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.02728491, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.0650348, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9700, training loss= 0.031054769, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.027558342, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.022238435, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10000, training loss= 0.024651235, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.036429416, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10200, training loss= 0.03384915, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.028155062, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10400, training loss= 0.020024555, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.030213457, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10600, training loss= 0.023865083, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.025360953, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10800, training loss= 0.030055229, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.031699546, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.028637126, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.018988451, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11200, training loss= 0.039206363, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 11300, training loss= 0.039356247, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.044051986, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.032888554, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.031224748, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.018247664, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.03268077, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11900, training loss= 0.026302781, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.033622637, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.03110427, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.040154148, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12300, training loss= 0.02441852, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12400, training loss= 0.017312275, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.051854357, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12600, training loss= 0.025919657, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.032572098, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12800, training loss= 0.03131195, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.027446624, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13000, training loss= 0.027935574, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.018801568, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13200, training loss= 0.019562393, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13300, training loss= 0.02451419, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.0243465, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13500, training loss= 0.024110302, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13600, training loss= 0.021121234, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13700, training loss= 0.020520644, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13800, training loss= 0.03684941, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.028044116, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.045637902, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.022185678, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14200, training loss= 0.024264595, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14300, training loss= 0.019707622, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.018388957, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14500, training loss= 0.024250174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.024589103, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14700, training loss= 0.02079852, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.024687191, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14900, training loss= 0.023615202, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.024089765, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15100, training loss= 0.018018086, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.023426024, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.05908562, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15400, training loss= 0.025643855, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15500, training loss= 0.025340425, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15600, training loss= 0.019220553, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15700, training loss= 0.016103769, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15800, training loss= 0.0114487335, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.01603613, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16000, training loss= 0.027101122, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16100, training loss= 0.025536131, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.027154356, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16300, training loss= 0.01673354, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16400, training loss= 0.023656502, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16500, training loss= 0.0225061, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16600, training loss= 0.019141767, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16700, training loss= 0.023902837, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16800, training loss= 0.03213394, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16900, training loss= 0.022205371, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17000, training loss= 0.022166053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17100, training loss= 0.016121734, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.025721274, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17300, training loss= 0.024314502, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17400, training loss= 0.07424358, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17500, training loss= 0.025536524, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17600, training loss= 0.019097555, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.020372178, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.019973755, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.027915822, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.017325303, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.018259816, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.026620492, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18300, training loss= 0.024115674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.02018994, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18500, training loss= 0.018927785, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18600, training loss= 0.028454905, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18700, training loss= 0.018433087, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.02117242, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.01782167, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19000, training loss= 0.018190729, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.022713574, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19200, training loss= 0.021204099, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19300, training loss= 0.014142682, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.075286016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19500, training loss= 0.04694508, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 19600, training loss= 0.018771555, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19700, training loss= 0.01538749, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19800, training loss= 0.014791196, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.01868606, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.014324878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.019953625, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20200, training loss= 0.020873124, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.018036846, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20400, training loss= 0.016488314, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20500, training loss= 0.017261878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20600, training loss= 0.016052261, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.016315594, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20800, training loss= 0.018976215, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.015773792, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21000, training loss= 0.015306531, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.030876702, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.020602986, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21300, training loss= 0.0152209485, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21400, training loss= 0.017748792, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21500, training loss= 0.01382571, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21600, training loss= 0.014688113, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21700, training loss= 0.021088324, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.029067716, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21900, training loss= 0.016649019, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.015335047, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.015354031, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.017646387, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.013083543, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22400, training loss= 0.013073867, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22500, training loss= 0.015670478, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.020062216, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22700, training loss= 0.018923009, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.016924325, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22900, training loss= 0.01554833, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23000, training loss= 0.0120445, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23100, training loss= 0.020580404, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.02159634, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23300, training loss= 0.015188979, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.02371751, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23500, training loss= 0.019451955, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.013289144, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.0416119, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23800, training loss= 0.022561463, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.015833296, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.016938904, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24100, training loss= 0.014181241, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24200, training loss= 0.015481221, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.018676678, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24400, training loss= 0.011988139, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.020808456, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.011700739, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24700, training loss= 0.012231016, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24800, training loss= 0.016725847, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.0074211517, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.022722458, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25100, training loss= 0.021748431, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25200, training loss= 0.014009227, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.021265112, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25400, training loss= 0.016795719, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.024591213, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.013465743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25700, training loss= 0.019695817, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.016865762, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25900, training loss= 0.012122252, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.013285461, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.013387564, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.015583682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26300, training loss= 0.009909165, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.013992573, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26500, training loss= 0.0152784875, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.04196927, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.011684554, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26800, training loss= 0.018355737, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.012084235, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.017502138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.01698389, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27200, training loss= 0.014446574, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.014492708, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.010808129, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27500, training loss= 0.017304773, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27600, training loss= 0.017342744, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.013266995, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.015563181, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27900, training loss= 0.016939983, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.014790591, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28100, training loss= 0.015744345, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.023322545, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28300, training loss= 0.017553741, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28400, training loss= 0.014200589, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.016160646, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.013095054, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28700, training loss= 0.0102111595, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28800, training loss= 0.010144157, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.01621818, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.0070286524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.014728072, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29200, training loss= 0.013394741, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29300, training loss= 0.013163605, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.014821969, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.01686944, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.009972401, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.016565803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29800, training loss= 0.016781075, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.014770799, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "Valid acc= 90.7 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 5 ...\n",
            "W2 = 5 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.30442464, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 100, training loss= 0.07969794, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.10478694, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 300, training loss= 0.090575084, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 400, training loss= 0.06495674, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 500, training loss= 0.07832124, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 600, training loss= 0.0950136, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 700, training loss= 0.0775249, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 800, training loss= 0.06580458, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 900, training loss= 0.039512243, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.06834094, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.048596494, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1200, training loss= 0.0739781, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.08010844, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 1400, training loss= 0.10556497, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.05634092, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.05728405, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1700, training loss= 0.062160395, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.04068904, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.08028476, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2000, training loss= 0.044674996, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.06318227, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.092218556, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.06434171, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2400, training loss= 0.054982387, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.05657399, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.042927396, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.06345944, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.08340177, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2900, training loss= 0.05783868, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.050080545, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.078679495, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.047307886, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.046613682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.049079947, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.04831494, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.054834653, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.021497808, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.054419044, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3900, training loss= 0.053336553, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.04969811, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.0485244, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.06711901, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.061691005, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.046157166, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 4500, training loss= 0.045098014, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.059183314, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 4700, training loss= 0.05033962, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.04112822, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4900, training loss= 0.040164, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.041523784, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 5100, training loss= 0.054399315, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.029835025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.045067362, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5400, training loss= 0.050171748, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.041868415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5600, training loss= 0.060213976, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.041961517, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 5800, training loss= 0.03792272, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5900, training loss= 0.056820303, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6000, training loss= 0.029720716, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6100, training loss= 0.043294672, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6200, training loss= 0.03788016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.04654553, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.03286157, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.043272875, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.027928807, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.04173712, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6800, training loss= 0.03923884, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.042329, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.021408016, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7100, training loss= 0.05336601, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.02181889, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.037270047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.034312617, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7500, training loss= 0.023721533, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7600, training loss= 0.037663024, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.036004707, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.036625132, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.023166053, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.026487175, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8100, training loss= 0.031961173, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8200, training loss= 0.029142385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8300, training loss= 0.022499863, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.026343117, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8500, training loss= 0.019102847, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 8600, training loss= 0.038732305, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8700, training loss= 0.026517572, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.023351707, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.029412258, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.017158862, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.04061254, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9200, training loss= 0.027317535, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9300, training loss= 0.017472865, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9400, training loss= 0.016194195, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.030425917, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.028128318, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.040469833, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.025716042, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9900, training loss= 0.009624936, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.024896188, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10100, training loss= 0.022680204, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.019565333, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.018231267, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.02300564, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.018460466, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10600, training loss= 0.018690756, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.011157905, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.01596949, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10900, training loss= 0.021606853, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.015362222, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.026260875, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.014562719, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11300, training loss= 0.022618534, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.010720132, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11500, training loss= 0.017021611, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11600, training loss= 0.018011604, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.018041408, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.015646959, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.01347851, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.023015153, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.019049076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12200, training loss= 0.016445063, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.012575908, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.009632282, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.017690571, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12600, training loss= 0.009883168, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.014876311, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12800, training loss= 0.011037427, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12900, training loss= 0.016175717, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.029069072, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.015336303, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.01730856, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.01415517, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13400, training loss= 0.011749121, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13500, training loss= 0.019031165, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13600, training loss= 0.019316878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.012574095, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13800, training loss= 0.010693935, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.019783685, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14000, training loss= 0.0117073255, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14100, training loss= 0.012167572, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14200, training loss= 0.01399757, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14300, training loss= 0.012688015, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14400, training loss= 0.019225437, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.00992128, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14600, training loss= 0.008841207, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.010326582, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.007372433, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.019664342, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.010504351, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.011666645, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15200, training loss= 0.015639639, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.018058402, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15400, training loss= 0.014686082, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.011076199, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.006377504, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15700, training loss= 0.008776022, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15800, training loss= 0.012641865, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15900, training loss= 0.012113582, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.012866443, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.01019335, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.012823124, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.013778481, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.011023332, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.01646699, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.0051611336, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16700, training loss= 0.008444757, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16800, training loss= 0.004633244, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16900, training loss= 0.011556686, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.010770087, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.010518276, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.008013764, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17300, training loss= 0.005018307, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17400, training loss= 0.0064670527, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.0068622134, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.009474615, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17700, training loss= 0.0075455727, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17800, training loss= 0.0046482747, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17900, training loss= 0.010449945, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18000, training loss= 0.007446697, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18100, training loss= 0.014098076, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18200, training loss= 0.022441668, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18300, training loss= 0.012340832, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18400, training loss= 0.0077223545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18500, training loss= 0.006920774, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.006828077, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.009815294, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18800, training loss= 0.0044782446, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18900, training loss= 0.005301247, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19000, training loss= 0.00845253, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19100, training loss= 0.0055013453, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19200, training loss= 0.012862838, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.0057748794, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.007818604, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.008842299, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.007116426, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19700, training loss= 0.004384382, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19800, training loss= 0.005933546, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19900, training loss= 0.005592092, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20000, training loss= 0.005686888, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20100, training loss= 0.0034530247, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20200, training loss= 0.0070539834, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20300, training loss= 0.0027495106, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20400, training loss= 0.009054754, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.0039406987, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20600, training loss= 0.011390776, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.0052010156, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20800, training loss= 0.0063994094, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20900, training loss= 0.0054136417, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.004942858, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.0052527157, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21200, training loss= 0.0056732344, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21300, training loss= 0.0039746966, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21400, training loss= 0.0060199224, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.0051224623, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21600, training loss= 0.00430792, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21700, training loss= 0.0045625814, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.011492177, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21900, training loss= 0.0061006015, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22000, training loss= 0.0058838697, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22100, training loss= 0.0034730353, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22200, training loss= 0.008267487, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22300, training loss= 0.0054917834, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.011534486, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22500, training loss= 0.004774589, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.0074155615, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22700, training loss= 0.0054513784, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22800, training loss= 0.0062110284, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.00573759, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23000, training loss= 0.006871652, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.0057938714, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.0025501247, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.005897901, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23400, training loss= 0.0025755921, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23500, training loss= 0.0056470567, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23600, training loss= 0.0037277928, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23700, training loss= 0.0042635156, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.0037621234, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.006056041, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24000, training loss= 0.0034957835, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24100, training loss= 0.005460504, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.0041296976, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.0041096825, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.0034284603, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24500, training loss= 0.00283673, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24600, training loss= 0.0034541741, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24700, training loss= 0.0032083555, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24800, training loss= 0.006586018, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 24900, training loss= 0.005634098, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.003860716, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.0031668984, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.0032699492, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.0038701736, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.0042426675, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25500, training loss= 0.0034472963, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.0033591776, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25700, training loss= 0.0023426926, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.0072680246, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.003417268, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.005262966, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26100, training loss= 0.003910167, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26200, training loss= 0.0025411432, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26300, training loss= 0.0034246265, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.0026969144, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.0020117396, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26600, training loss= 0.0028470631, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.0036676358, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.0033672578, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26900, training loss= 0.0035538245, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27000, training loss= 0.0030823115, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27100, training loss= 0.002065906, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27200, training loss= 0.0027999016, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27300, training loss= 0.0045044404, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.0030964713, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.0029130138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.0023501413, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27700, training loss= 0.0024806268, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27800, training loss= 0.0018639658, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.0025632717, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28000, training loss= 0.004341134, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.0020646078, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.0024867707, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28300, training loss= 0.0015799401, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28400, training loss= 0.0026702536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28500, training loss= 0.0015400297, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.002592114, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28700, training loss= 0.0039061257, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28800, training loss= 0.001371564, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 28900, training loss= 0.0028797134, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.0029780357, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.035928696, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 88.4000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.0067395093, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29300, training loss= 0.0033803314, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.0032328316, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.0031853474, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0018654376, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.0024449374, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.002764141, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.0016667338, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 90.9 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.191229, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.19165891, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.11254884, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.12078654, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 400, training loss= 0.06679879, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 500, training loss= 0.09112109, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 600, training loss= 0.053673036, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.0798405, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.08164522, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.093381695, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1000, training loss= 0.0564296, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.06695835, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.10006665, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.0621786, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.079237044, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1500, training loss= 0.0699187, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.07466367, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.09651919, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1800, training loss= 0.08220543, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1900, training loss= 0.07248737, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.09123461, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2100, training loss= 0.059635576, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.0702957, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2300, training loss= 0.07309471, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2400, training loss= 0.07127419, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2500, training loss= 0.06758719, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.05957796, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2700, training loss= 0.06275159, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.05935564, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.070369795, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3000, training loss= 0.05790904, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3100, training loss= 0.07127577, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.067139804, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.07238059, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.0663378, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.064172015, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3600, training loss= 0.060035538, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3700, training loss= 0.07490633, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.05577328, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.07158077, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4000, training loss= 0.062199313, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4100, training loss= 0.05583854, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4200, training loss= 0.04723678, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4300, training loss= 0.05826563, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.04242687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4500, training loss= 0.057875626, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.06685536, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.050862066, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.05042771, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4900, training loss= 0.039601117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.04325252, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.043464303, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.122334816, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.053768232, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.07182914, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.07300999, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5600, training loss= 0.048232503, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5700, training loss= 0.034050275, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.031864386, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5900, training loss= 0.036885913, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.040923025, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6100, training loss= 0.05678149, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6200, training loss= 0.038765807, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6300, training loss= 0.029060593, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.045486446, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.047594134, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.048983674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6700, training loss= 0.04506753, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6800, training loss= 0.044138953, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6900, training loss= 0.035543967, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.0463843, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7100, training loss= 0.040292706, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7200, training loss= 0.039941616, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7300, training loss= 0.029012378, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.055398908, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.04013042, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.09485838, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.06451859, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7800, training loss= 0.049125757, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.027223334, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8000, training loss= 0.033646174, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8100, training loss= 0.041543227, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.03814684, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8300, training loss= 0.05728055, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.03901031, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.042552214, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8600, training loss= 0.026290065, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8700, training loss= 0.04214222, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8800, training loss= 0.034659382, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8900, training loss= 0.027143281, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9000, training loss= 0.040738154, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.05981853, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.039609298, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.025699055, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.032102372, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.040352862, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9600, training loss= 0.031804245, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.033493783, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9800, training loss= 0.038623847, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9900, training loss= 0.031897712, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10000, training loss= 0.056541488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10100, training loss= 0.027602265, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.050810732, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10300, training loss= 0.04689969, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10400, training loss= 0.05722349, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10500, training loss= 0.026165277, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.030654155, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10700, training loss= 0.04426093, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.061953988, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.026810896, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.041048896, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11100, training loss= 0.037429687, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.052901074, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11300, training loss= 0.030334711, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11400, training loss= 0.052893907, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.026888402, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.034280114, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 11700, training loss= 0.036548797, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11800, training loss= 0.06636383, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.035277404, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12000, training loss= 0.03297004, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12100, training loss= 0.028878085, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.040607415, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12300, training loss= 0.030596593, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12400, training loss= 0.045790575, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12500, training loss= 0.017846687, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.03356145, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.03525335, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12800, training loss= 0.04765481, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.032348253, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.031324655, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.02829068, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13200, training loss= 0.037508346, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.031585958, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13400, training loss= 0.023312187, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13500, training loss= 0.029106561, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13600, training loss= 0.038491264, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13700, training loss= 0.022907114, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13800, training loss= 0.03977755, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13900, training loss= 0.025188856, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.06859596, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.029871551, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 14200, training loss= 0.02793362, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14300, training loss= 0.0242637, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14400, training loss= 0.03177997, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14500, training loss= 0.03386232, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14600, training loss= 0.02848401, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.030889021, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14800, training loss= 0.02914578, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14900, training loss= 0.030266462, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15000, training loss= 0.024479156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.025560025, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.03259207, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15300, training loss= 0.025513468, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15400, training loss= 0.02922835, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.032583516, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15600, training loss= 0.023151489, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.043719627, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.029240688, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15900, training loss= 0.03500608, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.02946982, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16100, training loss= 0.0327306, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16200, training loss= 0.027909491, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16300, training loss= 0.035764195, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.031066662, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.0304834, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.025741398, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16700, training loss= 0.01982715, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 16800, training loss= 0.023475561, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 16900, training loss= 0.036271974, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.027963122, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17100, training loss= 0.0246743, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17200, training loss= 0.018721733, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.032190286, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17400, training loss= 0.023674065, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17500, training loss= 0.03823791, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17600, training loss= 0.02476226, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17700, training loss= 0.020497607, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.015900156, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 17900, training loss= 0.028929893, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.020423803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.014936457, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18200, training loss= 0.023875065, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.03751482, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.022163121, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.028096663, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18600, training loss= 0.011694587, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18700, training loss= 0.024816167, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18800, training loss= 0.026280908, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 18900, training loss= 0.051889353, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.03683493, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19100, training loss= 0.020693634, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19200, training loss= 0.029672466, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 19300, training loss= 0.021550093, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.02786853, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.02585087, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19600, training loss= 0.027081154, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.06332689, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 19800, training loss= 0.022018539, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19900, training loss= 0.021753274, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20000, training loss= 0.027650194, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.017890478, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.02696676, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20300, training loss= 0.024251884, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 20400, training loss= 0.011460404, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20500, training loss= 0.022066565, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20600, training loss= 0.01272742, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 20700, training loss= 0.025353082, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20800, training loss= 0.017438274, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20900, training loss= 0.022254456, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21000, training loss= 0.030307706, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21100, training loss= 0.017351756, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.018852647, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.021383762, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21400, training loss= 0.020551413, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21500, training loss= 0.019704087, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.021350782, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.019662209, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21800, training loss= 0.01938009, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21900, training loss= 0.018302808, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22000, training loss= 0.019861886, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22100, training loss= 0.017574541, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 22200, training loss= 0.025287826, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.06115905, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22400, training loss= 0.033083424, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.02097488, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.017755678, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.024592046, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22800, training loss= 0.014845714, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22900, training loss= 0.015472553, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.016341742, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23100, training loss= 0.007693967, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23200, training loss= 0.026116565, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.016630339, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23400, training loss= 0.01985806, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23500, training loss= 0.029670082, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 23600, training loss= 0.025784902, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.018222185, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.015370956, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.016902812, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.020326266, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.016273925, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24200, training loss= 0.024763169, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 24300, training loss= 0.014315394, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.013560109, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24500, training loss= 0.024341743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24600, training loss= 0.052449983, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.01247847, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.017150218, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.02246384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25000, training loss= 0.012857726, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.021565156, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25200, training loss= 0.022527305, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25300, training loss= 0.009063523, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25400, training loss= 0.011936279, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25500, training loss= 0.010992319, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25600, training loss= 0.015369191, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25700, training loss= 0.015921468, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25800, training loss= 0.010578791, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25900, training loss= 0.014689262, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26000, training loss= 0.012432151, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.018366, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26200, training loss= 0.02837088, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26300, training loss= 0.05492098, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26400, training loss= 0.014582445, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26500, training loss= 0.013964288, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.013598987, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26700, training loss= 0.011502574, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26800, training loss= 0.026921067, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.03389521, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27000, training loss= 0.006997232, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.016368696, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27200, training loss= 0.013740546, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27300, training loss= 0.019505138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27400, training loss= 0.013374595, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.020378029, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27600, training loss= 0.014375765, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.013498231, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.019624354, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.012364462, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28000, training loss= 0.014720085, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28100, training loss= 0.013064348, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28200, training loss= 0.012346552, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.017172832, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28400, training loss= 0.013278367, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28500, training loss= 0.010999068, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 28600, training loss= 0.017385706, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.012722064, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28800, training loss= 0.010395544, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.019088153, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29000, training loss= 0.01403029, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29100, training loss= 0.010709813, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29200, training loss= 0.031208027, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.015735243, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.011849328, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.020035006, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29600, training loss= 0.016779728, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29700, training loss= 0.01394963, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29800, training loss= 0.018889187, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.014092201, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 1 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.6265739, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.08304785, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 200, training loss= 0.08102259, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 300, training loss= 0.1043339, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 400, training loss= 0.07549133, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.105647914, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.07702181, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.06749069, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.075774, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 900, training loss= 0.048562113, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1000, training loss= 0.05510956, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1100, training loss= 0.06842277, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1200, training loss= 0.09282347, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 1300, training loss= 0.060021896, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.050545227, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.063627616, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1600, training loss= 0.049233217, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.068023786, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1800, training loss= 0.07072421, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 1900, training loss= 0.07061729, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 2000, training loss= 0.05711626, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2100, training loss= 0.07806541, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2200, training loss= 0.041944165, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.05721875, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2400, training loss= 0.072159365, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.078669794, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2600, training loss= 0.05071194, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2700, training loss= 0.060906384, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.0472168, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2900, training loss= 0.04779773, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3000, training loss= 0.054409906, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.04959984, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.08405957, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3300, training loss= 0.041795466, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3400, training loss= 0.06442947, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.050644726, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3600, training loss= 0.06607673, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3700, training loss= 0.03864163, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3800, training loss= 0.04470504, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.035344955, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4000, training loss= 0.037129603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.042404488, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.037817996, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4300, training loss= 0.05204454, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4400, training loss= 0.04482446, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.04692294, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.03678098, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.040917974, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.057007276, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4900, training loss= 0.042581636, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.040901165, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.050039113, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.06626358, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.036191866, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5400, training loss= 0.029601544, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.043077167, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.051992506, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5700, training loss= 0.040128406, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5800, training loss= 0.04919796, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.025702044, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6000, training loss= 0.044022117, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6100, training loss= 0.039883442, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 6200, training loss= 0.038878884, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.037607964, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.045533486, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6500, training loss= 0.039105874, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.04086461, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6700, training loss= 0.036339547, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.025751757, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.021827787, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.034647387, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.029436836, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.03567787, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 7300, training loss= 0.040295374, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7400, training loss= 0.018117964, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.049440324, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.02606849, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7700, training loss= 0.02183716, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7800, training loss= 0.041133128, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 7900, training loss= 0.04837667, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8000, training loss= 0.02762487, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8100, training loss= 0.03696815, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.03485383, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8300, training loss= 0.028986368, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.02565945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8500, training loss= 0.03905866, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8600, training loss= 0.04403226, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.037943054, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8800, training loss= 0.032596823, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8900, training loss= 0.034273982, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9000, training loss= 0.025043253, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.01919035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9200, training loss= 0.039907616, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 9300, training loss= 0.026647683, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.032625657, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.029593373, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9600, training loss= 0.02788937, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9700, training loss= 0.024181478, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 9800, training loss= 0.036126874, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.026616432, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10000, training loss= 0.032658085, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 10100, training loss= 0.025962573, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 10200, training loss= 0.020818219, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.028771019, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 91.0999984741211 ...\n",
            "\n",
            "step 10400, training loss= 0.03340445, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10500, training loss= 0.02399766, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.031363346, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10700, training loss= 0.029313691, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.025370348, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 10900, training loss= 0.026597073, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 11000, training loss= 0.021597315, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 11100, training loss= 0.029189402, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.040495783, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.019280583, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.022649989, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11500, training loss= 0.014863884, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11600, training loss= 0.021710675, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 11700, training loss= 0.017400697, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 11800, training loss= 0.018746005, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11900, training loss= 0.01729412, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12000, training loss= 0.02205791, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12100, training loss= 0.026495026, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.021918735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.021348309, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 12400, training loss= 0.018402157, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.017724168, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.0298858, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.03509918, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12800, training loss= 0.02158515, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.024044218, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13000, training loss= 0.03233167, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13100, training loss= 0.023855034, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.021915607, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13300, training loss= 0.032462113, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 13400, training loss= 0.01677377, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.017918093, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 13600, training loss= 0.013302224, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 13700, training loss= 0.0196473, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 13800, training loss= 0.04363867, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.027026057, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14000, training loss= 0.008185981, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14100, training loss= 0.015311662, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14200, training loss= 0.015724326, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14300, training loss= 0.018147813, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14400, training loss= 0.015870227, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14500, training loss= 0.018958945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14600, training loss= 0.020127103, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.020582927, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.022103036, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.016263304, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.015326698, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 15100, training loss= 0.014633499, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.027829008, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 15300, training loss= 0.014881498, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15400, training loss= 0.030976953, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15500, training loss= 0.015012217, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.01657097, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15700, training loss= 0.0137746325, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15800, training loss= 0.014154744, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.0100888945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 16000, training loss= 0.011125884, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16100, training loss= 0.016582137, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.013649908, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16300, training loss= 0.015573271, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.009673573, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 16500, training loss= 0.011691419, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 16600, training loss= 0.026541904, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16700, training loss= 0.0216053, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 16800, training loss= 0.017952392, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 16900, training loss= 0.013890914, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17000, training loss= 0.013038047, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 17100, training loss= 0.022354743, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.016539361, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 17300, training loss= 0.038639307, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 17400, training loss= 0.018985892, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17500, training loss= 0.017920032, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17600, training loss= 0.02317852, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17700, training loss= 0.011380824, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 17800, training loss= 0.013837235, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 17900, training loss= 0.015556185, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18000, training loss= 0.012413566, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.014604481, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 18200, training loss= 0.009291385, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18300, training loss= 0.019405125, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 18400, training loss= 0.014971566, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.014846057, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18600, training loss= 0.0126648545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18700, training loss= 0.015376678, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18800, training loss= 0.012914596, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18900, training loss= 0.010087536, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19000, training loss= 0.010429308, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19100, training loss= 0.011850747, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19200, training loss= 0.011759111, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19300, training loss= 0.025373906, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19400, training loss= 0.02151052, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 0.015381225, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.013375023, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19700, training loss= 0.008605212, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 19800, training loss= 0.0108410735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 19900, training loss= 0.0069235372, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.017180802, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20100, training loss= 0.0073298654, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.013302929, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20300, training loss= 0.014303486, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.0127883805, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 20500, training loss= 0.009599064, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20600, training loss= 0.007364783, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20700, training loss= 0.009333384, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20800, training loss= 0.015390223, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20900, training loss= 0.009577845, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21000, training loss= 0.009400527, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21100, training loss= 0.010738522, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 21200, training loss= 0.0104158465, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21300, training loss= 0.011436636, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 0.007497135, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21500, training loss= 0.0069332286, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 21600, training loss= 0.0070307907, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 21700, training loss= 0.00769348, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21800, training loss= 0.008483147, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21900, training loss= 0.0080688745, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 0.011101025, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.008738891, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.01228488, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22300, training loss= 0.01587302, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22400, training loss= 0.00834844, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.011516885, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22600, training loss= 0.009398584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22700, training loss= 0.0080082575, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22800, training loss= 0.009557903, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22900, training loss= 0.010507029, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23000, training loss= 0.00967735, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23100, training loss= 0.008938545, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23200, training loss= 0.007361434, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23300, training loss= 0.038575117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 23400, training loss= 0.008615456, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 23500, training loss= 0.008761947, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23600, training loss= 0.009423472, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0999984741211 ...\n",
            "\n",
            "step 23700, training loss= 0.010768847, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 23800, training loss= 0.004513018, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0999984741211 ...\n",
            "\n",
            "step 23900, training loss= 0.007980636, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.005675543, training acc= 100.0%\n",
            "Validation Accuracy valid 91.29999542236328 ...\n",
            "\n",
            "step 24100, training loss= 0.009501258, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 24200, training loss= 0.0052392893, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.0077639427, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.006683429, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0999984741211 ...\n",
            "\n",
            "step 24500, training loss= 0.010467166, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.0068941135, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 24700, training loss= 0.008184566, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0999984741211 ...\n",
            "\n",
            "step 24800, training loss= 0.007812814, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 24900, training loss= 0.0063308156, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.009047995, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 25100, training loss= 0.03515731, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 25200, training loss= 0.008449129, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25300, training loss= 0.0075916764, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25400, training loss= 0.007288366, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25500, training loss= 0.007342273, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 0.0122300675, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 0.00881584, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25800, training loss= 0.006669634, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.009658776, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.006142715, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 26100, training loss= 0.009442588, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.00829712, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26300, training loss= 0.005768019, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26400, training loss= 0.006546159, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26500, training loss= 0.008818296, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 26600, training loss= 0.0061410535, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26700, training loss= 0.0051145004, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26800, training loss= 0.0095764045, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 26900, training loss= 0.0038623866, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.0025402599, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27100, training loss= 0.007060223, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27200, training loss= 0.006422579, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27300, training loss= 0.0070577613, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27400, training loss= 0.007669155, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 27500, training loss= 0.011602198, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27600, training loss= 0.004605776, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27700, training loss= 0.0069336197, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27800, training loss= 0.00939769, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27900, training loss= 0.0073000523, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.007938077, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28100, training loss= 0.012850752, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28200, training loss= 0.0043880804, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28300, training loss= 0.0067353374, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28400, training loss= 0.006163195, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.0037619732, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.0059289094, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28700, training loss= 0.006695697, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28800, training loss= 0.008042662, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28900, training loss= 0.0044074673, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29000, training loss= 0.0044865753, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.006539441, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 0.0035079771, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29300, training loss= 0.0074846433, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29400, training loss= 0.004117283, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29500, training loss= 0.00504593, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.0045381403, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29700, training loss= 0.0039511546, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 29800, training loss= 0.0066923737, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29900, training loss= 0.005434317, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "Valid acc= 91.299995 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.3449599, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.074902, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 200, training loss= 0.09589277, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.059836548, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.06183629, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.10572496, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 600, training loss= 0.073276475, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.10471521, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 800, training loss= 0.08185831, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.094424814, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.06869026, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.0850716, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1200, training loss= 0.083149076, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1300, training loss= 0.07297468, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1400, training loss= 0.055312317, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1500, training loss= 0.06506003, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1600, training loss= 0.055950005, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1700, training loss= 0.0577146, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.05451615, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 1900, training loss= 0.054733813, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2000, training loss= 0.0706765, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2100, training loss= 0.043800525, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2200, training loss= 0.06951522, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.056788716, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2400, training loss= 0.037125144, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2500, training loss= 0.0931114, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2600, training loss= 0.071109295, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2700, training loss= 0.060898848, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2800, training loss= 0.047101736, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.057304066, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.06034665, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.073664226, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3200, training loss= 0.05145164, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3300, training loss= 0.043871548, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.047907576, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 3500, training loss= 0.07874205, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.08039218, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.06703878, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3800, training loss= 0.06276833, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3900, training loss= 0.0542057, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4000, training loss= 0.070629366, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4100, training loss= 0.068390526, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 4200, training loss= 0.050332658, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4300, training loss= 0.051651023, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4400, training loss= 0.049404103, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4500, training loss= 0.04435574, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.05735399, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.047920052, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4800, training loss= 0.02383847, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.042732265, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5000, training loss= 0.04240207, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5100, training loss= 0.037701663, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5200, training loss= 0.045668565, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.043855976, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5400, training loss= 0.05009798, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5500, training loss= 0.06758038, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5600, training loss= 0.052550018, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.03704279, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 5800, training loss= 0.049813867, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 5900, training loss= 0.05908631, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6000, training loss= 0.03817319, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.05501245, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6200, training loss= 0.04955532, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 6300, training loss= 0.03519206, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6400, training loss= 0.03293425, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6500, training loss= 0.03822517, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.05575702, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.04832199, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6800, training loss= 0.0656927, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 6900, training loss= 0.029082354, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7000, training loss= 0.037043285, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 7100, training loss= 0.035765715, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7200, training loss= 0.032750223, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.054296974, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7400, training loss= 0.039916508, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.04230081, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.046412874, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7700, training loss= 0.04839241, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.028847674, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 7900, training loss= 0.028096775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.045409888, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8100, training loss= 0.051754754, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8200, training loss= 0.05092828, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8300, training loss= 0.032758337, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8400, training loss= 0.031352643, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.036772925, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.03176301, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 8700, training loss= 0.046779044, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.033858676, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.028580239, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9000, training loss= 0.042433918, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9100, training loss= 0.0351545, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 9200, training loss= 0.03301634, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9300, training loss= 0.020717785, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.0360634, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.037064478, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9600, training loss= 0.028812336, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9700, training loss= 0.040782306, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.05577147, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.026134593, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.05219985, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10100, training loss= 0.04929434, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 10200, training loss= 0.028093273, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10300, training loss= 0.037324667, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 10400, training loss= 0.026587242, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.04144529, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10600, training loss= 0.028158851, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 10700, training loss= 0.03480439, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10800, training loss= 0.05431198, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10900, training loss= 0.04588564, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.04633709, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.029614512, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 11200, training loss= 0.041111365, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11300, training loss= 0.035522863, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11400, training loss= 0.03395509, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.018754065, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.0501902, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.03077803, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 11800, training loss= 0.039956044, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.0303515, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12000, training loss= 0.026570307, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12100, training loss= 0.023597086, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12200, training loss= 0.019677717, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 12300, training loss= 0.019042721, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 12400, training loss= 0.030956954, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12500, training loss= 0.030308817, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 12600, training loss= 0.019768115, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.023397302, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.02204634, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12900, training loss= 0.06324919, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13000, training loss= 0.04356296, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.032119606, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 13200, training loss= 0.020022716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13300, training loss= 0.030529285, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.030478025, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.027301786, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.0347557, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 13700, training loss= 0.02392745, training acc= 100.0%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 13800, training loss= 0.036426682, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 13900, training loss= 0.051625002, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 14000, training loss= 0.055108216, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.022466637, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14200, training loss= 0.039101686, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.048877664, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 14400, training loss= 0.025964031, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14500, training loss= 0.034658358, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14600, training loss= 0.028106311, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14700, training loss= 0.03333648, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 14800, training loss= 0.025093766, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 14900, training loss= 0.040341113, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15000, training loss= 0.02644179, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.031414725, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15200, training loss= 0.032330465, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 15300, training loss= 0.024030004, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 15400, training loss= 0.033571355, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15500, training loss= 0.026663076, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 15600, training loss= 0.019260427, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.027036633, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15800, training loss= 0.026568959, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15900, training loss= 0.05186175, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 88.9000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.03145365, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.034990173, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16200, training loss= 0.026107792, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 16300, training loss= 0.021233616, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 16400, training loss= 0.03075546, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16500, training loss= 0.03215473, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.022057945, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.026249744, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16800, training loss= 0.02235781, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.022784142, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 17000, training loss= 0.021771818, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.018467274, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 17200, training loss= 0.01954375, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17300, training loss= 0.02891735, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17400, training loss= 0.026961142, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17500, training loss= 0.016564634, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17600, training loss= 0.02597748, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.022152552, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 17800, training loss= 0.053457685, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 17900, training loss= 0.08246437, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 18000, training loss= 0.019170668, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18100, training loss= 0.020870758, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18200, training loss= 0.02356133, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.021748314, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18400, training loss= 0.028498858, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 18500, training loss= 0.021150878, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18600, training loss= 0.030309651, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 18700, training loss= 0.024224482, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18800, training loss= 0.022272017, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18900, training loss= 0.023810867, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19000, training loss= 0.031559505, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.015080293, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19200, training loss= 0.023163458, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 19300, training loss= 0.024592167, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 19400, training loss= 0.029392978, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19500, training loss= 0.019781956, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19600, training loss= 0.017957713, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19700, training loss= 0.020450467, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.015500731, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 19900, training loss= 0.021432148, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20000, training loss= 0.029531682, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20100, training loss= 0.013846342, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 20200, training loss= 0.026615236, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20300, training loss= 0.023237262, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 20400, training loss= 0.02742762, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.20000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.023466347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20600, training loss= 0.020856436, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.022515183, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20800, training loss= 0.029971117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 20900, training loss= 0.02203422, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 21000, training loss= 0.020121293, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21100, training loss= 0.014925171, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.020045185, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.019447716, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21400, training loss= 0.022639591, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.027227191, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 21600, training loss= 0.011749589, training acc= 100.0%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 21700, training loss= 0.016878473, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 21800, training loss= 0.019077737, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21900, training loss= 0.015269437, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 22000, training loss= 0.020737136, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22100, training loss= 0.02103741, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.012894607, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22300, training loss= 0.019614838, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 22400, training loss= 0.026870653, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22500, training loss= 0.018766232, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 22600, training loss= 0.012949411, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 22700, training loss= 0.018929668, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.018311558, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 22900, training loss= 0.019475847, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23000, training loss= 0.014196941, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23100, training loss= 0.024122957, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.01764877, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.017664645, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 23400, training loss= 0.02240909, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 23500, training loss= 0.020002117, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.013277502, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23700, training loss= 0.06735972, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23800, training loss= 0.025970003, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 23900, training loss= 0.012382542, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24000, training loss= 0.020738086, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.014545762, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24200, training loss= 0.021948984, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 24300, training loss= 0.01157419, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 24400, training loss= 0.012863171, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24500, training loss= 0.018906603, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24600, training loss= 0.0155249955, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.020084018, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.017780576, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 24900, training loss= 0.011105802, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.019527907, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 25100, training loss= 0.02912581, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.0 ...\n",
            "\n",
            "step 25200, training loss= 0.015514566, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.023670657, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 25400, training loss= 0.017432254, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25500, training loss= 0.01907851, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.012964758, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25700, training loss= 0.011251216, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 25800, training loss= 0.017841375, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 25900, training loss= 0.015855482, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26000, training loss= 0.011744, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26100, training loss= 0.014635596, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.015964212, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.020555858, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26400, training loss= 0.0246102, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.011686074, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.012140898, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26700, training loss= 0.013922377, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 26800, training loss= 0.0137789585, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26900, training loss= 0.01917364, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27000, training loss= 0.024527546, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27100, training loss= 0.022107627, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 27200, training loss= 0.015082543, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.018914709, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 27400, training loss= 0.01836222, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 27500, training loss= 0.017910963, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 27600, training loss= 0.013654803, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.012571219, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 27800, training loss= 0.017039431, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 27900, training loss= 0.019244133, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28000, training loss= 0.017319798, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28100, training loss= 0.022985265, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28200, training loss= 0.02058006, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28300, training loss= 0.015139163, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28400, training loss= 0.020521963, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 28500, training loss= 0.018492423, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28600, training loss= 0.01645259, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.02264532, training acc= 100.0%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.01678212, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 28900, training loss= 0.016725859, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.015063269, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29100, training loss= 0.012848408, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29200, training loss= 0.014196936, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29300, training loss= 0.011044723, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29400, training loss= 0.010152553, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29500, training loss= 0.015517922, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 29600, training loss= 0.020069914, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.033217184, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 29800, training loss= 0.014801456, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 29900, training loss= 0.02269168, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "Valid acc= 90.5 %\n",
            "Validation Accuracy Test 83.9879150390625 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 2 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 0.75679547, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.07081474, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 200, training loss= 0.06280635, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.06366221, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 400, training loss= 0.09899042, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 500, training loss= 0.07793575, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 600, training loss= 0.05336939, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 700, training loss= 0.06624834, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 800, training loss= 0.07359494, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 900, training loss= 0.044813804, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1000, training loss= 0.08861605, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1100, training loss= 0.05504379, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1200, training loss= 0.053607047, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.06016055, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1400, training loss= 0.045840103, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1500, training loss= 0.06469011, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1600, training loss= 0.026452363, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1700, training loss= 0.07408973, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 1800, training loss= 0.07872581, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1900, training loss= 0.05435951, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.03658667, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 2100, training loss= 0.06047278, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.0688393, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2300, training loss= 0.06912128, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2400, training loss= 0.05234959, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 2500, training loss= 0.05970593, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 2600, training loss= 0.05290348, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2700, training loss= 0.08860385, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2800, training loss= 0.05079078, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2900, training loss= 0.038509693, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3000, training loss= 0.05681508, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3100, training loss= 0.045058385, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 3200, training loss= 0.06940509, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3300, training loss= 0.06343162, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3400, training loss= 0.044229556, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.05163684, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3600, training loss= 0.037393108, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3700, training loss= 0.049938753, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3800, training loss= 0.03878649, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3900, training loss= 0.04027407, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4000, training loss= 0.043519676, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4100, training loss= 0.053636312, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4200, training loss= 0.05380392, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.030415347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 4400, training loss= 0.045118764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.042037047, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 4600, training loss= 0.040465083, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4700, training loss= 0.03071172, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 4800, training loss= 0.030626727, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4900, training loss= 0.05233832, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5000, training loss= 0.054583937, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.040631156, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 5200, training loss= 0.04986969, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5300, training loss= 0.04556356, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.036749996, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5500, training loss= 0.050614934, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.040123448, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 5700, training loss= 0.034159377, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5800, training loss= 0.044930283, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5900, training loss= 0.040787436, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6000, training loss= 0.028979298, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 6100, training loss= 0.029606925, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6200, training loss= 0.034030393, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6300, training loss= 0.034166645, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.031820152, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 6500, training loss= 0.030274983, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 6600, training loss= 0.03324377, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 6700, training loss= 0.042651016, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 6800, training loss= 0.029714698, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 6900, training loss= 0.025159061, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 7000, training loss= 0.03281623, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7100, training loss= 0.049797576, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7200, training loss= 0.054433372, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 7300, training loss= 0.051772356, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7400, training loss= 0.024570739, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7500, training loss= 0.02564811, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7600, training loss= 0.032917127, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7700, training loss= 0.04374796, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 7800, training loss= 0.038355693, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 7900, training loss= 0.05020865, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 8000, training loss= 0.029766709, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 8100, training loss= 0.030296382, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8200, training loss= 0.026735488, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8300, training loss= 0.037849803, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8400, training loss= 0.033114783, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.030070368, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8600, training loss= 0.026793672, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8700, training loss= 0.020989303, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 8800, training loss= 0.027361542, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8900, training loss= 0.05909345, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 9000, training loss= 0.03502909, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9100, training loss= 0.040956933, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 9200, training loss= 0.032880504, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9300, training loss= 0.034607187, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9400, training loss= 0.029071216, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9500, training loss= 0.020229496, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9600, training loss= 0.029638777, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 9700, training loss= 0.04350096, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9800, training loss= 0.029622955, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 9900, training loss= 0.02410535, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 10000, training loss= 0.038935233, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 10100, training loss= 0.024565365, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10200, training loss= 0.036906324, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10300, training loss= 0.01805889, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10400, training loss= 0.053318918, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10500, training loss= 0.05003132, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10600, training loss= 0.026512822, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 10700, training loss= 0.029575706, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10800, training loss= 0.027959665, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10900, training loss= 0.031671118, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11000, training loss= 0.028805962, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11100, training loss= 0.026963085, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11200, training loss= 0.03351192, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11300, training loss= 0.020024452, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11400, training loss= 0.036556266, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 11500, training loss= 0.016309122, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 11600, training loss= 0.031086484, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11700, training loss= 0.025146767, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 11800, training loss= 0.026754167, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 11900, training loss= 0.025431879, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.02481731, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12100, training loss= 0.015811194, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12200, training loss= 0.02765058, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12300, training loss= 0.035678297, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12400, training loss= 0.019866366, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12500, training loss= 0.028845033, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 12600, training loss= 0.024685556, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 12700, training loss= 0.020810276, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 12800, training loss= 0.025057456, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 12900, training loss= 0.026379539, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.014780223, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.01943725, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 13200, training loss= 0.024289586, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13300, training loss= 0.023065606, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13400, training loss= 0.01983503, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13500, training loss= 0.025770688, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.02287854, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 13700, training loss= 0.025043776, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 13800, training loss= 0.019664695, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 13900, training loss= 0.015131841, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.03667991, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 14100, training loss= 0.016094577, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14200, training loss= 0.015487794, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 14300, training loss= 0.023650363, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 14400, training loss= 0.021951376, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14500, training loss= 0.020197019, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 14600, training loss= 0.01601215, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 14700, training loss= 0.015912028, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 14800, training loss= 0.017600587, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 14900, training loss= 0.022708174, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 15000, training loss= 0.025646027, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 15100, training loss= 0.020948514, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.015224836, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15300, training loss= 0.01747478, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15400, training loss= 0.017523913, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15500, training loss= 0.015705185, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15600, training loss= 0.034979716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.023895415, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 15800, training loss= 0.013134477, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 15900, training loss= 0.021646554, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16000, training loss= 0.025015093, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16100, training loss= 0.02112901, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16200, training loss= 0.014189111, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16300, training loss= 0.011910955, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.017215675, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 16500, training loss= 0.01931409, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 16600, training loss= 0.021848323, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16700, training loss= 0.021479802, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 16800, training loss= 0.021601256, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16900, training loss= 0.016531518, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17000, training loss= 0.028339293, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17100, training loss= 0.018741872, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17200, training loss= 0.014112485, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17300, training loss= 0.023035573, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17400, training loss= 0.0149436295, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17500, training loss= 0.014055693, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17600, training loss= 0.01730029, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17700, training loss= 0.0155313, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17800, training loss= 0.014124734, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 17900, training loss= 0.022686524, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 18000, training loss= 0.008984524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18100, training loss= 0.01564145, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 0.020040566, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 18300, training loss= 0.012395037, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18400, training loss= 0.027470766, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.008639417, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18600, training loss= 0.016025703, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18700, training loss= 0.008957602, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 18800, training loss= 0.023008062, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 18900, training loss= 0.019335525, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19000, training loss= 0.009296053, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19100, training loss= 0.009752293, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19200, training loss= 0.018876882, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19300, training loss= 0.019063586, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 19400, training loss= 0.016843673, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 19500, training loss= 0.017282732, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19600, training loss= 0.011430315, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19700, training loss= 0.014444174, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19800, training loss= 0.015717337, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19900, training loss= 0.016943196, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20000, training loss= 0.012099822, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20100, training loss= 0.007437586, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20200, training loss= 0.014087988, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20300, training loss= 0.008728945, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 20400, training loss= 0.011700089, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20500, training loss= 0.010247895, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20600, training loss= 0.016652491, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20700, training loss= 0.0120919915, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20800, training loss= 0.017388152, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 20900, training loss= 0.011439975, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21000, training loss= 0.008600276, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21100, training loss= 0.010352073, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21200, training loss= 0.010570584, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21300, training loss= 0.013387248, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 21400, training loss= 0.00930899, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 21500, training loss= 0.015334421, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21600, training loss= 0.01795302, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21700, training loss= 0.013988352, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 21800, training loss= 0.014927968, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21900, training loss= 0.013111045, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 0.010867181, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22100, training loss= 0.014942039, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22200, training loss= 0.011927684, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22300, training loss= 0.013779422, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22400, training loss= 0.017055834, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22500, training loss= 0.012009439, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22600, training loss= 0.011276359, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22700, training loss= 0.010725729, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.016683344, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22900, training loss= 0.011973511, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23000, training loss= 0.009451692, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23100, training loss= 0.012099035, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23200, training loss= 0.009368331, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23300, training loss= 0.011006612, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 23400, training loss= 0.010838734, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23500, training loss= 0.005598637, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23600, training loss= 0.007241664, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23700, training loss= 0.017372483, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.0118427295, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 23900, training loss= 0.009422, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24000, training loss= 0.009555551, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24100, training loss= 0.014685879, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24200, training loss= 0.016324202, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24300, training loss= 0.0097949775, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24400, training loss= 0.01291351, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 24500, training loss= 0.011992081, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.009572125, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24700, training loss= 0.007926663, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24800, training loss= 0.016358398, training acc= 100.0%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 24900, training loss= 0.010304334, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25000, training loss= 0.009419878, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.006898548, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 0.009377417, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25300, training loss= 0.015331809, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 25400, training loss= 0.006629987, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25500, training loss= 0.006335493, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25600, training loss= 0.008806114, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25700, training loss= 0.008941826, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25800, training loss= 0.0071945554, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25900, training loss= 0.007364588, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26000, training loss= 0.0060440055, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26100, training loss= 0.0070970887, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26200, training loss= 0.007969733, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.0073657655, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26400, training loss= 0.009644138, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.012190102, training acc= 100.0%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 26600, training loss= 0.009921942, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 26700, training loss= 0.007412004, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 26800, training loss= 0.0118651455, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 26900, training loss= 0.010134011, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27000, training loss= 0.010016161, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27100, training loss= 0.008414461, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27200, training loss= 0.007586393, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 27300, training loss= 0.0068582282, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27400, training loss= 0.008116717, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.014664011, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.008820603, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27700, training loss= 0.008708722, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27800, training loss= 0.008889505, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27900, training loss= 0.008752582, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28000, training loss= 0.040200785, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 28100, training loss= 0.01011335, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28200, training loss= 0.006940591, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28300, training loss= 0.010779736, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28400, training loss= 0.009165724, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 28500, training loss= 0.011138864, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28600, training loss= 0.005832427, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28700, training loss= 0.010571994, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28800, training loss= 0.007971218, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28900, training loss= 0.0053900364, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29000, training loss= 0.009818352, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29100, training loss= 0.0056008943, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 29200, training loss= 0.0085270265, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29300, training loss= 0.007393669, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29400, training loss= 0.0072957817, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 29500, training loss= 0.0099451905, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 29600, training loss= 0.00634401, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29700, training loss= 0.00650458, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 29800, training loss= 0.011032774, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29900, training loss= 0.00871436, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "Valid acc= 91.0 %\n",
            "Validation Accuracy Test 85.49848937988281 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 0 ...\n",
            "**************************************************\n",
            "==================================================\n",
            "step 0, training loss= 1.5694593, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 100, training loss= 0.12637532, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 200, training loss= 0.06355765, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 300, training loss= 0.06642344, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 400, training loss= 0.07158377, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 500, training loss= 0.06997821, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 600, training loss= 0.060942102, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 700, training loss= 0.06342124, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 800, training loss= 0.073283695, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 900, training loss= 0.07972445, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 1000, training loss= 0.08275899, training acc= 95.99999785423279%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 1100, training loss= 0.07295144, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1200, training loss= 0.061242413, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 1300, training loss= 0.10909607, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 1400, training loss= 0.06483579, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1500, training loss= 0.0829496, training acc= 95.49999833106995%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 1600, training loss= 0.056935906, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1700, training loss= 0.037935235, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 1800, training loss= 0.059340358, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 1900, training loss= 0.03811501, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2000, training loss= 0.06021077, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2100, training loss= 0.053418674, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2200, training loss= 0.04702893, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 2300, training loss= 0.045469265, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 2400, training loss= 0.06987353, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2500, training loss= 0.041206714, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2600, training loss= 0.04475248, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 2700, training loss= 0.07773595, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 2800, training loss= 0.09256845, training acc= 94.9999988079071%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 2900, training loss= 0.059399635, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 3000, training loss= 0.053325184, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 3100, training loss= 0.03762651, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 3200, training loss= 0.05542798, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3300, training loss= 0.058439918, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 3400, training loss= 0.05177675, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 3500, training loss= 0.067592956, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3600, training loss= 0.057191033, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3700, training loss= 0.059474856, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 3800, training loss= 0.03752176, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 3900, training loss= 0.06513607, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4000, training loss= 0.053925753, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4100, training loss= 0.0351326, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4200, training loss= 0.04917344, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 4300, training loss= 0.051746514, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 4400, training loss= 0.043434832, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4500, training loss= 0.051068176, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 4600, training loss= 0.061288875, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 4700, training loss= 0.039645176, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 4800, training loss= 0.03883594, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 4900, training loss= 0.05186769, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 5000, training loss= 0.0434495, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5100, training loss= 0.036383826, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5200, training loss= 0.026648117, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5300, training loss= 0.07267495, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 5400, training loss= 0.05749023, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5500, training loss= 0.04060542, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 5600, training loss= 0.046978947, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5700, training loss= 0.030293597, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5800, training loss= 0.039155643, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 5900, training loss= 0.04167304, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6000, training loss= 0.04443286, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6100, training loss= 0.049852315, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6200, training loss= 0.04436712, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6300, training loss= 0.047114573, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6400, training loss= 0.06618199, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 6500, training loss= 0.036605574, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6600, training loss= 0.032325894, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6700, training loss= 0.043450233, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 6800, training loss= 0.04848649, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 6900, training loss= 0.039726537, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 7000, training loss= 0.03901049, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7100, training loss= 0.030428592, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 7200, training loss= 0.0504163, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 7300, training loss= 0.037992105, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7400, training loss= 0.033300463, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 7500, training loss= 0.053445715, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7600, training loss= 0.034053225, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7700, training loss= 0.040821303, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 7800, training loss= 0.040084027, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 7900, training loss= 0.03953073, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 8000, training loss= 0.036103662, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8100, training loss= 0.035388615, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 8200, training loss= 0.029057397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 8300, training loss= 0.032481443, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 8400, training loss= 0.033493217, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8500, training loss= 0.03828795, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8600, training loss= 0.03176112, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8700, training loss= 0.03629731, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 8800, training loss= 0.045571882, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 8900, training loss= 0.038294736, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9000, training loss= 0.01950348, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9100, training loss= 0.03671067, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 9200, training loss= 0.035009205, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 9300, training loss= 0.037597943, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 9400, training loss= 0.03918584, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9500, training loss= 0.030920012, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 9600, training loss= 0.057198286, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 9700, training loss= 0.03971899, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 9800, training loss= 0.048510145, training acc= 96.49999737739563%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 9900, training loss= 0.039731737, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10000, training loss= 0.026370296, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10100, training loss= 0.02989744, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 10200, training loss= 0.029818757, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10300, training loss= 0.034341257, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10400, training loss= 0.020774832, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 10500, training loss= 0.02688374, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 10600, training loss= 0.04142746, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 10700, training loss= 0.043195717, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 10800, training loss= 0.07381206, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 10900, training loss= 0.03999494, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 11000, training loss= 0.04873852, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 11100, training loss= 0.030901609, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11200, training loss= 0.029702334, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11300, training loss= 0.032749023, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11400, training loss= 0.012884811, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11500, training loss= 0.029911537, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 11600, training loss= 0.037549764, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 11700, training loss= 0.030249467, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 11800, training loss= 0.017575545, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 11900, training loss= 0.029281357, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 12000, training loss= 0.045476805, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.30000305175781 ...\n",
            "\n",
            "step 12100, training loss= 0.022284618, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 12200, training loss= 0.02666964, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12300, training loss= 0.028823355, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 12400, training loss= 0.026685018, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 12500, training loss= 0.024458956, training acc= 100.0%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 12600, training loss= 0.029665157, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12700, training loss= 0.023005856, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 12800, training loss= 0.04543915, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 12900, training loss= 0.020646172, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13000, training loss= 0.03113901, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13100, training loss= 0.06139194, training acc= 97.00000286102295%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13200, training loss= 0.028582249, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13300, training loss= 0.035876434, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13400, training loss= 0.02280443, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13500, training loss= 0.026039904, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 13600, training loss= 0.03706136, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 13700, training loss= 0.03212428, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 13800, training loss= 0.03313335, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 13900, training loss= 0.032528378, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14000, training loss= 0.024839425, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14100, training loss= 0.022450205, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 14200, training loss= 0.023158256, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 14300, training loss= 0.024050463, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 14400, training loss= 0.019785905, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14500, training loss= 0.030116046, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14600, training loss= 0.03764266, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 14700, training loss= 0.024436232, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 14800, training loss= 0.024750566, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 14900, training loss= 0.02127124, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15000, training loss= 0.020835347, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 15100, training loss= 0.027498284, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15200, training loss= 0.03321631, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15300, training loss= 0.028440828, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15400, training loss= 0.03455818, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 15500, training loss= 0.020359505, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.4000015258789 ...\n",
            "\n",
            "step 15600, training loss= 0.028231142, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 15700, training loss= 0.026847554, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 15800, training loss= 0.01898783, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 15900, training loss= 0.016311135, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16000, training loss= 0.022812353, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 16100, training loss= 0.015390067, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 16200, training loss= 0.027240394, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 16300, training loss= 0.029510295, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16400, training loss= 0.03194397, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16500, training loss= 0.026387146, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.60000610351562 ...\n",
            "\n",
            "step 16600, training loss= 0.026033554, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 16700, training loss= 0.018591989, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 16800, training loss= 0.034659643, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 16900, training loss= 0.02899693, training acc= 98.00000190734863%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17000, training loss= 0.016261274, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17100, training loss= 0.020853337, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17200, training loss= 0.033146065, training acc= 97.50000238418579%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 17300, training loss= 0.023720592, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17400, training loss= 0.017346444, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 17500, training loss= 0.024414046, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17600, training loss= 0.0254691, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 17700, training loss= 0.022006074, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 17800, training loss= 0.022555983, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 17900, training loss= 0.024281424, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18000, training loss= 0.022401515, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18100, training loss= 0.017856108, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 18200, training loss= 0.016257118, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 18300, training loss= 0.016927563, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.5 ...\n",
            "\n",
            "step 18400, training loss= 0.022881033, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 18500, training loss= 0.012962492, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 18600, training loss= 0.015334132, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 18700, training loss= 0.019690564, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18800, training loss= 0.025154918, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 18900, training loss= 0.015826946, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19000, training loss= 0.02233601, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 19100, training loss= 0.027506227, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19200, training loss= 0.020692071, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19300, training loss= 0.023360765, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 19400, training loss= 0.02150642, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 19500, training loss= 0.020714415, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 19600, training loss= 0.016505875, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 19700, training loss= 0.017043998, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 19800, training loss= 0.021697493, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 19900, training loss= 0.01760698, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20000, training loss= 0.020361286, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 20100, training loss= 0.027505403, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 20200, training loss= 0.021818636, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 20300, training loss= 0.022651685, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 20400, training loss= 0.024408463, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 20500, training loss= 0.021578213, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20600, training loss= 0.017292075, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 20700, training loss= 0.02306002, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 20800, training loss= 0.011787294, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 20900, training loss= 0.016604675, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 21000, training loss= 0.017751971, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 21100, training loss= 0.016041702, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21200, training loss= 0.015987309, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21300, training loss= 0.020999976, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 21400, training loss= 0.030165603, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21500, training loss= 0.014882746, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21600, training loss= 0.015164721, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 21700, training loss= 0.015341671, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 21800, training loss= 0.019837672, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 21900, training loss= 0.020681923, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22000, training loss= 0.013876972, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 22100, training loss= 0.02256211, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 22200, training loss= 0.020196319, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22300, training loss= 0.0131222, training acc= 100.0%\n",
            "Validation Accuracy valid 89.70000457763672 ...\n",
            "\n",
            "step 22400, training loss= 0.017679824, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 22500, training loss= 0.014204385, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 22600, training loss= 0.009722608, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 22700, training loss= 0.016862359, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 22800, training loss= 0.015835961, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 22900, training loss= 0.01874206, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23000, training loss= 0.025868831, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 23100, training loss= 0.022823958, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23200, training loss= 0.013747461, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 23300, training loss= 0.015834, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 23400, training loss= 0.016465759, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 23500, training loss= 0.020950487, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 23600, training loss= 0.025505355, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23700, training loss= 0.018338738, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 23800, training loss= 0.014266297, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 23900, training loss= 0.01363109, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24000, training loss= 0.014053511, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24100, training loss= 0.026716208, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24200, training loss= 0.0137573555, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 24300, training loss= 0.015840162, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 24400, training loss= 0.015800362, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 24500, training loss= 0.015371637, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 24600, training loss= 0.019100716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 24700, training loss= 0.017559065, training acc= 100.0%\n",
            "step 24800, training loss= 0.020567974, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 24900, training loss= 0.019712413, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25000, training loss= 0.016346902, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 25100, training loss= 0.019951742, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25200, training loss= 0.01830764, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25300, training loss= 0.047792614, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 25400, training loss= 0.016709875, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 25500, training loss= 0.011904955, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 25600, training loss= 0.019038497, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 25700, training loss= 0.01725483, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 25800, training loss= 0.017216286, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 25900, training loss= 0.01644016, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26000, training loss= 0.020860871, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26100, training loss= 0.019329716, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26200, training loss= 0.014855427, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26300, training loss= 0.010393524, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 26400, training loss= 0.01399036, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 26500, training loss= 0.012932958, training acc= 100.0%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 26600, training loss= 0.014599561, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26700, training loss= 0.008288907, training acc= 100.0%\n",
            "Validation Accuracy valid 90.10000610351562 ...\n",
            "\n",
            "step 26800, training loss= 0.013115718, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 26900, training loss= 0.07549893, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.9000015258789 ...\n",
            "\n",
            "step 27000, training loss= 0.02935499, training acc= 98.50000143051147%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 27100, training loss= 0.015895506, training acc= 100.0%\n",
            "Validation Accuracy valid 91.0 ...\n",
            "\n",
            "step 27200, training loss= 0.017134175, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.80000305175781 ...\n",
            "\n",
            "step 27300, training loss= 0.015834767, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 27400, training loss= 0.013056703, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27500, training loss= 0.011973573, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27600, training loss= 0.019982448, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27700, training loss= 0.011783188, training acc= 100.0%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 27800, training loss= 0.014097226, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5999984741211 ...\n",
            "\n",
            "step 27900, training loss= 0.010302587, training acc= 100.0%\n",
            "Validation Accuracy valid 90.69999694824219 ...\n",
            "\n",
            "step 28000, training loss= 0.017444355, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28100, training loss= 0.012027973, training acc= 100.0%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28200, training loss= 0.012946295, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.5 ...\n",
            "\n",
            "step 28300, training loss= 0.008197352, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28400, training loss= 0.010157335, training acc= 100.0%\n",
            "Validation Accuracy valid 89.9000015258789 ...\n",
            "\n",
            "step 28500, training loss= 0.014045158, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.30000305175781 ...\n",
            "\n",
            "step 28600, training loss= 0.009555917, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28700, training loss= 0.009071981, training acc= 100.0%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28800, training loss= 0.0182757, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.4000015258789 ...\n",
            "\n",
            "step 28900, training loss= 0.016445674, training acc= 100.0%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29000, training loss= 0.018839577, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 89.0999984741211 ...\n",
            "\n",
            "step 29100, training loss= 0.012067353, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29200, training loss= 0.014141534, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29300, training loss= 0.008165533, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29400, training loss= 0.01345704, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 89.80000305175781 ...\n",
            "\n",
            "step 29500, training loss= 0.015406268, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29600, training loss= 0.020329116, training acc= 99.00000095367432%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29700, training loss= 0.0111157475, training acc= 100.0%\n",
            "Validation Accuracy valid 90.20000457763672 ...\n",
            "\n",
            "step 29800, training loss= 0.014459287, training acc= 100.0%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "step 29900, training loss= 0.018529385, training acc= 99.50000047683716%\n",
            "Validation Accuracy valid 90.0 ...\n",
            "\n",
            "Valid acc= 91.0 %\n",
            "Validation Accuracy Test 85.80060577392578 ...\n",
            "==================================================\n",
            "W1 = 6 ...\n",
            "W2 = 3 ...\n",
            "W3 = 1 ...\n",
            "**************************************************\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tB8zakGK3Zzp"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### --\n",
        "#### Valid acc= 98.5 %\n",
        "#### Validation Accuracy Test 98.08917236328125 ...\n",
        "==================================================\n",
        "W1 = 5 ...\n",
        "W2 = 4 ...\n",
        "W3 = 0 ...\n",
        "**************************************************\n",
        "==================================================\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DysvlYK_3UuW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bFyJSL6Yx7Dt"
      },
      "cell_type": "markdown",
      "source": [
        "## contd from above different start point"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsk4HwnCPtR3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameter tuning"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jz2-ZZrWPz1c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max(ValidAccuracy_Track)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTX6kBhaPzyc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oOV5_7Er2qmC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Track)\n",
        "plt.plot(ValidAccuracy_Test_track)\n",
        "\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aXUrVrDqPzum",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "splt.plot(ValidAccuracy_Track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qDiB6tNU4DUq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Track],bins=30)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QFb2ZTPYk0_K"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WOMNr2hxk1Py"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xClVvxq_hQ50",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ValidAccuracy_Test_track)\n",
        "plt.ylabel('Iter')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YmTBX6sTqm6m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.hist([ValidAccuracy_Test_track],bins=30)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tXZ8K7a_qm2Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
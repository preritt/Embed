{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SatimFullDatasetProbBasedTestAccTestAcc90p5 .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/SatimFullDatasetProbBasedTestAccTestAcc90p5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qWL1XvRKt0EI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yuoNYnTshaZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G4FSwFTChgdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_label = np.concatenate((train_label, validation_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5erFTN6-BRM",
        "colab_type": "code",
        "outputId": "d08a57f3-1531-40c6-db41-3b70905d45d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "VloppGYRyrEX",
        "colab_type": "code",
        "outputId": "00b74c35-9804-4a65-9fc0-1527f55ca262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(90, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.95444174\n",
            "Iteration 2, loss = 0.41361696\n",
            "Iteration 3, loss = 0.37376292\n",
            "Iteration 4, loss = 0.35310299\n",
            "Iteration 5, loss = 0.33669458\n",
            "Iteration 6, loss = 0.32397037\n",
            "Iteration 7, loss = 0.31519296\n",
            "Iteration 8, loss = 0.30943933\n",
            "Iteration 9, loss = 0.30110286\n",
            "Iteration 10, loss = 0.29639559\n",
            "Iteration 11, loss = 0.29181714\n",
            "Iteration 12, loss = 0.28519907\n",
            "Iteration 13, loss = 0.27945018\n",
            "Iteration 14, loss = 0.27446988\n",
            "Iteration 15, loss = 0.27230486\n",
            "Iteration 16, loss = 0.26854954\n",
            "Iteration 17, loss = 0.26347512\n",
            "Iteration 18, loss = 0.25999897\n",
            "Iteration 19, loss = 0.25824005\n",
            "Iteration 20, loss = 0.25456133\n",
            "Iteration 21, loss = 0.24952501\n",
            "Iteration 22, loss = 0.24607191\n",
            "Iteration 23, loss = 0.24673228\n",
            "Iteration 24, loss = 0.24442729\n",
            "Iteration 25, loss = 0.24115307\n",
            "Iteration 26, loss = 0.23827513\n",
            "Iteration 27, loss = 0.23520357\n",
            "Iteration 28, loss = 0.23354455\n",
            "Iteration 29, loss = 0.22978524\n",
            "Iteration 30, loss = 0.22810795\n",
            "Iteration 31, loss = 0.22567502\n",
            "Iteration 32, loss = 0.22661689\n",
            "Iteration 33, loss = 0.22176630\n",
            "Iteration 34, loss = 0.22185255\n",
            "Iteration 35, loss = 0.21909550\n",
            "Iteration 36, loss = 0.21857916\n",
            "Iteration 37, loss = 0.21802408\n",
            "Iteration 38, loss = 0.21273616\n",
            "Iteration 39, loss = 0.21271724\n",
            "Iteration 40, loss = 0.21180686\n",
            "Iteration 41, loss = 0.20911150\n",
            "Iteration 42, loss = 0.20824662\n",
            "Iteration 43, loss = 0.20727753\n",
            "Iteration 44, loss = 0.20444614\n",
            "Iteration 45, loss = 0.20458268\n",
            "Iteration 46, loss = 0.20322771\n",
            "Iteration 47, loss = 0.20093423\n",
            "Iteration 48, loss = 0.19972227\n",
            "Iteration 49, loss = 0.19969319\n",
            "Iteration 50, loss = 0.19881669\n",
            "Iteration 51, loss = 0.19614789\n",
            "Iteration 52, loss = 0.19417483\n",
            "Iteration 53, loss = 0.19168104\n",
            "Iteration 54, loss = 0.19479601\n",
            "Iteration 55, loss = 0.19010506\n",
            "Iteration 56, loss = 0.19106383\n",
            "Iteration 57, loss = 0.19142207\n",
            "Iteration 58, loss = 0.18865416\n",
            "Iteration 59, loss = 0.18610193\n",
            "Iteration 60, loss = 0.18574850\n",
            "Iteration 61, loss = 0.18561203\n",
            "Iteration 62, loss = 0.18429022\n",
            "Iteration 63, loss = 0.18052444\n",
            "Iteration 64, loss = 0.18136414\n",
            "Iteration 65, loss = 0.18031222\n",
            "Iteration 66, loss = 0.17744159\n",
            "Iteration 67, loss = 0.18027992\n",
            "Iteration 68, loss = 0.17645335\n",
            "Iteration 69, loss = 0.17403393\n",
            "Iteration 70, loss = 0.17429126\n",
            "Iteration 71, loss = 0.17618357\n",
            "Iteration 72, loss = 0.17183623\n",
            "Iteration 73, loss = 0.17166370\n",
            "Iteration 74, loss = 0.17217259\n",
            "Iteration 75, loss = 0.16904945\n",
            "Iteration 76, loss = 0.17088875\n",
            "Iteration 77, loss = 0.17259165\n",
            "Iteration 78, loss = 0.16779362\n",
            "Iteration 79, loss = 0.16512526\n",
            "Iteration 80, loss = 0.16614422\n",
            "Iteration 81, loss = 0.16629507\n",
            "Iteration 82, loss = 0.16287885\n",
            "Iteration 83, loss = 0.16415537\n",
            "Iteration 84, loss = 0.16234924\n",
            "Iteration 85, loss = 0.16424623\n",
            "Iteration 86, loss = 0.15978972\n",
            "Iteration 87, loss = 0.16143070\n",
            "Iteration 88, loss = 0.15866024\n",
            "Iteration 89, loss = 0.15941105\n",
            "Iteration 90, loss = 0.15681068\n",
            "Iteration 91, loss = 0.15561312\n",
            "Iteration 92, loss = 0.15621932\n",
            "Iteration 93, loss = 0.15605395\n",
            "Iteration 94, loss = 0.15510723\n",
            "Iteration 95, loss = 0.15339714\n",
            "Iteration 96, loss = 0.15174013\n",
            "Iteration 97, loss = 0.15426171\n",
            "Iteration 98, loss = 0.15044099\n",
            "Iteration 99, loss = 0.15172792\n",
            "Iteration 100, loss = 0.14968459\n",
            "Iteration 101, loss = 0.14847401\n",
            "Iteration 102, loss = 0.14847588\n",
            "Iteration 103, loss = 0.14778554\n",
            "Iteration 104, loss = 0.14824874\n",
            "Iteration 105, loss = 0.14742960\n",
            "Iteration 106, loss = 0.14452012\n",
            "Iteration 107, loss = 0.14947363\n",
            "Iteration 108, loss = 0.14322124\n",
            "Iteration 109, loss = 0.14478542\n",
            "Iteration 110, loss = 0.14181720\n",
            "Iteration 111, loss = 0.14135020\n",
            "Iteration 112, loss = 0.14072554\n",
            "Iteration 113, loss = 0.13985860\n",
            "Iteration 114, loss = 0.13897508\n",
            "Iteration 115, loss = 0.13912146\n",
            "Iteration 116, loss = 0.13914079\n",
            "Iteration 117, loss = 0.13889620\n",
            "Iteration 118, loss = 0.13568594\n",
            "Iteration 119, loss = 0.13788100\n",
            "Iteration 120, loss = 0.13676511\n",
            "Iteration 121, loss = 0.13544847\n",
            "Iteration 122, loss = 0.13301428\n",
            "Iteration 123, loss = 0.13581044\n",
            "Iteration 124, loss = 0.13166328\n",
            "Iteration 125, loss = 0.13556177\n",
            "Iteration 126, loss = 0.13061816\n",
            "Iteration 127, loss = 0.12774804\n",
            "Iteration 128, loss = 0.13414609\n",
            "Iteration 129, loss = 0.12788896\n",
            "Iteration 130, loss = 0.12703824\n",
            "Iteration 131, loss = 0.12845110\n",
            "Iteration 132, loss = 0.12680860\n",
            "Iteration 133, loss = 0.12745193\n",
            "Iteration 134, loss = 0.12698741\n",
            "Iteration 135, loss = 0.12842388\n",
            "Iteration 136, loss = 0.12634677\n",
            "Iteration 137, loss = 0.12352253\n",
            "Iteration 138, loss = 0.12330926\n",
            "Iteration 139, loss = 0.12610248\n",
            "Iteration 140, loss = 0.12203222\n",
            "Iteration 141, loss = 0.12216357\n",
            "Iteration 142, loss = 0.11924790\n",
            "Iteration 143, loss = 0.11957397\n",
            "Iteration 144, loss = 0.12033362\n",
            "Iteration 145, loss = 0.11740384\n",
            "Iteration 146, loss = 0.11871911\n",
            "Iteration 147, loss = 0.11659951\n",
            "Iteration 148, loss = 0.12022110\n",
            "Iteration 149, loss = 0.11646908\n",
            "Iteration 150, loss = 0.11516562\n",
            "Iteration 151, loss = 0.11565456\n",
            "Iteration 152, loss = 0.11418154\n",
            "Iteration 153, loss = 0.11264107\n",
            "Iteration 154, loss = 0.11497207\n",
            "Iteration 155, loss = 0.11319484\n",
            "Iteration 156, loss = 0.11410818\n",
            "Iteration 157, loss = 0.11406045\n",
            "Iteration 158, loss = 0.10999054\n",
            "Iteration 159, loss = 0.11248917\n",
            "Iteration 160, loss = 0.11442108\n",
            "Iteration 161, loss = 0.11135488\n",
            "Iteration 162, loss = 0.11127527\n",
            "Iteration 163, loss = 0.10752335\n",
            "Iteration 164, loss = 0.10901415\n",
            "Iteration 165, loss = 0.10863796\n",
            "Iteration 166, loss = 0.10790327\n",
            "Iteration 167, loss = 0.10961160\n",
            "Iteration 168, loss = 0.10851879\n",
            "Iteration 169, loss = 0.10602720\n",
            "Iteration 170, loss = 0.10630070\n",
            "Iteration 171, loss = 0.10501613\n",
            "Iteration 172, loss = 0.10583980\n",
            "Iteration 173, loss = 0.10541182\n",
            "Iteration 174, loss = 0.10096666\n",
            "Iteration 175, loss = 0.10404634\n",
            "Iteration 176, loss = 0.10221237\n",
            "Iteration 177, loss = 0.10075696\n",
            "Iteration 178, loss = 0.09931985\n",
            "Iteration 179, loss = 0.10203152\n",
            "Iteration 180, loss = 0.10096311\n",
            "Iteration 181, loss = 0.09975398\n",
            "Iteration 182, loss = 0.09955987\n",
            "Iteration 183, loss = 0.09993594\n",
            "Iteration 184, loss = 0.09770182\n",
            "Iteration 185, loss = 0.09802935\n",
            "Iteration 186, loss = 0.09803881\n",
            "Iteration 187, loss = 0.09618500\n",
            "Iteration 188, loss = 0.09616072\n",
            "Iteration 189, loss = 0.09800732\n",
            "Iteration 190, loss = 0.09534339\n",
            "Iteration 191, loss = 0.09352430\n",
            "Iteration 192, loss = 0.09372701\n",
            "Iteration 193, loss = 0.09739990\n",
            "Iteration 194, loss = 0.09370456\n",
            "Iteration 195, loss = 0.09311714\n",
            "Iteration 196, loss = 0.09235983\n",
            "Iteration 197, loss = 0.09294382\n",
            "Iteration 198, loss = 0.09261564\n",
            "Iteration 199, loss = 0.09151696\n",
            "Iteration 200, loss = 0.09206768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(90,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "8m9_X9bUdZJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "# train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fo_lFxdIc85n",
        "colab_type": "code",
        "outputId": "c913201f-928a-4fea-a1de-4cdb2ee332ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "# clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "#                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "### acc is 98.41\n",
        "clf2 = MLPClassifier(hidden_layer_sizes=(90, ), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "\n",
        "# Test set score: 0.950119\n",
        "\n",
        "clf2.fit(train_valid_combined, train_valid_label)\n",
        "# clf2.fit(train_data, train_label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.82634238\n",
            "Iteration 2, loss = 0.41373569\n",
            "Iteration 3, loss = 0.37605369\n",
            "Iteration 4, loss = 0.35571391\n",
            "Iteration 5, loss = 0.34263036\n",
            "Iteration 6, loss = 0.33011321\n",
            "Iteration 7, loss = 0.32304803\n",
            "Iteration 8, loss = 0.31196381\n",
            "Iteration 9, loss = 0.30402870\n",
            "Iteration 10, loss = 0.29827007\n",
            "Iteration 11, loss = 0.28948546\n",
            "Iteration 12, loss = 0.28612687\n",
            "Iteration 13, loss = 0.27932343\n",
            "Iteration 14, loss = 0.27619162\n",
            "Iteration 15, loss = 0.27067846\n",
            "Iteration 16, loss = 0.26685167\n",
            "Iteration 17, loss = 0.26476077\n",
            "Iteration 18, loss = 0.26116681\n",
            "Iteration 19, loss = 0.25827607\n",
            "Iteration 20, loss = 0.25558723\n",
            "Iteration 21, loss = 0.25277891\n",
            "Iteration 22, loss = 0.24954713\n",
            "Iteration 23, loss = 0.24710936\n",
            "Iteration 24, loss = 0.24911412\n",
            "Iteration 25, loss = 0.24259238\n",
            "Iteration 26, loss = 0.24047983\n",
            "Iteration 27, loss = 0.23850629\n",
            "Iteration 28, loss = 0.23516517\n",
            "Iteration 29, loss = 0.23435265\n",
            "Iteration 30, loss = 0.23254712\n",
            "Iteration 31, loss = 0.23163801\n",
            "Iteration 32, loss = 0.22906617\n",
            "Iteration 33, loss = 0.22580472\n",
            "Iteration 34, loss = 0.22265630\n",
            "Iteration 35, loss = 0.22342602\n",
            "Iteration 36, loss = 0.22277728\n",
            "Iteration 37, loss = 0.21981775\n",
            "Iteration 38, loss = 0.21871942\n",
            "Iteration 39, loss = 0.21849579\n",
            "Iteration 40, loss = 0.21897141\n",
            "Iteration 41, loss = 0.21492731\n",
            "Iteration 42, loss = 0.21896888\n",
            "Iteration 43, loss = 0.21554859\n",
            "Iteration 44, loss = 0.21061509\n",
            "Iteration 45, loss = 0.20803572\n",
            "Iteration 46, loss = 0.21019711\n",
            "Iteration 47, loss = 0.21155291\n",
            "Iteration 48, loss = 0.20390460\n",
            "Iteration 49, loss = 0.20457895\n",
            "Iteration 50, loss = 0.20148154\n",
            "Iteration 51, loss = 0.20170466\n",
            "Iteration 52, loss = 0.20018665\n",
            "Iteration 53, loss = 0.20125723\n",
            "Iteration 54, loss = 0.19698586\n",
            "Iteration 55, loss = 0.19478336\n",
            "Iteration 56, loss = 0.19409930\n",
            "Iteration 57, loss = 0.19786545\n",
            "Iteration 58, loss = 0.19667586\n",
            "Iteration 59, loss = 0.19213791\n",
            "Iteration 60, loss = 0.19191822\n",
            "Iteration 61, loss = 0.19433809\n",
            "Iteration 62, loss = 0.18982952\n",
            "Iteration 63, loss = 0.18792718\n",
            "Iteration 64, loss = 0.18654077\n",
            "Iteration 65, loss = 0.18773692\n",
            "Iteration 66, loss = 0.18286938\n",
            "Iteration 67, loss = 0.18427653\n",
            "Iteration 68, loss = 0.18262255\n",
            "Iteration 69, loss = 0.17980965\n",
            "Iteration 70, loss = 0.17712315\n",
            "Iteration 71, loss = 0.17877538\n",
            "Iteration 72, loss = 0.17685662\n",
            "Iteration 73, loss = 0.18036686\n",
            "Iteration 74, loss = 0.18272290\n",
            "Iteration 75, loss = 0.17592057\n",
            "Iteration 76, loss = 0.17336084\n",
            "Iteration 77, loss = 0.17853535\n",
            "Iteration 78, loss = 0.17254716\n",
            "Iteration 79, loss = 0.17403643\n",
            "Iteration 80, loss = 0.16933701\n",
            "Iteration 81, loss = 0.17064029\n",
            "Iteration 82, loss = 0.17065341\n",
            "Iteration 83, loss = 0.16888742\n",
            "Iteration 84, loss = 0.16870911\n",
            "Iteration 85, loss = 0.16729551\n",
            "Iteration 86, loss = 0.16172111\n",
            "Iteration 87, loss = 0.16400710\n",
            "Iteration 88, loss = 0.16454690\n",
            "Iteration 89, loss = 0.16217496\n",
            "Iteration 90, loss = 0.16331493\n",
            "Iteration 91, loss = 0.16606537\n",
            "Iteration 92, loss = 0.16032764\n",
            "Iteration 93, loss = 0.16022860\n",
            "Iteration 94, loss = 0.16171106\n",
            "Iteration 95, loss = 0.15858685\n",
            "Iteration 96, loss = 0.15777336\n",
            "Iteration 97, loss = 0.15502751\n",
            "Iteration 98, loss = 0.15510696\n",
            "Iteration 99, loss = 0.15301141\n",
            "Iteration 100, loss = 0.15125909\n",
            "Iteration 101, loss = 0.15462113\n",
            "Iteration 102, loss = 0.15567224\n",
            "Iteration 103, loss = 0.15214800\n",
            "Iteration 104, loss = 0.15154664\n",
            "Iteration 105, loss = 0.15108969\n",
            "Iteration 106, loss = 0.14845555\n",
            "Iteration 107, loss = 0.14992475\n",
            "Iteration 108, loss = 0.14694244\n",
            "Iteration 109, loss = 0.14533156\n",
            "Iteration 110, loss = 0.14954038\n",
            "Iteration 111, loss = 0.14540026\n",
            "Iteration 112, loss = 0.14305388\n",
            "Iteration 113, loss = 0.14429560\n",
            "Iteration 114, loss = 0.14429765\n",
            "Iteration 115, loss = 0.14264543\n",
            "Iteration 116, loss = 0.14533264\n",
            "Iteration 117, loss = 0.14138862\n",
            "Iteration 118, loss = 0.13762571\n",
            "Iteration 119, loss = 0.13928244\n",
            "Iteration 120, loss = 0.13940020\n",
            "Iteration 121, loss = 0.13613364\n",
            "Iteration 122, loss = 0.13412158\n",
            "Iteration 123, loss = 0.13675635\n",
            "Iteration 124, loss = 0.13664594\n",
            "Iteration 125, loss = 0.13707532\n",
            "Iteration 126, loss = 0.13291167\n",
            "Iteration 127, loss = 0.13523410\n",
            "Iteration 128, loss = 0.13531406\n",
            "Iteration 129, loss = 0.13116114\n",
            "Iteration 130, loss = 0.12877429\n",
            "Iteration 131, loss = 0.12806132\n",
            "Iteration 132, loss = 0.12830673\n",
            "Iteration 133, loss = 0.12758487\n",
            "Iteration 134, loss = 0.12852522\n",
            "Iteration 135, loss = 0.12691419\n",
            "Iteration 136, loss = 0.12538173\n",
            "Iteration 137, loss = 0.12675194\n",
            "Iteration 138, loss = 0.12573433\n",
            "Iteration 139, loss = 0.12409021\n",
            "Iteration 140, loss = 0.12797801\n",
            "Iteration 141, loss = 0.12397559\n",
            "Iteration 142, loss = 0.12412356\n",
            "Iteration 143, loss = 0.12369043\n",
            "Iteration 144, loss = 0.12303290\n",
            "Iteration 145, loss = 0.12074717\n",
            "Iteration 146, loss = 0.11912411\n",
            "Iteration 147, loss = 0.11811292\n",
            "Iteration 148, loss = 0.11721474\n",
            "Iteration 149, loss = 0.12084641\n",
            "Iteration 150, loss = 0.11654213\n",
            "Iteration 151, loss = 0.11707185\n",
            "Iteration 152, loss = 0.11703879\n",
            "Iteration 153, loss = 0.11883907\n",
            "Iteration 154, loss = 0.11671177\n",
            "Iteration 155, loss = 0.11480477\n",
            "Iteration 156, loss = 0.11389872\n",
            "Iteration 157, loss = 0.11175690\n",
            "Iteration 158, loss = 0.11128733\n",
            "Iteration 159, loss = 0.11249148\n",
            "Iteration 160, loss = 0.10991955\n",
            "Iteration 161, loss = 0.11039066\n",
            "Iteration 162, loss = 0.10958861\n",
            "Iteration 163, loss = 0.11255658\n",
            "Iteration 164, loss = 0.11010505\n",
            "Iteration 165, loss = 0.11036995\n",
            "Iteration 166, loss = 0.10557753\n",
            "Iteration 167, loss = 0.10612640\n",
            "Iteration 168, loss = 0.10530010\n",
            "Iteration 169, loss = 0.11082845\n",
            "Iteration 170, loss = 0.10657805\n",
            "Iteration 171, loss = 0.10281291\n",
            "Iteration 172, loss = 0.10304390\n",
            "Iteration 173, loss = 0.10285818\n",
            "Iteration 174, loss = 0.11195976\n",
            "Iteration 175, loss = 0.10504590\n",
            "Iteration 176, loss = 0.10486552\n",
            "Iteration 177, loss = 0.10005840\n",
            "Iteration 178, loss = 0.09969148\n",
            "Iteration 179, loss = 0.09826476\n",
            "Iteration 180, loss = 0.09942677\n",
            "Iteration 181, loss = 0.10357958\n",
            "Iteration 182, loss = 0.10117345\n",
            "Iteration 183, loss = 0.10483996\n",
            "Iteration 184, loss = 0.09848744\n",
            "Iteration 185, loss = 0.10142734\n",
            "Iteration 186, loss = 0.09627610\n",
            "Iteration 187, loss = 0.09996445\n",
            "Iteration 188, loss = 0.09457861\n",
            "Iteration 189, loss = 0.09374801\n",
            "Iteration 190, loss = 0.09655249\n",
            "Iteration 191, loss = 0.09305067\n",
            "Iteration 192, loss = 0.09156758\n",
            "Iteration 193, loss = 0.09259070\n",
            "Iteration 194, loss = 0.09178192\n",
            "Iteration 195, loss = 0.09244169\n",
            "Iteration 196, loss = 0.08960696\n",
            "Iteration 197, loss = 0.09183802\n",
            "Iteration 198, loss = 0.09144301\n",
            "Iteration 199, loss = 0.09533629\n",
            "Iteration 200, loss = 0.08970769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(90,), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Wi_0y1C6e9Er",
        "colab_type": "code",
        "outputId": "357dc11f-cb42-4c49-ec16-4c8caee2d326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4435, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "oy5MNJqFys-H",
        "colab_type": "code",
        "outputId": "f4f3b1c7-e5cb-46fe-a842-5ab9aa6a5668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9710051546391752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "T0aiYNsdyuBR",
        "colab_type": "code",
        "outputId": "b368778a-e73e-45d0-8b2f-3890c22264ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8858001502629602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "w7DSKjQcyvL0",
        "colab_type": "code",
        "outputId": "880c17c3-86ef-465d-872e-f07f138b6fa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "bOJLm3y6dkCs",
        "colab_type": "code",
        "outputId": "1e0bbea1-55f7-478a-93ca-68f62db08bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(train_data,train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9771262886597938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "hnUFUI4rdjwi",
        "colab_type": "code",
        "outputId": "50b96df0-b58e-4376-adad-af9e6be248a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(validation_data,validation_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9616829451540195"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "1u7u5mLsirGr",
        "colab_type": "code",
        "outputId": "05fed44e-945a-4597-d9f1-4d98c86f5f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "BtNN_G2Bdkpr",
        "colab_type": "code",
        "outputId": "3a68f571-f661-40d2-8b67-f23170a9106c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(test_data,test_label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "63SIF9YCiJ9X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9T8IoNGpkVv_",
        "colab_type": "code",
        "outputId": "5ea00043-47a1-4793-8e16-fafbf7462a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "kxWBf1tjiJm4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DYHOkr0CiOxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eDauxfwliQZb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "\n",
        "\n",
        "# saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GlClhIpViZoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "metadata": {
        "id": "NhtjHgUwl0Kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vLrSUA61iQW_",
        "colab_type": "code",
        "outputId": "9aeec275-e0e3-49e1-a100-17f88a40baf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(train_label_one_hot,axis = 1))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([781.,   0., 384.,   0., 798.,   0., 306.,   0., 294., 541.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XfNKrbvrmDl6",
        "colab_type": "code",
        "outputId": "35acf8ee-8f38-4f41-d396-299b6aeb89fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(np.argmax(validation_label_one_hot,axis = 1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([291.,   0.,  95.,   0., 163.,   0., 109.,   0., 176., 497.]),\n",
              " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fX0eodcgiQTr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYJZs7GgCy5p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle  #train_data, train_label\n",
        "\n",
        "X_train, y_train = shuffle(train_data, train_label_one_hot)\n",
        "validation_data, validation_label_one_hot = validation_data, validation_label_one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4WFIdiuCy53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup TensorFlow\n",
        "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "est-t83SCy55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vgad6Ny0OjqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "41fc6957-a0b4-4553-c0f4-45d2cb68babf"
      },
      "cell_type": "code",
      "source": [
        "connection_probability = tf.Variable(1.)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ZqUctyopqzZ",
        "colab_type": "code",
        "outputId": "7eb43905-fcc9-4699-a885-f944142507ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "# print(G_W1.shape)\n",
        "# print(G_W2.shape)\n",
        "# print(G_W3.shape)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3104, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UYVUi6tIf1mG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# len(clf.coefs_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w6aNutv83RcA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define the network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "stGmwMYz8vws",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "# xavier_init([clf.coefs_[1].shape[1]])\n",
        "# G_W1 = tf.Variable(xavier_init([clf.coefs_[0].shape[0], clf.coefs_[0].shape[1]]))\n",
        "# G_b1 = tf.Variable(xavier_init([clf.intercepts_ [0].shape[0]]))\n",
        "\n",
        "# G_W2 =  tf.Variable(xavier_init([clf.coefs_[1].shape[0], clf.coefs_[1].shape[1]]))\n",
        "# G_b2 = tf.Variable(xavier_init([clf.intercepts_ [1].shape[0]]))\n",
        "\n",
        "# G_W3 =  tf.Variable(np.float32(clf.coefs_[2]))\n",
        "# G_b3 = tf.Variable(np.float32(clf.intercepts_ [2]))\n",
        "\n",
        "# G_w_out_h1 = tf.Variable(xavier_init([10,80]))\n",
        "# G_b_out_h1 = tf.Variable(xavier_init([80]))\n",
        "\n",
        "# G_w_h2_h1 = tf.Variable(xavier_init([40,80]))\n",
        "# G_b_h2_h1 = tf.Variable(xavier_init([80]))\n",
        "\n",
        "\n",
        "# G_w_h1_input = tf.Variable(xavier_init([80,16]))\n",
        "# G_b_h1_input = tf.Variable(xavier_init([16]))\n",
        "\n",
        "\n",
        "# G_w_input_h1_h2 = tf.Variable(xavier_init([16,40]))\n",
        "# G_b_h1_input = tf.Variable(xavier_init([40]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2bajK44GmiR1",
        "colab_type": "code",
        "outputId": "6d529352-0474-471e-c164-1ae9a628e2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "hncjRrBbmRDY",
        "colab_type": "code",
        "outputId": "6725f04d-46ea-4086-a7de-f638669aed3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.coefs_[0].shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 90)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "-sfSdtHU3JfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.layers import flatten\n",
        "\n",
        "def LeNet(x, test_mode = False):    \n",
        "    # Hyperparameters\n",
        "    mu = 0\n",
        "    sigma = 0.1\n",
        "    layer_depth = {\n",
        "        'layer_1' : 6,\n",
        "        'layer_2' : 16,\n",
        "        'layer_3' : 120,\n",
        "        'layer_f1' : 84\n",
        "    }\n",
        "\n",
        "\n",
        "    \n",
        "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
        "    x_flat = flatten(x)\n",
        "    fc1 = flatten(x)\n",
        "    fdense = fc1\n",
        "    \n",
        "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
        "    fc1_w = G_W1# tf.Variable(tf.truncated_normal(shape = (X_train.shape[1]*X_train.shape[2],300), mean = mu, stddev = sigma))\n",
        "    fc1_b = G_b1# tf.Variable(tf.zeros(300))\n",
        "    fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
        "    \n",
        "    # TODO: Activation.\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "\n",
        "#     # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
        "#     fc2_w = G_W2# tf.Variable(tf.truncated_normal(shape = (300,100), mean = mu, stddev = sigma))\n",
        "#     fc2_b = G_b2# tf.Variable(tf.zeros(100))\n",
        "#     fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
        "#     # TODO: Activation.\n",
        "#     fc2 = tf.nn.relu(fc2)\n",
        "    fc3_w = G_W2\n",
        "    fc3_b = G_b2\n",
        "    \n",
        "    logits = tf.matmul(fc1, fc3_w) + fc3_b\n",
        "    \n",
        "    #################\n",
        "    ##### Inset probability connection from x to conv2\n",
        "    fc2p_w = tf.Variable(xavier_init([X_train.shape[1],clf.coefs_[1].shape[1]]))\n",
        "    fc2p_b = tf.Variable(xavier_init([clf.coefs_[1].shape[1]]))\n",
        "    fc2_2nd_input = tf.matmul(x_flat,fc2p_w) + fc2p_b\n",
        "#     fc2_2nd_input = tf.nn.relu(fc2_2nd_input)\n",
        "    connect2 = tf.logical_and(tf.random.uniform(shape = tf.shape(connection_probability)) < connection_probability, tf.equal(test_mode,False))\n",
        "    logits = tf.cond(connect2,lambda: logits + fc2_2nd_input, lambda: logits )    \n",
        "    ################    \n",
        "#     fc3_w = G_W3\n",
        "#     fc3_b = G_b3\n",
        "    \n",
        "#     logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
        "#     print(logits.shape)\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AGmN34tg3_tv",
        "colab_type": "code",
        "outputId": "5d4ba64f-ce52-41dc-85e0-86dd857e3b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_label_one_hot.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "-NX_lWUB6zue",
        "colab_type": "code",
        "outputId": "3a850ce7-8fd1-4b89-831a-f1848f24f356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_label"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, ..., 2, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "M3U_MKYr34Xp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with tf.name_scope('Input'):\n",
        "\n",
        "  x = tf.placeholder(tf.float32, (None, train_data.shape[1]), name='X')\n",
        "  y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "# one_hot_y = tf.one_hot(y, train_label_one_hot.shape[1])\n",
        "is_testing= tf.placeholder(tf.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rtTKpeM4P8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-e6BG9DI3Jb3",
        "colab_type": "code",
        "outputId": "e576b8fb-31ac-4573-d7d7-55b710044ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "rate = 0.001\n",
        "decay_rate = 1.0005**(X_train.shape[0]/BATCH_SIZE);\n",
        "decay_rate =1.3\n",
        "print(decay_rate)\n",
        "logits = LeNet(x,is_testing)\n",
        "with tf.name_scope('Train'):\n",
        "#   cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
        "#   loss_operation = tf.reduce_mean(cross_entropy, name='loss')\n",
        "  loss_operation = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=LeNet(x, test_mode=False), labels=y))\n",
        "  tf.summary.scalar('loss', loss_operation)\n",
        "# optimizer = tf.train.MomentumOptimizer(learning_rate = rate,momentum=.9)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "# tf.train.natural_exp_decay()\n",
        "training_operation = optimizer.minimize(loss_operation)\n",
        "new_prob = connection_probability.assign(connection_probability/decay_rate)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-35-31c5d4ed37f0>:9: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8eQKHOw7PHm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def evaluate(X_data, y_data):\n",
        "correct_pred = tf.equal(tf.argmax(LeNet(x,test_mode=True), 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tb-sFE34OGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
        "# accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# saver = tf.train.Saver()\n",
        "\n",
        "# def evaluate(X_data, y_data):\n",
        "#     num_examples = len(X_data)\n",
        "#     total_accuracy = 0\n",
        "#     sess = tf.get_default_session()\n",
        "#     for offset in range(0, num_examples, BATCH_SIZE):\n",
        "#         batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "#         accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, is_testing: True})\n",
        "#         total_accuracy += (accuracy * len(batch_x))\n",
        "#     tot_acc = total_accuracy / num_examples\n",
        "#     with tf.name_scope('Accuracy'):\n",
        "#       tf.summary.scalar('accuracy', tot_acc)\n",
        "#     return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yCovfr0E4oJq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the mode"
      ]
    },
    {
      "metadata": {
        "id": "NGF2PRgw9nLL",
        "colab_type": "code",
        "outputId": "c1771cd3-6dfc-4352-c19f-df62ac52e012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "2056*2"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "6Cl89uCj9hjc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 2056"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4H5Dgkf69TOx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nk5Kihg685LI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZQaEeNO285BK",
        "colab_type": "code",
        "outputId": "00170343-2025-4533-b641-a1537d557479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3104, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "2kUXlIo82NoY",
        "colab_type": "code",
        "outputId": "db551de0-01f6-4bef-d34d-e6395791d58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1331, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "4VP4QWKJ4ODG",
        "colab_type": "code",
        "outputId": "41b742d0-2e5b-4db9-c8a4-dcaad7d10a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 42585
        }
      },
      "cell_type": "code",
      "source": [
        "print(decay_rate)\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = X_train.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "epoch_track = []\n",
        "print_every = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "#     saver.restore(sess, './DNAAdamBased')\n",
        "    num_examples = len(X_train)\n",
        "    best_accuracy_valid = 0\n",
        "    print(\"Training...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        X_train, y_train = shuffle(X_train, y_train)\n",
        "        for step in range(0, total_steps_for_one_pass):        \n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "#             print(step,'Finishing',step*BATCH_SIZE )\n",
        "            step = 0\n",
        "\n",
        "          else:\n",
        "\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "#             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "#           print(batch_y.shape)\n",
        "          tr_op  = sess.run([training_operation], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "#           train_writer.add_summary(summary_tr, i)\n",
        "        prob = sess.run(new_prob)\n",
        "        if i%print_every == 0:\n",
        "          tr_accuracy = sess.run(accuracy*100, feed_dict={x: X_train,y:y_train, is_testing: True})  # evaluate(X_train, y_train)\n",
        "          print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True}) #evaluate(X_validation, y_validation)\n",
        "          validation_accuracy_track.append(validation_accuracy)\n",
        "          train_accuracy_track.append(tr_accuracy)\n",
        "          epoch_track.append(i)\n",
        "          connection_probability_track.append(prob)\n",
        "          print(\"EPOCH {} ...\".format(i+1))\n",
        "          print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "          print(prob)\n",
        "          print()\n",
        "          if (validation_accuracy >= best_accuracy_valid):\n",
        "            best_accuracy_valid = validation_accuracy\n",
        "            saver.save(sess, './DNAAdamBased')\n",
        "        \n",
        "#     saver.save(sess, './lenet')\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 96.52062\n",
            "EPOCH 1 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.7692308\n",
            "\n",
            "Train Accuracy = 97.00387\n",
            "EPOCH 11 ...\n",
            "Validation Accuracy = 87.82870\n",
            "0.055798586\n",
            "\n",
            "Train Accuracy = 97.16495\n",
            "EPOCH 21 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.004047527\n",
            "\n",
            "Train Accuracy = 97.32603\n",
            "EPOCH 31 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0002936002\n",
            "\n",
            "Train Accuracy = 97.42268\n",
            "EPOCH 41 ...\n",
            "Validation Accuracy = 88.80540\n",
            "2.1297219e-05\n",
            "\n",
            "Train Accuracy = 97.29382\n",
            "EPOCH 51 ...\n",
            "Validation Accuracy = 88.73028\n",
            "1.5448612e-06\n",
            "\n",
            "Train Accuracy = 97.42268\n",
            "EPOCH 61 ...\n",
            "Validation Accuracy = 88.80540\n",
            "1.120614e-07\n",
            "\n",
            "Train Accuracy = 97.35825\n",
            "EPOCH 71 ...\n",
            "Validation Accuracy = 88.80540\n",
            "8.128727e-09\n",
            "\n",
            "Train Accuracy = 97.42268\n",
            "EPOCH 81 ...\n",
            "Validation Accuracy = 88.73028\n",
            "5.8964295e-10\n",
            "\n",
            "Train Accuracy = 97.48711\n",
            "EPOCH 91 ...\n",
            "Validation Accuracy = 88.73028\n",
            "4.2771616e-11\n",
            "\n",
            "Train Accuracy = 97.45490\n",
            "EPOCH 101 ...\n",
            "Validation Accuracy = 88.80540\n",
            "3.1025744e-12\n",
            "\n",
            "Train Accuracy = 97.51933\n",
            "EPOCH 111 ...\n",
            "Validation Accuracy = 88.73028\n",
            "2.2505507e-13\n",
            "\n",
            "Train Accuracy = 97.55155\n",
            "EPOCH 121 ...\n",
            "Validation Accuracy = 88.73028\n",
            "1.6325083e-14\n",
            "\n",
            "Train Accuracy = 97.58376\n",
            "EPOCH 131 ...\n",
            "Validation Accuracy = 88.73028\n",
            "1.1841916e-15\n",
            "\n",
            "Train Accuracy = 97.64820\n",
            "EPOCH 141 ...\n",
            "Validation Accuracy = 88.80540\n",
            "8.589908e-17\n",
            "\n",
            "Train Accuracy = 97.64820\n",
            "EPOCH 151 ...\n",
            "Validation Accuracy = 88.65514\n",
            "6.230962e-18\n",
            "\n",
            "Train Accuracy = 97.68041\n",
            "EPOCH 161 ...\n",
            "Validation Accuracy = 88.65514\n",
            "4.519825e-19\n",
            "\n",
            "Train Accuracy = 97.68041\n",
            "EPOCH 171 ...\n",
            "Validation Accuracy = 88.65514\n",
            "3.278598e-20\n",
            "\n",
            "Train Accuracy = 97.74484\n",
            "EPOCH 181 ...\n",
            "Validation Accuracy = 88.65514\n",
            "2.378235e-21\n",
            "\n",
            "Train Accuracy = 97.77706\n",
            "EPOCH 191 ...\n",
            "Validation Accuracy = 88.65514\n",
            "1.7251281e-22\n",
            "\n",
            "Train Accuracy = 97.71263\n",
            "EPOCH 201 ...\n",
            "Validation Accuracy = 88.65514\n",
            "1.2513764e-23\n",
            "\n",
            "Train Accuracy = 97.77706\n",
            "EPOCH 211 ...\n",
            "Validation Accuracy = 88.58001\n",
            "9.077255e-25\n",
            "\n",
            "Train Accuracy = 97.77706\n",
            "EPOCH 221 ...\n",
            "Validation Accuracy = 88.80540\n",
            "6.584474e-26\n",
            "\n",
            "Train Accuracy = 97.84149\n",
            "EPOCH 231 ...\n",
            "Validation Accuracy = 88.65514\n",
            "4.7762573e-27\n",
            "\n",
            "Train Accuracy = 97.80928\n",
            "EPOCH 241 ...\n",
            "Validation Accuracy = 88.73028\n",
            "3.4646095e-28\n",
            "\n",
            "Train Accuracy = 97.93814\n",
            "EPOCH 251 ...\n",
            "Validation Accuracy = 88.80540\n",
            "2.513164e-29\n",
            "\n",
            "Train Accuracy = 97.97036\n",
            "EPOCH 261 ...\n",
            "Validation Accuracy = 88.58001\n",
            "1.8230031e-30\n",
            "\n",
            "Train Accuracy = 97.90593\n",
            "EPOCH 271 ...\n",
            "Validation Accuracy = 88.73028\n",
            "1.3223731e-31\n",
            "\n",
            "Train Accuracy = 97.97036\n",
            "EPOCH 281 ...\n",
            "Validation Accuracy = 88.65514\n",
            "9.5922514e-33\n",
            "\n",
            "Train Accuracy = 98.00258\n",
            "EPOCH 291 ...\n",
            "Validation Accuracy = 88.65514\n",
            "6.9580436e-34\n",
            "\n",
            "Train Accuracy = 98.03479\n",
            "EPOCH 301 ...\n",
            "Validation Accuracy = 88.58001\n",
            "5.047237e-35\n",
            "\n",
            "Train Accuracy = 98.06701\n",
            "EPOCH 311 ...\n",
            "Validation Accuracy = 88.73028\n",
            "3.6611724e-36\n",
            "\n",
            "Train Accuracy = 98.03479\n",
            "EPOCH 321 ...\n",
            "Validation Accuracy = 88.50488\n",
            "2.6557474e-37\n",
            "\n",
            "Train Accuracy = 98.13144\n",
            "EPOCH 331 ...\n",
            "Validation Accuracy = 88.65514\n",
            "1.9264303e-38\n",
            "\n",
            "Train Accuracy = 98.09923\n",
            "EPOCH 341 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.16366\n",
            "EPOCH 351 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.19588\n",
            "EPOCH 361 ...\n",
            "Validation Accuracy = 88.42976\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.22809\n",
            "EPOCH 371 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.29253\n",
            "EPOCH 381 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.22809\n",
            "EPOCH 391 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.29253\n",
            "EPOCH 401 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.35696\n",
            "EPOCH 411 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.29253\n",
            "EPOCH 421 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.32474\n",
            "EPOCH 431 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.32474\n",
            "EPOCH 441 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.29253\n",
            "EPOCH 451 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.35696\n",
            "EPOCH 461 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.38918\n",
            "EPOCH 471 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42139\n",
            "EPOCH 481 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.38918\n",
            "EPOCH 491 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.35696\n",
            "EPOCH 501 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42139\n",
            "EPOCH 511 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.45361\n",
            "EPOCH 521 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.45361\n",
            "EPOCH 531 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.48582\n",
            "EPOCH 541 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.48582\n",
            "EPOCH 551 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.51804\n",
            "EPOCH 561 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.51804\n",
            "EPOCH 571 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.51804\n",
            "EPOCH 581 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.51804\n",
            "EPOCH 591 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.58247\n",
            "EPOCH 601 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.55026\n",
            "EPOCH 611 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.61469\n",
            "EPOCH 621 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.64691\n",
            "EPOCH 631 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.58247\n",
            "EPOCH 641 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.64691\n",
            "EPOCH 651 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.64691\n",
            "EPOCH 661 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.67912\n",
            "EPOCH 671 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.67912\n",
            "EPOCH 681 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.74356\n",
            "EPOCH 691 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.77577\n",
            "EPOCH 701 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.77577\n",
            "EPOCH 711 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.77577\n",
            "EPOCH 721 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.84021\n",
            "EPOCH 731 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.90464\n",
            "EPOCH 741 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.84021\n",
            "EPOCH 751 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.87242\n",
            "EPOCH 761 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.90464\n",
            "EPOCH 771 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.84021\n",
            "EPOCH 781 ...\n",
            "Validation Accuracy = 89.48159\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.87242\n",
            "EPOCH 791 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96907\n",
            "EPOCH 801 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.93686\n",
            "EPOCH 811 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96907\n",
            "EPOCH 821 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96907\n",
            "EPOCH 831 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09794\n",
            "EPOCH 841 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03351\n",
            "EPOCH 851 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96907\n",
            "EPOCH 861 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.00129\n",
            "EPOCH 871 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03351\n",
            "EPOCH 881 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16237\n",
            "EPOCH 891 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.00129\n",
            "EPOCH 901 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16237\n",
            "EPOCH 911 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25902\n",
            "EPOCH 921 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09794\n",
            "EPOCH 931 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25902\n",
            "EPOCH 941 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.22680\n",
            "EPOCH 951 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25902\n",
            "EPOCH 961 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25902\n",
            "EPOCH 971 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.32345\n",
            "EPOCH 981 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29124\n",
            "EPOCH 991 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.32345\n",
            "EPOCH 1001 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29124\n",
            "EPOCH 1011 ...\n",
            "Validation Accuracy = 89.48159\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.32345\n",
            "EPOCH 1021 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.35567\n",
            "EPOCH 1031 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.32345\n",
            "EPOCH 1041 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.32345\n",
            "EPOCH 1051 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.35567\n",
            "EPOCH 1061 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.35567\n",
            "EPOCH 1071 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.35567\n",
            "EPOCH 1081 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38789\n",
            "EPOCH 1091 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.42010\n",
            "EPOCH 1101 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.45232\n",
            "EPOCH 1111 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48454\n",
            "EPOCH 1121 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48454\n",
            "EPOCH 1131 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.42010\n",
            "EPOCH 1141 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48454\n",
            "EPOCH 1151 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48454\n",
            "EPOCH 1161 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.45232\n",
            "EPOCH 1171 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48454\n",
            "EPOCH 1181 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.51675\n",
            "EPOCH 1191 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.54897\n",
            "EPOCH 1201 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.42010\n",
            "EPOCH 1211 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.51675\n",
            "EPOCH 1221 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48454\n",
            "EPOCH 1231 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.51675\n",
            "EPOCH 1241 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.51675\n",
            "EPOCH 1251 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.54897\n",
            "EPOCH 1261 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.61340\n",
            "EPOCH 1271 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.58118\n",
            "EPOCH 1281 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.54897\n",
            "EPOCH 1291 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.61340\n",
            "EPOCH 1301 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1311 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1321 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.58118\n",
            "EPOCH 1331 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1341 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1351 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1361 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.58118\n",
            "EPOCH 1371 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1381 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1391 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.67783\n",
            "EPOCH 1401 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.67783\n",
            "EPOCH 1411 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1421 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.64562\n",
            "EPOCH 1431 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1441 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.67783\n",
            "EPOCH 1451 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.67783\n",
            "EPOCH 1461 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1471 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.74227\n",
            "EPOCH 1481 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1491 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1501 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1511 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1521 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1531 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.77448\n",
            "EPOCH 1541 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1551 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1561 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1571 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.71005\n",
            "EPOCH 1581 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1591 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1601 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.77448\n",
            "EPOCH 1611 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.77448\n",
            "EPOCH 1621 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1631 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1641 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1651 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1661 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1671 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1681 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1691 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1701 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1711 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1721 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1731 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.80670\n",
            "EPOCH 1741 ...\n",
            "Validation Accuracy = 89.48159\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1751 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1761 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1771 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1781 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1791 ...\n",
            "Validation Accuracy = 89.55672\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1801 ...\n",
            "Validation Accuracy = 89.48159\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1811 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1821 ...\n",
            "Validation Accuracy = 89.48159\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1831 ...\n",
            "Validation Accuracy = 89.48159\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1841 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1851 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.87113\n",
            "EPOCH 1861 ...\n",
            "Validation Accuracy = 89.40646\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.87113\n",
            "EPOCH 1871 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.87113\n",
            "EPOCH 1881 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1891 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1901 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1911 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1921 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1931 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1941 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.87113\n",
            "EPOCH 1951 ...\n",
            "Validation Accuracy = 89.33133\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.83892\n",
            "EPOCH 1961 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 1971 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 1981 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 1991 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2001 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2011 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2021 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2031 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2041 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2051 ...\n",
            "Validation Accuracy = 89.25620\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2061 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2071 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2081 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2091 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2101 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2111 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.90335\n",
            "EPOCH 2121 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2131 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2141 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2151 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2161 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2171 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2181 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2191 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2201 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2211 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2221 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2231 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2241 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2251 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2261 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2271 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2281 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2291 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2301 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2311 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2321 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2331 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2341 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2351 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2361 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2371 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2381 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2391 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2401 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2411 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2421 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2431 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2441 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2451 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2461 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2471 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2481 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2491 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2501 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2511 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2521 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2531 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2541 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2551 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2561 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2571 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2581 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2591 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2601 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2611 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2621 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2631 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2641 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2651 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2661 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.93557\n",
            "EPOCH 2671 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2681 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2691 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2701 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2711 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2721 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2731 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2741 ...\n",
            "Validation Accuracy = 89.18107\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2751 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2761 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.96778\n",
            "EPOCH 2771 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2781 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2791 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2801 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2811 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2821 ...\n",
            "Validation Accuracy = 89.10593\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2831 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2841 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2851 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2861 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2871 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2881 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2891 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2901 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2911 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2921 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2931 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2941 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2951 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2961 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2971 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2981 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 2991 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3001 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3011 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3021 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3031 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3041 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3051 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3061 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3071 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3081 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3091 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3101 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3111 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3121 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3131 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3141 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3151 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3161 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3171 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3181 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3191 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3201 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3211 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3221 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3231 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3241 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3251 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3261 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3271 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3281 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3291 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3301 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3311 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3321 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3331 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3341 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3351 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3361 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3371 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3381 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3391 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3401 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3411 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3421 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3431 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3441 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3451 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3461 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3471 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3481 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3491 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3501 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3511 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3521 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3531 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3541 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3551 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3561 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3571 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3581 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3591 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3601 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3611 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3621 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3631 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3641 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3651 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3661 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3671 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3681 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3691 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3701 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3711 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3721 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3731 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3741 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3751 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3761 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3771 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3781 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3791 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3801 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3811 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3821 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3831 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3841 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3851 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3861 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3871 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3881 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3891 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3901 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3911 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3921 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3931 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3941 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3951 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3961 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3971 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3981 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 3991 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4001 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4011 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4021 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4031 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4041 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4051 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4061 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4071 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4081 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4091 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4101 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4111 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4121 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4131 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4141 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4151 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4161 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4171 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4181 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4191 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4201 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4211 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4221 ...\n",
            "Validation Accuracy = 88.50488\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4231 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4241 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4251 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4261 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4271 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4281 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4291 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4301 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4311 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4321 ...\n",
            "Validation Accuracy = 88.58001\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4331 ...\n",
            "Validation Accuracy = 88.65514\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4341 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4351 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4361 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4371 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4381 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4391 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4401 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4411 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4421 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4431 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4441 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4451 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4461 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4471 ...\n",
            "Validation Accuracy = 88.80540\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4481 ...\n",
            "Validation Accuracy = 88.73028\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4491 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4501 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4511 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4521 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4531 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4541 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4551 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4561 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4571 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4581 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4591 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4601 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4611 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4621 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4631 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4641 ...\n",
            "Validation Accuracy = 89.03080\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4651 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4661 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4671 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4681 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4691 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4701 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4711 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4721 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4731 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4741 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4751 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4761 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4771 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4781 ...\n",
            "Validation Accuracy = 88.88054\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4791 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4801 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4811 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4821 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4831 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4841 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4851 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4861 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4871 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4881 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4891 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4901 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4911 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4921 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4931 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4941 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4951 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4961 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4971 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4981 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 100.00000\n",
            "EPOCH 4991 ...\n",
            "Validation Accuracy = 88.95567\n",
            "0.0\n",
            "\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ob9_kroS1ZK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7c918f9-3b8a-4b76-893b-4e71437f6a0b"
      },
      "cell_type": "code",
      "source": [
        "print(decay_rate)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zydEA48dDeNA",
        "colab_type": "code",
        "outputId": "321475ee-2476-4770-c7ef-6f0adb640aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.argmax(validation_accuracy_track)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "oDevMH2N3JZu",
        "colab_type": "code",
        "outputId": "5af5874a-61bf-4aba-b6ca-680046610313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "best_accuracy_valid"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.556725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "uhbuJEM0-sVm",
        "colab_type": "code",
        "outputId": "8ba755b3-8c17-46d6-caa7-6a1fb09ec0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './DNAAdamBased')\n",
        "    saver.save(sess, './SatimFullAdam')\n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True})\n",
        "    print(\"Validation Accuracy = {:.6f}\".format(validation_accuracy))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./DNAAdamBased\n",
            "Validation Accuracy = 89.556725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D5okZYa4CSqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ou2-UqDCXZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "steps_plot =  [step for step in range(0, 4861, print_every)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6G17qZY_Pxq",
        "colab_type": "code",
        "outputId": "d97074f9-fd1a-421d-b00c-9f160fb0b645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(validation_accuracy_track)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "sNS-YE0XCg4s",
        "colab_type": "code",
        "outputId": "871a7aca-5610-4fbb-cac9-9a615ff8ca81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "# plt.plot( savgol_filter(np.asarray(validation_accuracy_track),51,1))\n",
        "plt.plot( (validation_accuracy_track))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f08453991d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEVRAPj/XXZZk2pRLlMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BBlFJwfn-45J",
        "colab_type": "code",
        "outputId": "5711c091-0c93-4ad0-e413-d089d537ac56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot( (connection_probability_track))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f08454409b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MCKAiyEFCg2F",
        "colab_type": "code",
        "outputId": "7c241b69-8f09-491a-c778-b15d220dffb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "steps_plot = epoch_track# [step for step in range(0, 2291, print_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, np.asarray(train_accuracy_track))  \n",
        "plt.plot(steps_plot, validation_accuracy_track)\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "u7hYf8U_CXWh",
        "colab_type": "code",
        "outputId": "35f3e6d0-5c3b-4582-9c84-26cf0ba6832b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "valid_accuracy_filtered = validation_accuracy_track\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.556725\n",
            "179\n",
            "1790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TKucNn6bEZzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lrwM4UUCXTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sio.savemat('SatimFullDatasetADAM_ProbabilityBasedValid89p48.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "                                       'train_accuracy_track':train_accuracy_track,\n",
        "                                       'connection_probability_track':connection_probability_track,\n",
        "                                       'epochTrack':epoch_track, 'TestAcc':'test_accuracy',\n",
        "                                                         'BestValidation':best_accuracy_valid})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFCL8d7-CIxP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Now  retrain til 24 Epochs"
      ]
    },
    {
      "metadata": {
        "id": "qoqMxUbZCIRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5n7bYp9-FCn8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 1791"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "puoBTQ3fCIOT",
        "colab_type": "code",
        "outputId": "5a597532-042a-40fc-d714-047a808483a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 15368
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "\n",
        "print_every = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(X_train)\n",
        "    best_accuracy_valid = 0\n",
        "    print(\"Training...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        X_train, y_train = shuffle(combined_train_valid, combined_train_valid_label)\n",
        "        for step in range(0, total_steps_for_one_pass):        \n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "#             print(step,'Finishing',step*BATCH_SIZE )\n",
        "            step = 0\n",
        "\n",
        "          else:\n",
        "\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "#             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "#           print(batch_y.shape)\n",
        "          tr_op  = sess.run([training_operation], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "#           train_writer.add_summary(summary_tr, i)\n",
        "        prob = sess.run(new_prob)\n",
        "        if i%print_every == 0:\n",
        "          tr_accuracy = sess.run(accuracy*100, feed_dict={x: X_train,y:y_train, is_testing: True})  # evaluate(X_train, y_train)\n",
        "          print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={x: aside_valid_test,y:aside_valid_test_label, is_testing: True}) #evaluate(X_validation, y_validation)\n",
        "          validation_accuracy_track.append(validation_accuracy)\n",
        "          train_accuracy_track.append(tr_accuracy)\n",
        "          connection_probability_track.append(prob)\n",
        "          print(\"EPOCH {} ...\".format(i+1))\n",
        "          print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "          print(prob)\n",
        "          print()\n",
        "          if (validation_accuracy >= best_accuracy_valid):\n",
        "            best_accuracy_valid = validation_accuracy\n",
        "#             saver.save(sess, './PendigitSGDBased')\n",
        "    saver.save(sess, './SatimFullAdamBasedAllPass')   \n",
        "#     saver.save(sess, './lenet')\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\n",
            "Train Accuracy = 94.09111\n",
            "EPOCH 1 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.7692308\n",
            "\n",
            "Train Accuracy = 94.70004\n",
            "EPOCH 11 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.055798586\n",
            "\n",
            "Train Accuracy = 94.90302\n",
            "EPOCH 21 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.004047527\n",
            "\n",
            "Train Accuracy = 94.99323\n",
            "EPOCH 31 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0002936002\n",
            "\n",
            "Train Accuracy = 95.06089\n",
            "EPOCH 41 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.1297219e-05\n",
            "\n",
            "Train Accuracy = 94.99323\n",
            "EPOCH 51 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.5448612e-06\n",
            "\n",
            "Train Accuracy = 95.03835\n",
            "EPOCH 61 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.120614e-07\n",
            "\n",
            "Train Accuracy = 95.15110\n",
            "EPOCH 71 ...\n",
            "Validation Accuracy = 100.00000\n",
            "8.128727e-09\n",
            "\n",
            "Train Accuracy = 95.19621\n",
            "EPOCH 81 ...\n",
            "Validation Accuracy = 100.00000\n",
            "5.8964295e-10\n",
            "\n",
            "Train Accuracy = 95.26387\n",
            "EPOCH 91 ...\n",
            "Validation Accuracy = 100.00000\n",
            "4.2771616e-11\n",
            "\n",
            "Train Accuracy = 95.19621\n",
            "EPOCH 101 ...\n",
            "Validation Accuracy = 100.00000\n",
            "3.1025744e-12\n",
            "\n",
            "Train Accuracy = 95.30898\n",
            "EPOCH 111 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.2505507e-13\n",
            "\n",
            "Train Accuracy = 95.44429\n",
            "EPOCH 121 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.6325083e-14\n",
            "\n",
            "Train Accuracy = 95.44429\n",
            "EPOCH 131 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.1841916e-15\n",
            "\n",
            "Train Accuracy = 95.46684\n",
            "EPOCH 141 ...\n",
            "Validation Accuracy = 100.00000\n",
            "8.589908e-17\n",
            "\n",
            "Train Accuracy = 95.46684\n",
            "EPOCH 151 ...\n",
            "Validation Accuracy = 100.00000\n",
            "6.230962e-18\n",
            "\n",
            "Train Accuracy = 95.73748\n",
            "EPOCH 161 ...\n",
            "Validation Accuracy = 100.00000\n",
            "4.519825e-19\n",
            "\n",
            "Train Accuracy = 95.57961\n",
            "EPOCH 171 ...\n",
            "Validation Accuracy = 100.00000\n",
            "3.278598e-20\n",
            "\n",
            "Train Accuracy = 95.66982\n",
            "EPOCH 181 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.378235e-21\n",
            "\n",
            "Train Accuracy = 95.71494\n",
            "EPOCH 191 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.7251281e-22\n",
            "\n",
            "Train Accuracy = 95.73748\n",
            "EPOCH 201 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.2513764e-23\n",
            "\n",
            "Train Accuracy = 95.76003\n",
            "EPOCH 211 ...\n",
            "Validation Accuracy = 100.00000\n",
            "9.077255e-25\n",
            "\n",
            "Train Accuracy = 95.82769\n",
            "EPOCH 221 ...\n",
            "Validation Accuracy = 100.00000\n",
            "6.584474e-26\n",
            "\n",
            "Train Accuracy = 95.87280\n",
            "EPOCH 231 ...\n",
            "Validation Accuracy = 100.00000\n",
            "4.7762573e-27\n",
            "\n",
            "Train Accuracy = 96.07578\n",
            "EPOCH 241 ...\n",
            "Validation Accuracy = 100.00000\n",
            "3.4646095e-28\n",
            "\n",
            "Train Accuracy = 95.91791\n",
            "EPOCH 251 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.513164e-29\n",
            "\n",
            "Train Accuracy = 95.91791\n",
            "EPOCH 261 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.8230031e-30\n",
            "\n",
            "Train Accuracy = 95.96301\n",
            "EPOCH 271 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.3223731e-31\n",
            "\n",
            "Train Accuracy = 96.05322\n",
            "EPOCH 281 ...\n",
            "Validation Accuracy = 100.00000\n",
            "9.5922514e-33\n",
            "\n",
            "Train Accuracy = 96.16599\n",
            "EPOCH 291 ...\n",
            "Validation Accuracy = 100.00000\n",
            "6.9580436e-34\n",
            "\n",
            "Train Accuracy = 96.18855\n",
            "EPOCH 301 ...\n",
            "Validation Accuracy = 100.00000\n",
            "5.047237e-35\n",
            "\n",
            "Train Accuracy = 96.14343\n",
            "EPOCH 311 ...\n",
            "Validation Accuracy = 100.00000\n",
            "3.6611724e-36\n",
            "\n",
            "Train Accuracy = 96.12088\n",
            "EPOCH 321 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.6557474e-37\n",
            "\n",
            "Train Accuracy = 96.05322\n",
            "EPOCH 331 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.9264303e-38\n",
            "\n",
            "Train Accuracy = 96.32386\n",
            "EPOCH 341 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.16599\n",
            "EPOCH 351 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.41407\n",
            "EPOCH 361 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.21109\n",
            "EPOCH 371 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.21109\n",
            "EPOCH 381 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.41407\n",
            "EPOCH 391 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.48174\n",
            "EPOCH 401 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.59450\n",
            "EPOCH 411 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.32386\n",
            "EPOCH 421 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.48174\n",
            "EPOCH 431 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.57195\n",
            "EPOCH 441 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.59450\n",
            "EPOCH 451 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.57195\n",
            "EPOCH 461 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.61705\n",
            "EPOCH 471 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.63960\n",
            "EPOCH 481 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.57195\n",
            "EPOCH 491 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.70726\n",
            "EPOCH 501 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.77493\n",
            "EPOCH 511 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.75237\n",
            "EPOCH 521 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.63960\n",
            "EPOCH 531 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.75237\n",
            "EPOCH 541 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.75237\n",
            "EPOCH 551 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.84258\n",
            "EPOCH 561 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.75237\n",
            "EPOCH 571 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.97790\n",
            "EPOCH 581 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.95535\n",
            "EPOCH 591 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.02300\n",
            "EPOCH 601 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.97790\n",
            "EPOCH 611 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.88768\n",
            "EPOCH 621 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.84258\n",
            "EPOCH 631 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.95535\n",
            "EPOCH 641 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.02300\n",
            "EPOCH 651 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 96.93279\n",
            "EPOCH 661 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.11321\n",
            "EPOCH 671 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.09066\n",
            "EPOCH 681 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.29364\n",
            "EPOCH 691 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.13577\n",
            "EPOCH 701 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.20343\n",
            "EPOCH 711 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.29364\n",
            "EPOCH 721 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.27109\n",
            "EPOCH 731 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.13577\n",
            "EPOCH 741 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.22598\n",
            "EPOCH 751 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.27109\n",
            "EPOCH 761 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.42896\n",
            "EPOCH 771 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.40640\n",
            "EPOCH 781 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.45152\n",
            "EPOCH 791 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.38385\n",
            "EPOCH 801 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.38385\n",
            "EPOCH 811 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.38385\n",
            "EPOCH 821 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.36130\n",
            "EPOCH 831 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.40640\n",
            "EPOCH 841 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.67704\n",
            "EPOCH 851 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.63194\n",
            "EPOCH 861 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.33875\n",
            "EPOCH 871 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.74470\n",
            "EPOCH 881 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.38385\n",
            "EPOCH 891 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.51917\n",
            "EPOCH 901 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.69959\n",
            "EPOCH 911 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.76725\n",
            "EPOCH 921 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.72215\n",
            "EPOCH 931 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.49662\n",
            "EPOCH 941 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.74470\n",
            "EPOCH 951 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.78980\n",
            "EPOCH 961 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.83492\n",
            "EPOCH 971 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.54173\n",
            "EPOCH 981 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.81236\n",
            "EPOCH 991 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.97023\n",
            "EPOCH 1001 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.83492\n",
            "EPOCH 1011 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.94768\n",
            "EPOCH 1021 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.69959\n",
            "EPOCH 1031 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.78980\n",
            "EPOCH 1041 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.83492\n",
            "EPOCH 1051 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.90257\n",
            "EPOCH 1061 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.92513\n",
            "EPOCH 1071 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.74470\n",
            "EPOCH 1081 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.01534\n",
            "EPOCH 1091 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.03789\n",
            "EPOCH 1101 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.83492\n",
            "EPOCH 1111 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.88002\n",
            "EPOCH 1121 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 97.99278\n",
            "EPOCH 1131 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.06044\n",
            "EPOCH 1141 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.03789\n",
            "EPOCH 1151 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.24087\n",
            "EPOCH 1161 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.30853\n",
            "EPOCH 1171 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.30853\n",
            "EPOCH 1181 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.26342\n",
            "EPOCH 1191 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.30853\n",
            "EPOCH 1201 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.30853\n",
            "EPOCH 1211 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.28597\n",
            "EPOCH 1221 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.33108\n",
            "EPOCH 1231 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.15065\n",
            "EPOCH 1241 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.17321\n",
            "EPOCH 1251 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42129\n",
            "EPOCH 1261 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.39874\n",
            "EPOCH 1271 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.28597\n",
            "EPOCH 1281 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42129\n",
            "EPOCH 1291 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.44384\n",
            "EPOCH 1301 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.37618\n",
            "EPOCH 1311 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.24087\n",
            "EPOCH 1321 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.44384\n",
            "EPOCH 1331 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.21832\n",
            "EPOCH 1341 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42129\n",
            "EPOCH 1351 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.46640\n",
            "EPOCH 1361 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.33108\n",
            "EPOCH 1371 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.28597\n",
            "EPOCH 1381 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42129\n",
            "EPOCH 1391 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.42129\n",
            "EPOCH 1401 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.48895\n",
            "EPOCH 1411 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.39874\n",
            "EPOCH 1421 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.44384\n",
            "EPOCH 1431 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.55661\n",
            "EPOCH 1441 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.69193\n",
            "EPOCH 1451 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.57916\n",
            "EPOCH 1461 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.66937\n",
            "EPOCH 1471 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.71448\n",
            "EPOCH 1481 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.64682\n",
            "EPOCH 1491 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.69193\n",
            "EPOCH 1501 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.62427\n",
            "EPOCH 1511 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.78214\n",
            "EPOCH 1521 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.73703\n",
            "EPOCH 1531 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.75958\n",
            "EPOCH 1541 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.80469\n",
            "EPOCH 1551 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.64682\n",
            "EPOCH 1561 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.71448\n",
            "EPOCH 1571 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.75958\n",
            "EPOCH 1581 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.66937\n",
            "EPOCH 1591 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.66937\n",
            "EPOCH 1601 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.73703\n",
            "EPOCH 1611 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.71448\n",
            "EPOCH 1621 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.73703\n",
            "EPOCH 1631 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96256\n",
            "EPOCH 1641 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.84980\n",
            "EPOCH 1651 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.87235\n",
            "EPOCH 1661 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96256\n",
            "EPOCH 1671 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.00767\n",
            "EPOCH 1681 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.91746\n",
            "EPOCH 1691 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96256\n",
            "EPOCH 1701 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.05277\n",
            "EPOCH 1711 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96256\n",
            "EPOCH 1721 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14299\n",
            "EPOCH 1731 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.91746\n",
            "EPOCH 1741 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.07533\n",
            "EPOCH 1751 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.05277\n",
            "EPOCH 1761 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.91746\n",
            "EPOCH 1771 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.00767\n",
            "EPOCH 1781 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.87235\n",
            "EPOCH 1791 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ImtSTCNJF9E_",
        "colab_type": "code",
        "outputId": "0b2f78ed-31f4-47af-abfb-001ed51c2ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './SatimFullAdamBasedAllPass')\n",
        "#     saver.save(sess, './HarReducedAdamAllPass')  \n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True})\n",
        "    print(\"Validation Accuracy = {:.6f}\".format(validation_accuracy))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./SatimFullAdamBasedAllPass\n",
            "Validation Accuracy = 97.971451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4FVMAeXpCIL8",
        "colab_type": "code",
        "outputId": "11950881-b87c-4877-8773-a8f314b60807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Without all pass\n",
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './SatimFullAdamBasedAllPass')\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={x: test_data,y:test_label_one_hot, is_testing: True})\n",
        "    print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./SatimFullAdamBasedAllPass\n",
            "Test Accuracy = 90.500000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VGUWHQR3CIJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-HXCpiAuCIGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGYzlt7KCIDI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hr57zkSqCIAK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q08ZXCdr-sTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Without all pass\n",
        "# with tf.Session() as sess:\n",
        "# #     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "#     saver.restore(sess, './PendigitSGDBased')\n",
        "#     test_accuracy = sess.run(accuracy*100, feed_dict={x: test_data,y:test_label_one_hot, is_testing: True})\n",
        "#     print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M9z1P1DG-sQM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dW6V7O1e-sNf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochTrack = epoch_track\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r7lCgbXR3JXa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vFfzfjOB3JTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
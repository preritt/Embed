{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PendigitReducedProbabilityBasedMay03 .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/PendigitReducedProbabilityBasedMay03_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWL1XvRKt0EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuoNYnTshaZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "train_data = np.load('X_train.npy')\n",
        "train_label = np.load('y_train.npy')\n",
        "validation_data = np.load('X_validation.npy')\n",
        "validation_label = np.load('y_validation.npy')\n",
        "test_data = np.load('X_test.npy')\n",
        "test_label = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4FSwFTChgdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_label = np.concatenate((train_label, validation_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5erFTN6-BRM",
        "colab_type": "code",
        "outputId": "98f26c9d-8df0-467a-f589-d2cc52d002f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7494, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VloppGYRyrEX",
        "colab_type": "code",
        "outputId": "3fe1083f-65e7-4e18-9f64-0334d367ab29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5236
        }
      },
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(52, ), max_iter=300, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.01)\n",
        "\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.19446587\n",
            "Iteration 2, loss = 0.23696629\n",
            "Iteration 3, loss = 0.17868948\n",
            "Iteration 4, loss = 0.15552579\n",
            "Iteration 5, loss = 0.14108610\n",
            "Iteration 6, loss = 0.13240962\n",
            "Iteration 7, loss = 0.12542174\n",
            "Iteration 8, loss = 0.11955255\n",
            "Iteration 9, loss = 0.11543610\n",
            "Iteration 10, loss = 0.11101569\n",
            "Iteration 11, loss = 0.10793801\n",
            "Iteration 12, loss = 0.10518172\n",
            "Iteration 13, loss = 0.10256103\n",
            "Iteration 14, loss = 0.10092615\n",
            "Iteration 15, loss = 0.09840088\n",
            "Iteration 16, loss = 0.09555894\n",
            "Iteration 17, loss = 0.09388517\n",
            "Iteration 18, loss = 0.09318289\n",
            "Iteration 19, loss = 0.09089645\n",
            "Iteration 20, loss = 0.08987732\n",
            "Iteration 21, loss = 0.08898618\n",
            "Iteration 22, loss = 0.08664369\n",
            "Iteration 23, loss = 0.08537959\n",
            "Iteration 24, loss = 0.08471996\n",
            "Iteration 25, loss = 0.08398658\n",
            "Iteration 26, loss = 0.08219434\n",
            "Iteration 27, loss = 0.08018296\n",
            "Iteration 28, loss = 0.08004677\n",
            "Iteration 29, loss = 0.07829681\n",
            "Iteration 30, loss = 0.07822888\n",
            "Iteration 31, loss = 0.07835564\n",
            "Iteration 32, loss = 0.07630159\n",
            "Iteration 33, loss = 0.07480104\n",
            "Iteration 34, loss = 0.07475919\n",
            "Iteration 35, loss = 0.07333453\n",
            "Iteration 36, loss = 0.07289138\n",
            "Iteration 37, loss = 0.07181937\n",
            "Iteration 38, loss = 0.07175785\n",
            "Iteration 39, loss = 0.07048879\n",
            "Iteration 40, loss = 0.06975888\n",
            "Iteration 41, loss = 0.07005298\n",
            "Iteration 42, loss = 0.06975936\n",
            "Iteration 43, loss = 0.06846355\n",
            "Iteration 44, loss = 0.06751092\n",
            "Iteration 45, loss = 0.06766759\n",
            "Iteration 46, loss = 0.06660535\n",
            "Iteration 47, loss = 0.06581473\n",
            "Iteration 48, loss = 0.06611731\n",
            "Iteration 49, loss = 0.06527860\n",
            "Iteration 50, loss = 0.06580920\n",
            "Iteration 51, loss = 0.06420833\n",
            "Iteration 52, loss = 0.06324661\n",
            "Iteration 53, loss = 0.06273623\n",
            "Iteration 54, loss = 0.06345121\n",
            "Iteration 55, loss = 0.06295479\n",
            "Iteration 56, loss = 0.06271901\n",
            "Iteration 57, loss = 0.06258118\n",
            "Iteration 58, loss = 0.06109074\n",
            "Iteration 59, loss = 0.06097699\n",
            "Iteration 60, loss = 0.06096126\n",
            "Iteration 61, loss = 0.05971780\n",
            "Iteration 62, loss = 0.05987020\n",
            "Iteration 63, loss = 0.05929332\n",
            "Iteration 64, loss = 0.05913139\n",
            "Iteration 65, loss = 0.05872885\n",
            "Iteration 66, loss = 0.05870300\n",
            "Iteration 67, loss = 0.05789683\n",
            "Iteration 68, loss = 0.05743750\n",
            "Iteration 69, loss = 0.05720833\n",
            "Iteration 70, loss = 0.05722436\n",
            "Iteration 71, loss = 0.05760029\n",
            "Iteration 72, loss = 0.05681588\n",
            "Iteration 73, loss = 0.05618295\n",
            "Iteration 74, loss = 0.05590201\n",
            "Iteration 75, loss = 0.05626691\n",
            "Iteration 76, loss = 0.05535437\n",
            "Iteration 77, loss = 0.05506384\n",
            "Iteration 78, loss = 0.05528812\n",
            "Iteration 79, loss = 0.05422711\n",
            "Iteration 80, loss = 0.05446720\n",
            "Iteration 81, loss = 0.05555991\n",
            "Iteration 82, loss = 0.05388408\n",
            "Iteration 83, loss = 0.05473811\n",
            "Iteration 84, loss = 0.05366372\n",
            "Iteration 85, loss = 0.05308701\n",
            "Iteration 86, loss = 0.05278121\n",
            "Iteration 87, loss = 0.05267624\n",
            "Iteration 88, loss = 0.05311953\n",
            "Iteration 89, loss = 0.05237590\n",
            "Iteration 90, loss = 0.05255056\n",
            "Iteration 91, loss = 0.05214811\n",
            "Iteration 92, loss = 0.05158367\n",
            "Iteration 93, loss = 0.05170608\n",
            "Iteration 94, loss = 0.05097209\n",
            "Iteration 95, loss = 0.05091453\n",
            "Iteration 96, loss = 0.05135406\n",
            "Iteration 97, loss = 0.05034064\n",
            "Iteration 98, loss = 0.05022167\n",
            "Iteration 99, loss = 0.05095791\n",
            "Iteration 100, loss = 0.04961350\n",
            "Iteration 101, loss = 0.05064483\n",
            "Iteration 102, loss = 0.05073258\n",
            "Iteration 103, loss = 0.05005304\n",
            "Iteration 104, loss = 0.05163886\n",
            "Iteration 105, loss = 0.04958955\n",
            "Iteration 106, loss = 0.04879180\n",
            "Iteration 107, loss = 0.04937808\n",
            "Iteration 108, loss = 0.04905763\n",
            "Iteration 109, loss = 0.04901305\n",
            "Iteration 110, loss = 0.04819569\n",
            "Iteration 111, loss = 0.04865646\n",
            "Iteration 112, loss = 0.04839820\n",
            "Iteration 113, loss = 0.04831668\n",
            "Iteration 114, loss = 0.04720840\n",
            "Iteration 115, loss = 0.04705462\n",
            "Iteration 116, loss = 0.04779093\n",
            "Iteration 117, loss = 0.04798699\n",
            "Iteration 118, loss = 0.04740709\n",
            "Iteration 119, loss = 0.04728460\n",
            "Iteration 120, loss = 0.04767912\n",
            "Iteration 121, loss = 0.04682136\n",
            "Iteration 122, loss = 0.04696737\n",
            "Iteration 123, loss = 0.04633472\n",
            "Iteration 124, loss = 0.04659317\n",
            "Iteration 125, loss = 0.04653313\n",
            "Iteration 126, loss = 0.04602319\n",
            "Iteration 127, loss = 0.04591099\n",
            "Iteration 128, loss = 0.04501738\n",
            "Iteration 129, loss = 0.04619777\n",
            "Iteration 130, loss = 0.04581902\n",
            "Iteration 131, loss = 0.04524073\n",
            "Iteration 132, loss = 0.04573403\n",
            "Iteration 133, loss = 0.04542550\n",
            "Iteration 134, loss = 0.04523663\n",
            "Iteration 135, loss = 0.04502494\n",
            "Iteration 136, loss = 0.04579509\n",
            "Iteration 137, loss = 0.04478158\n",
            "Iteration 138, loss = 0.04429900\n",
            "Iteration 139, loss = 0.04432835\n",
            "Iteration 140, loss = 0.04472356\n",
            "Iteration 141, loss = 0.04401428\n",
            "Iteration 142, loss = 0.04456657\n",
            "Iteration 143, loss = 0.04444233\n",
            "Iteration 144, loss = 0.04389731\n",
            "Iteration 145, loss = 0.04379786\n",
            "Iteration 146, loss = 0.04389524\n",
            "Iteration 147, loss = 0.04375842\n",
            "Iteration 148, loss = 0.04441555\n",
            "Iteration 149, loss = 0.04380099\n",
            "Iteration 150, loss = 0.04407227\n",
            "Iteration 151, loss = 0.04374381\n",
            "Iteration 152, loss = 0.04394211\n",
            "Iteration 153, loss = 0.04349569\n",
            "Iteration 154, loss = 0.04275113\n",
            "Iteration 155, loss = 0.04295906\n",
            "Iteration 156, loss = 0.04298407\n",
            "Iteration 157, loss = 0.04269523\n",
            "Iteration 158, loss = 0.04307885\n",
            "Iteration 159, loss = 0.04273689\n",
            "Iteration 160, loss = 0.04274220\n",
            "Iteration 161, loss = 0.04273123\n",
            "Iteration 162, loss = 0.04289732\n",
            "Iteration 163, loss = 0.04263709\n",
            "Iteration 164, loss = 0.04255530\n",
            "Iteration 165, loss = 0.04193794\n",
            "Iteration 166, loss = 0.04243718\n",
            "Iteration 167, loss = 0.04214676\n",
            "Iteration 168, loss = 0.04229058\n",
            "Iteration 169, loss = 0.04166305\n",
            "Iteration 170, loss = 0.04159365\n",
            "Iteration 171, loss = 0.04145764\n",
            "Iteration 172, loss = 0.04184316\n",
            "Iteration 173, loss = 0.04115987\n",
            "Iteration 174, loss = 0.04128029\n",
            "Iteration 175, loss = 0.04181253\n",
            "Iteration 176, loss = 0.04204112\n",
            "Iteration 177, loss = 0.04090128\n",
            "Iteration 178, loss = 0.04077446\n",
            "Iteration 179, loss = 0.04121384\n",
            "Iteration 180, loss = 0.04104961\n",
            "Iteration 181, loss = 0.04106618\n",
            "Iteration 182, loss = 0.04057016\n",
            "Iteration 183, loss = 0.04080858\n",
            "Iteration 184, loss = 0.04130482\n",
            "Iteration 185, loss = 0.04017086\n",
            "Iteration 186, loss = 0.04048820\n",
            "Iteration 187, loss = 0.04039760\n",
            "Iteration 188, loss = 0.04082673\n",
            "Iteration 189, loss = 0.04050670\n",
            "Iteration 190, loss = 0.03977136\n",
            "Iteration 191, loss = 0.04035478\n",
            "Iteration 192, loss = 0.04013814\n",
            "Iteration 193, loss = 0.03997412\n",
            "Iteration 194, loss = 0.03965723\n",
            "Iteration 195, loss = 0.04011808\n",
            "Iteration 196, loss = 0.04145274\n",
            "Iteration 197, loss = 0.04030598\n",
            "Iteration 198, loss = 0.04025520\n",
            "Iteration 199, loss = 0.03950205\n",
            "Iteration 200, loss = 0.03968778\n",
            "Iteration 201, loss = 0.03982633\n",
            "Iteration 202, loss = 0.03907211\n",
            "Iteration 203, loss = 0.03908903\n",
            "Iteration 204, loss = 0.03958331\n",
            "Iteration 205, loss = 0.03914075\n",
            "Iteration 206, loss = 0.03946970\n",
            "Iteration 207, loss = 0.03935095\n",
            "Iteration 208, loss = 0.03953642\n",
            "Iteration 209, loss = 0.03956065\n",
            "Iteration 210, loss = 0.03918492\n",
            "Iteration 211, loss = 0.03922738\n",
            "Iteration 212, loss = 0.03881615\n",
            "Iteration 213, loss = 0.03938698\n",
            "Iteration 214, loss = 0.03865229\n",
            "Iteration 215, loss = 0.03899486\n",
            "Iteration 216, loss = 0.03838757\n",
            "Iteration 217, loss = 0.03878241\n",
            "Iteration 218, loss = 0.03922885\n",
            "Iteration 219, loss = 0.03861657\n",
            "Iteration 220, loss = 0.03865917\n",
            "Iteration 221, loss = 0.03839199\n",
            "Iteration 222, loss = 0.03864654\n",
            "Iteration 223, loss = 0.03789876\n",
            "Iteration 224, loss = 0.03905423\n",
            "Iteration 225, loss = 0.03779147\n",
            "Iteration 226, loss = 0.03806444\n",
            "Iteration 227, loss = 0.03798489\n",
            "Iteration 228, loss = 0.03821398\n",
            "Iteration 229, loss = 0.03903213\n",
            "Iteration 230, loss = 0.03818617\n",
            "Iteration 231, loss = 0.03761949\n",
            "Iteration 232, loss = 0.03750375\n",
            "Iteration 233, loss = 0.03787092\n",
            "Iteration 234, loss = 0.03859993\n",
            "Iteration 235, loss = 0.03748704\n",
            "Iteration 236, loss = 0.03794061\n",
            "Iteration 237, loss = 0.03795048\n",
            "Iteration 238, loss = 0.03772659\n",
            "Iteration 239, loss = 0.03758033\n",
            "Iteration 240, loss = 0.03888061\n",
            "Iteration 241, loss = 0.03726983\n",
            "Iteration 242, loss = 0.03832190\n",
            "Iteration 243, loss = 0.03832151\n",
            "Iteration 244, loss = 0.03738000\n",
            "Iteration 245, loss = 0.03760494\n",
            "Iteration 246, loss = 0.03695023\n",
            "Iteration 247, loss = 0.03846052\n",
            "Iteration 248, loss = 0.03770035\n",
            "Iteration 249, loss = 0.03677972\n",
            "Iteration 250, loss = 0.03805998\n",
            "Iteration 251, loss = 0.03706846\n",
            "Iteration 252, loss = 0.03683238\n",
            "Iteration 253, loss = 0.03712343\n",
            "Iteration 254, loss = 0.03785976\n",
            "Iteration 255, loss = 0.03810663\n",
            "Iteration 256, loss = 0.03740622\n",
            "Iteration 257, loss = 0.03700200\n",
            "Iteration 258, loss = 0.03684150\n",
            "Iteration 259, loss = 0.03676213\n",
            "Iteration 260, loss = 0.03714139\n",
            "Iteration 261, loss = 0.03834680\n",
            "Iteration 262, loss = 0.03655144\n",
            "Iteration 263, loss = 0.03693476\n",
            "Iteration 264, loss = 0.03679985\n",
            "Iteration 265, loss = 0.03699390\n",
            "Iteration 266, loss = 0.03638448\n",
            "Iteration 267, loss = 0.03695512\n",
            "Iteration 268, loss = 0.03598962\n",
            "Iteration 269, loss = 0.03629624\n",
            "Iteration 270, loss = 0.03682766\n",
            "Iteration 271, loss = 0.03633297\n",
            "Iteration 272, loss = 0.03626379\n",
            "Iteration 273, loss = 0.03579389\n",
            "Iteration 274, loss = 0.03678263\n",
            "Iteration 275, loss = 0.03565787\n",
            "Iteration 276, loss = 0.03540347\n",
            "Iteration 277, loss = 0.03646504\n",
            "Iteration 278, loss = 0.03694376\n",
            "Iteration 279, loss = 0.03599226\n",
            "Iteration 280, loss = 0.03615126\n",
            "Iteration 281, loss = 0.03604124\n",
            "Iteration 282, loss = 0.03616731\n",
            "Iteration 283, loss = 0.03665035\n",
            "Iteration 284, loss = 0.03641867\n",
            "Iteration 285, loss = 0.03531962\n",
            "Iteration 286, loss = 0.03585061\n",
            "Iteration 287, loss = 0.03545219\n",
            "Iteration 288, loss = 0.03486525\n",
            "Iteration 289, loss = 0.03498109\n",
            "Iteration 290, loss = 0.03542241\n",
            "Iteration 291, loss = 0.03523527\n",
            "Iteration 292, loss = 0.03498714\n",
            "Iteration 293, loss = 0.03594388\n",
            "Iteration 294, loss = 0.03563986\n",
            "Iteration 295, loss = 0.03618941\n",
            "Iteration 296, loss = 0.03640038\n",
            "Iteration 297, loss = 0.03521632\n",
            "Iteration 298, loss = 0.03626177\n",
            "Iteration 299, loss = 0.03543504\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(52,), learning_rate='constant',\n",
              "       learning_rate_init=0.01, max_iter=300, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m9_X9bUdZJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "# train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo_lFxdIc85n",
        "colab_type": "code",
        "outputId": "901e5f89-4a12-442f-ba4a-3ba30c0d7e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4896
        }
      },
      "source": [
        "# clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "#                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "### acc is 98.41\n",
        "clf2 = MLPClassifier(hidden_layer_sizes=(52, ), max_iter=300, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-5, random_state=1,\n",
        "                    learning_rate_init=.01)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "clf2.fit(train_valid_combined, train_valid_label)\n",
        "# clf2.fit(train_data, train_label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.02835409\n",
            "Iteration 2, loss = 0.20806844\n",
            "Iteration 3, loss = 0.16186345\n",
            "Iteration 4, loss = 0.14236552\n",
            "Iteration 5, loss = 0.13049484\n",
            "Iteration 6, loss = 0.12295001\n",
            "Iteration 7, loss = 0.11667608\n",
            "Iteration 8, loss = 0.11039315\n",
            "Iteration 9, loss = 0.10737870\n",
            "Iteration 10, loss = 0.10366733\n",
            "Iteration 11, loss = 0.09985583\n",
            "Iteration 12, loss = 0.09700508\n",
            "Iteration 13, loss = 0.09421757\n",
            "Iteration 14, loss = 0.09205720\n",
            "Iteration 15, loss = 0.09109401\n",
            "Iteration 16, loss = 0.08875745\n",
            "Iteration 17, loss = 0.08684354\n",
            "Iteration 18, loss = 0.08478296\n",
            "Iteration 19, loss = 0.08372401\n",
            "Iteration 20, loss = 0.08232357\n",
            "Iteration 21, loss = 0.08066136\n",
            "Iteration 22, loss = 0.07941823\n",
            "Iteration 23, loss = 0.07750687\n",
            "Iteration 24, loss = 0.07669953\n",
            "Iteration 25, loss = 0.07559938\n",
            "Iteration 26, loss = 0.07490124\n",
            "Iteration 27, loss = 0.07405346\n",
            "Iteration 28, loss = 0.07264183\n",
            "Iteration 29, loss = 0.07227327\n",
            "Iteration 30, loss = 0.07102841\n",
            "Iteration 31, loss = 0.07042734\n",
            "Iteration 32, loss = 0.07004851\n",
            "Iteration 33, loss = 0.06836436\n",
            "Iteration 34, loss = 0.06793133\n",
            "Iteration 35, loss = 0.06654717\n",
            "Iteration 36, loss = 0.06690701\n",
            "Iteration 37, loss = 0.06613458\n",
            "Iteration 38, loss = 0.06487773\n",
            "Iteration 39, loss = 0.06488728\n",
            "Iteration 40, loss = 0.06385456\n",
            "Iteration 41, loss = 0.06358027\n",
            "Iteration 42, loss = 0.06278615\n",
            "Iteration 43, loss = 0.06203558\n",
            "Iteration 44, loss = 0.06183710\n",
            "Iteration 45, loss = 0.06169359\n",
            "Iteration 46, loss = 0.06063127\n",
            "Iteration 47, loss = 0.06030269\n",
            "Iteration 48, loss = 0.05964267\n",
            "Iteration 49, loss = 0.05996962\n",
            "Iteration 50, loss = 0.05952174\n",
            "Iteration 51, loss = 0.05845597\n",
            "Iteration 52, loss = 0.05821365\n",
            "Iteration 53, loss = 0.05831709\n",
            "Iteration 54, loss = 0.05754459\n",
            "Iteration 55, loss = 0.05721510\n",
            "Iteration 56, loss = 0.05714136\n",
            "Iteration 57, loss = 0.05573599\n",
            "Iteration 58, loss = 0.05510604\n",
            "Iteration 59, loss = 0.05568745\n",
            "Iteration 60, loss = 0.05475460\n",
            "Iteration 61, loss = 0.05482601\n",
            "Iteration 62, loss = 0.05448890\n",
            "Iteration 63, loss = 0.05425679\n",
            "Iteration 64, loss = 0.05350456\n",
            "Iteration 65, loss = 0.05357870\n",
            "Iteration 66, loss = 0.05375183\n",
            "Iteration 67, loss = 0.05350081\n",
            "Iteration 68, loss = 0.05311928\n",
            "Iteration 69, loss = 0.05213982\n",
            "Iteration 70, loss = 0.05211887\n",
            "Iteration 71, loss = 0.05168432\n",
            "Iteration 72, loss = 0.05135286\n",
            "Iteration 73, loss = 0.05182103\n",
            "Iteration 74, loss = 0.05133131\n",
            "Iteration 75, loss = 0.05082076\n",
            "Iteration 76, loss = 0.05059492\n",
            "Iteration 77, loss = 0.05040713\n",
            "Iteration 78, loss = 0.04998523\n",
            "Iteration 79, loss = 0.05022367\n",
            "Iteration 80, loss = 0.05041175\n",
            "Iteration 81, loss = 0.04944649\n",
            "Iteration 82, loss = 0.04964947\n",
            "Iteration 83, loss = 0.04888813\n",
            "Iteration 84, loss = 0.04901144\n",
            "Iteration 85, loss = 0.04852715\n",
            "Iteration 86, loss = 0.04907034\n",
            "Iteration 87, loss = 0.04915708\n",
            "Iteration 88, loss = 0.04830905\n",
            "Iteration 89, loss = 0.04805964\n",
            "Iteration 90, loss = 0.04891386\n",
            "Iteration 91, loss = 0.04820988\n",
            "Iteration 92, loss = 0.04761011\n",
            "Iteration 93, loss = 0.04732148\n",
            "Iteration 94, loss = 0.04750664\n",
            "Iteration 95, loss = 0.04724312\n",
            "Iteration 96, loss = 0.04741340\n",
            "Iteration 97, loss = 0.04699579\n",
            "Iteration 98, loss = 0.04701001\n",
            "Iteration 99, loss = 0.04659829\n",
            "Iteration 100, loss = 0.04626261\n",
            "Iteration 101, loss = 0.04677770\n",
            "Iteration 102, loss = 0.04595959\n",
            "Iteration 103, loss = 0.04590809\n",
            "Iteration 104, loss = 0.04646260\n",
            "Iteration 105, loss = 0.04590933\n",
            "Iteration 106, loss = 0.04509959\n",
            "Iteration 107, loss = 0.04574783\n",
            "Iteration 108, loss = 0.04563006\n",
            "Iteration 109, loss = 0.04566812\n",
            "Iteration 110, loss = 0.04458315\n",
            "Iteration 111, loss = 0.04497389\n",
            "Iteration 112, loss = 0.04474835\n",
            "Iteration 113, loss = 0.04478262\n",
            "Iteration 114, loss = 0.04424492\n",
            "Iteration 115, loss = 0.04519088\n",
            "Iteration 116, loss = 0.04422592\n",
            "Iteration 117, loss = 0.04445173\n",
            "Iteration 118, loss = 0.04367781\n",
            "Iteration 119, loss = 0.04444398\n",
            "Iteration 120, loss = 0.04392827\n",
            "Iteration 121, loss = 0.04370155\n",
            "Iteration 122, loss = 0.04370947\n",
            "Iteration 123, loss = 0.04394257\n",
            "Iteration 124, loss = 0.04317710\n",
            "Iteration 125, loss = 0.04309293\n",
            "Iteration 126, loss = 0.04325124\n",
            "Iteration 127, loss = 0.04375412\n",
            "Iteration 128, loss = 0.04343279\n",
            "Iteration 129, loss = 0.04326428\n",
            "Iteration 130, loss = 0.04243174\n",
            "Iteration 131, loss = 0.04242799\n",
            "Iteration 132, loss = 0.04255979\n",
            "Iteration 133, loss = 0.04204442\n",
            "Iteration 134, loss = 0.04256179\n",
            "Iteration 135, loss = 0.04279888\n",
            "Iteration 136, loss = 0.04189846\n",
            "Iteration 137, loss = 0.04362843\n",
            "Iteration 138, loss = 0.04223112\n",
            "Iteration 139, loss = 0.04425830\n",
            "Iteration 140, loss = 0.04155094\n",
            "Iteration 141, loss = 0.04198995\n",
            "Iteration 142, loss = 0.04150820\n",
            "Iteration 143, loss = 0.04146381\n",
            "Iteration 144, loss = 0.04180960\n",
            "Iteration 145, loss = 0.04127274\n",
            "Iteration 146, loss = 0.04097791\n",
            "Iteration 147, loss = 0.04118043\n",
            "Iteration 148, loss = 0.04113455\n",
            "Iteration 149, loss = 0.04100456\n",
            "Iteration 150, loss = 0.04075696\n",
            "Iteration 151, loss = 0.04109800\n",
            "Iteration 152, loss = 0.04083845\n",
            "Iteration 153, loss = 0.04143443\n",
            "Iteration 154, loss = 0.04130983\n",
            "Iteration 155, loss = 0.04096294\n",
            "Iteration 156, loss = 0.04081142\n",
            "Iteration 157, loss = 0.04003266\n",
            "Iteration 158, loss = 0.04060283\n",
            "Iteration 159, loss = 0.04033974\n",
            "Iteration 160, loss = 0.04018797\n",
            "Iteration 161, loss = 0.04032197\n",
            "Iteration 162, loss = 0.04187178\n",
            "Iteration 163, loss = 0.04078422\n",
            "Iteration 164, loss = 0.04033505\n",
            "Iteration 165, loss = 0.04003979\n",
            "Iteration 166, loss = 0.03943658\n",
            "Iteration 167, loss = 0.03944533\n",
            "Iteration 168, loss = 0.04026673\n",
            "Iteration 169, loss = 0.03911797\n",
            "Iteration 170, loss = 0.04015064\n",
            "Iteration 171, loss = 0.03960103\n",
            "Iteration 172, loss = 0.03962783\n",
            "Iteration 173, loss = 0.03958498\n",
            "Iteration 174, loss = 0.03898348\n",
            "Iteration 175, loss = 0.03914571\n",
            "Iteration 176, loss = 0.03960722\n",
            "Iteration 177, loss = 0.03899574\n",
            "Iteration 178, loss = 0.03937355\n",
            "Iteration 179, loss = 0.03877513\n",
            "Iteration 180, loss = 0.03829182\n",
            "Iteration 181, loss = 0.03864133\n",
            "Iteration 182, loss = 0.03889415\n",
            "Iteration 183, loss = 0.03891447\n",
            "Iteration 184, loss = 0.03897408\n",
            "Iteration 185, loss = 0.03807268\n",
            "Iteration 186, loss = 0.03829522\n",
            "Iteration 187, loss = 0.03872095\n",
            "Iteration 188, loss = 0.03798565\n",
            "Iteration 189, loss = 0.03910254\n",
            "Iteration 190, loss = 0.03907657\n",
            "Iteration 191, loss = 0.03801335\n",
            "Iteration 192, loss = 0.03914735\n",
            "Iteration 193, loss = 0.03821184\n",
            "Iteration 194, loss = 0.03859276\n",
            "Iteration 195, loss = 0.03799437\n",
            "Iteration 196, loss = 0.03824954\n",
            "Iteration 197, loss = 0.03762295\n",
            "Iteration 198, loss = 0.03801005\n",
            "Iteration 199, loss = 0.03727715\n",
            "Iteration 200, loss = 0.03720651\n",
            "Iteration 201, loss = 0.03786752\n",
            "Iteration 202, loss = 0.03754606\n",
            "Iteration 203, loss = 0.03778501\n",
            "Iteration 204, loss = 0.03740453\n",
            "Iteration 205, loss = 0.03761355\n",
            "Iteration 206, loss = 0.03826775\n",
            "Iteration 207, loss = 0.03778991\n",
            "Iteration 208, loss = 0.03738401\n",
            "Iteration 209, loss = 0.03702396\n",
            "Iteration 210, loss = 0.03712399\n",
            "Iteration 211, loss = 0.03725078\n",
            "Iteration 212, loss = 0.03773101\n",
            "Iteration 213, loss = 0.03712839\n",
            "Iteration 214, loss = 0.03737110\n",
            "Iteration 215, loss = 0.03689840\n",
            "Iteration 216, loss = 0.03744812\n",
            "Iteration 217, loss = 0.03657559\n",
            "Iteration 218, loss = 0.03706541\n",
            "Iteration 219, loss = 0.03812039\n",
            "Iteration 220, loss = 0.03662960\n",
            "Iteration 221, loss = 0.03630254\n",
            "Iteration 222, loss = 0.03634971\n",
            "Iteration 223, loss = 0.03646793\n",
            "Iteration 224, loss = 0.03624277\n",
            "Iteration 225, loss = 0.03685566\n",
            "Iteration 226, loss = 0.03651535\n",
            "Iteration 227, loss = 0.03656301\n",
            "Iteration 228, loss = 0.03661601\n",
            "Iteration 229, loss = 0.03739520\n",
            "Iteration 230, loss = 0.03610868\n",
            "Iteration 231, loss = 0.03686020\n",
            "Iteration 232, loss = 0.03670017\n",
            "Iteration 233, loss = 0.03635405\n",
            "Iteration 234, loss = 0.03653263\n",
            "Iteration 235, loss = 0.03588199\n",
            "Iteration 236, loss = 0.03633381\n",
            "Iteration 237, loss = 0.03606480\n",
            "Iteration 238, loss = 0.03596379\n",
            "Iteration 239, loss = 0.03619717\n",
            "Iteration 240, loss = 0.03701473\n",
            "Iteration 241, loss = 0.03620529\n",
            "Iteration 242, loss = 0.03614842\n",
            "Iteration 243, loss = 0.03551794\n",
            "Iteration 244, loss = 0.03658738\n",
            "Iteration 245, loss = 0.03578332\n",
            "Iteration 246, loss = 0.03592173\n",
            "Iteration 247, loss = 0.03585908\n",
            "Iteration 248, loss = 0.03504526\n",
            "Iteration 249, loss = 0.03590478\n",
            "Iteration 250, loss = 0.03633082\n",
            "Iteration 251, loss = 0.03616249\n",
            "Iteration 252, loss = 0.03616394\n",
            "Iteration 253, loss = 0.03583584\n",
            "Iteration 254, loss = 0.03541899\n",
            "Iteration 255, loss = 0.03513443\n",
            "Iteration 256, loss = 0.03575241\n",
            "Iteration 257, loss = 0.03536614\n",
            "Iteration 258, loss = 0.03503229\n",
            "Iteration 259, loss = 0.03485818\n",
            "Iteration 260, loss = 0.03510446\n",
            "Iteration 261, loss = 0.03469738\n",
            "Iteration 262, loss = 0.03548821\n",
            "Iteration 263, loss = 0.03460572\n",
            "Iteration 264, loss = 0.03485623\n",
            "Iteration 265, loss = 0.03612007\n",
            "Iteration 266, loss = 0.03545231\n",
            "Iteration 267, loss = 0.03547157\n",
            "Iteration 268, loss = 0.03388621\n",
            "Iteration 269, loss = 0.03510459\n",
            "Iteration 270, loss = 0.03452867\n",
            "Iteration 271, loss = 0.03424132\n",
            "Iteration 272, loss = 0.03433933\n",
            "Iteration 273, loss = 0.03510554\n",
            "Iteration 274, loss = 0.03469031\n",
            "Iteration 275, loss = 0.03486962\n",
            "Iteration 276, loss = 0.03648519\n",
            "Iteration 277, loss = 0.03434351\n",
            "Iteration 278, loss = 0.03633991\n",
            "Iteration 279, loss = 0.03411669\n",
            "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(52,), learning_rate='constant',\n",
              "       learning_rate_init=0.01, max_iter=300, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=1e-05,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi_0y1C6e9Er",
        "colab_type": "code",
        "outputId": "48ccc102-c0b3-4397-c6df-e955b2637bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7494, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy5MNJqFys-H",
        "colab_type": "code",
        "outputId": "1f954bc8-5ab1-4d1f-b17f-af5ee462340e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(clf.score(train_data,train_label))\n",
        "print(clf2.score(train_data,train_label))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9879899916597165\n",
            "0.987489574645538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0aiYNsdyuBR",
        "colab_type": "code",
        "outputId": "db0b8180-a0dd-4d64-ee59-354a5d2a4880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(clf.score(validation_data,validation_label))\n",
        "print(clf2.score(validation_data,validation_label))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9826551034022681\n",
            "0.9939959973315544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7DSKjQcyvL0",
        "colab_type": "code",
        "outputId": "41660abb-8ed5-4938-ab17-f34ef0479985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(clf.score(test_data,test_label))\n",
        "print(clf2.score(test_data,test_label))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.97284162378502\n",
            "0.9736992567181246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOJLm3y6dkCs",
        "colab_type": "code",
        "outputId": "75515654-93b5-40d6-a57c-61621ef82a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf2.score(train_data,train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.987489574645538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnUFUI4rdjwi",
        "colab_type": "code",
        "outputId": "d1e4d1e8-2f60-494c-dc4b-e34ff2395dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf2.score(validation_data,validation_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9939959973315544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u7u5mLsirGr",
        "colab_type": "code",
        "outputId": "462fb724-7f57-4bbe-ea1e-bc50408fe533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97284162378502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtNN_G2Bdkpr",
        "colab_type": "code",
        "outputId": "0d9aa424-1288-473e-a4d4-12ffb3e45c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf2.score(test_data,test_label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9736992567181246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63SIF9YCiJ9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
        "enc.fit(train_label.reshape(1,-1).T)\n",
        "train_label_one_hot = enc.transform(train_label.reshape(-1,1))\n",
        "test_label_one_hot = enc.transform(test_label.reshape(-1,1))\n",
        "validation_label_one_hot = enc.transform(validation_label.reshape(-1,1))\n",
        "validation_test_label_one_hot = enc.transform(train_valid_label.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T8IoNGpkVv_",
        "colab_type": "code",
        "outputId": "a26b1540-04cb-4620-969f-e8ef72098d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_label_one_hot.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3498, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxWBf1tjiJm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def next_batch(num, data, labels):\n",
        "    '''\n",
        "    Return a total of `num` random samples and labels. \n",
        "    '''\n",
        "    idx = np.arange(0 , len(data))\n",
        "    np.random.shuffle(idx)\n",
        "    idx = idx[:num]\n",
        "    data_shuffle = [data[ i] for i in idx]\n",
        "    labels_shuffle = [labels[ i] for i in idx]\n",
        "    \n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYHOkr0CiOxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDauxfwliQZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "\n",
        "\n",
        "# saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlClhIpViZoW",
        "colab_type": "text"
      },
      "source": [
        "#### Divide valid in two parts for validation and validation-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhtjHgUwl0Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLrSUA61iQW_",
        "colab_type": "code",
        "outputId": "3f115846-0076-4714-8d2c-a12f36b924ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "plt.hist(np.argmax(train_label_one_hot,axis = 1))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([624., 623., 624., 575., 624., 576., 576., 623., 575., 575.]),\n",
              " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CWpc/8L8ki0lvD1ev0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfNKrbvrmDl6",
        "colab_type": "code",
        "outputId": "8b3a56d4-12f8-42f0-e9e0-f69ff31502fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "plt.hist(np.argmax(validation_label_one_hot,axis = 1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([156., 156., 156., 144., 156., 144., 144., 155., 144., 144.]),\n",
              " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQS9JjTPoJalxBr0kNc6gl6TG/S/I+e4LEKaj1wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX0eodcgiQTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYJZs7GgCy5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle  #train_data, train_label\n",
        "\n",
        "X_train, y_train = shuffle(train_data, train_label_one_hot)\n",
        "validation_data, validation_label_one_hot = validation_data, validation_label_one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4WFIdiuCy53",
        "colab_type": "text"
      },
      "source": [
        "## Setup TensorFlow\n",
        "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "est-t83SCy55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgad6Ny0OjqN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "820e0711-de16-4566-ede8-0b906d7f3c9b"
      },
      "source": [
        "connection_probability = tf.Variable(1.)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZqUctyopqzZ",
        "colab_type": "code",
        "outputId": "818c3d50-7e31-4d36-e3a2-0c4162fb86be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "# print(G_W1.shape)\n",
        "# print(G_W2.shape)\n",
        "# print(G_W3.shape)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5995, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYVUi6tIf1mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(clf.coefs_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6aNutv83RcA",
        "colab_type": "text"
      },
      "source": [
        "#### Define the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "stGmwMYz8vws",
        "colab": {}
      },
      "source": [
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "# G_W3 =  tf.Variable(np.float32(clf.coefs_[2]))\n",
        "# G_b3 = tf.Variable(np.float32(clf.intercepts_ [2]))\n",
        "\n",
        "# G_w_out_h1 = tf.Variable(xavier_init([10,80]))\n",
        "# G_b_out_h1 = tf.Variable(xavier_init([80]))\n",
        "\n",
        "# G_w_h2_h1 = tf.Variable(xavier_init([40,80]))\n",
        "# G_b_h2_h1 = tf.Variable(xavier_init([80]))\n",
        "\n",
        "\n",
        "# G_w_h1_input = tf.Variable(xavier_init([80,16]))\n",
        "# G_b_h1_input = tf.Variable(xavier_init([16]))\n",
        "\n",
        "\n",
        "# G_w_input_h1_h2 = tf.Variable(xavier_init([16,40]))\n",
        "# G_b_h1_input = tf.Variable(xavier_init([40]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bajK44GmiR1",
        "colab_type": "code",
        "outputId": "633f9e08-2a37-478b-b07c-74c7059363f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5995, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hncjRrBbmRDY",
        "colab_type": "code",
        "outputId": "1785c136-2f37-4b56-f070-223716275275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.coefs_[0].shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 52)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sfSdtHU3JfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.contrib.layers import flatten\n",
        "\n",
        "def LeNet(x, test_mode = False):    \n",
        "    # Hyperparameters\n",
        "    mu = 0\n",
        "    sigma = 0.1\n",
        "    layer_depth = {\n",
        "        'layer_1' : 6,\n",
        "        'layer_2' : 16,\n",
        "        'layer_3' : 120,\n",
        "        'layer_f1' : 84\n",
        "    }\n",
        "\n",
        "\n",
        "    \n",
        "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
        "    x_flat = flatten(x)\n",
        "    fc1 = flatten(x)\n",
        "    fdense = fc1\n",
        "    \n",
        "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
        "    fc1_w = G_W1# tf.Variable(tf.truncated_normal(shape = (X_train.shape[1]*X_train.shape[2],300), mean = mu, stddev = sigma))\n",
        "    fc1_b = G_b1# tf.Variable(tf.zeros(300))\n",
        "    fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
        "    \n",
        "    # TODO: Activation.\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "\n",
        "#     # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
        "#     fc2_w = G_W2# tf.Variable(tf.truncated_normal(shape = (300,100), mean = mu, stddev = sigma))\n",
        "#     fc2_b = G_b2# tf.Variable(tf.zeros(100))\n",
        "#     fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
        "#     # TODO: Activation.\n",
        "#     fc2 = tf.nn.relu(fc2)\n",
        "    fc3_w = G_W2\n",
        "    fc3_b = G_b2\n",
        "    \n",
        "    logits = tf.matmul(fc1, fc3_w) + fc3_b\n",
        "    \n",
        "    #################\n",
        "    ##### Inset probability connection from x to conv2\n",
        "    fc2p_w = tf.Variable(xavier_init([X_train.shape[1],clf.coefs_[1].shape[1]]))\n",
        "    fc2p_b = tf.Variable(xavier_init([clf.coefs_[1].shape[1]]))\n",
        "    fc2_2nd_input = tf.matmul(x_flat,fc2p_w) + fc2p_b\n",
        "#     fc2_2nd_input = tf.nn.relu(fc2_2nd_input)\n",
        "    connect2 = tf.logical_and(tf.random.uniform(shape = tf.shape(connection_probability)) < connection_probability, tf.equal(test_mode,False))\n",
        "    logits = tf.cond(connect2,lambda: logits + fc2_2nd_input, lambda: logits )    \n",
        "    ################    \n",
        "#     fc3_w = G_W3\n",
        "#     fc3_b = G_b3\n",
        "    \n",
        "#     logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
        "#     print(logits.shape)\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGmN34tg3_tv",
        "colab_type": "code",
        "outputId": "73033b00-b43f-496d-9780-3861c3beab41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_label_one_hot.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5995, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NX_lWUB6zue",
        "colab_type": "code",
        "outputId": "df41ac8c-bc35-4373-d905-f3c3b6852e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_label"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 3, ..., 6, 3, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3U_MKYr34Xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with tf.name_scope('Input'):\n",
        "\n",
        "  x = tf.placeholder(tf.float32, (None, train_data.shape[1]), name='X')\n",
        "  y = tf.placeholder(\"float\", [None, 1+np.max(train_label)])\n",
        "# one_hot_y = tf.one_hot(y, train_label_one_hot.shape[1])\n",
        "is_testing= tf.placeholder(tf.bool)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rtTKpeM4P8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e6BG9DI3Jb3",
        "colab_type": "code",
        "outputId": "829de8aa-f8e4-4c85-83f7-205390719609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rate = 0.001\n",
        "decay_rate = 1.0005**(X_train.shape[0]/BATCH_SIZE);\n",
        "decay_rate =1.1\n",
        "print(decay_rate)\n",
        "logits = LeNet(x,is_testing)\n",
        "with tf.name_scope('Train'):\n",
        "#   cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
        "#   loss_operation = tf.reduce_mean(cross_entropy, name='loss')\n",
        "  loss_operation = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=LeNet(x, test_mode=False), labels=y))\n",
        "  tf.summary.scalar('loss', loss_operation)\n",
        "# optimizer = tf.train.MomentumOptimizer(learning_rate = rate,momentum=.9)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "# tf.train.natural_exp_decay()\n",
        "training_operation = optimizer.minimize(loss_operation)\n",
        "new_prob = connection_probability.assign(connection_probability/decay_rate)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8eQKHOw7PHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def evaluate(X_data, y_data):\n",
        "correct_pred = tf.equal(tf.argmax(LeNet(x,test_mode=True), 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tb-sFE34OGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
        "# accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# saver = tf.train.Saver()\n",
        "\n",
        "# def evaluate(X_data, y_data):\n",
        "#     num_examples = len(X_data)\n",
        "#     total_accuracy = 0\n",
        "#     sess = tf.get_default_session()\n",
        "#     for offset in range(0, num_examples, BATCH_SIZE):\n",
        "#         batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "#         accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, is_testing: True})\n",
        "#         total_accuracy += (accuracy * len(batch_x))\n",
        "#     tot_acc = total_accuracy / num_examples\n",
        "#     with tf.name_scope('Accuracy'):\n",
        "#       tf.summary.scalar('accuracy', tot_acc)\n",
        "#     return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCovfr0E4oJq",
        "colab_type": "text"
      },
      "source": [
        "### Train the mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGF2PRgw9nLL",
        "colab_type": "code",
        "outputId": "171c81fd-2110-476e-bb54-1312cab04de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "2056*2"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4112"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cl89uCj9hjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 4112"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H5Dgkf69TOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5Kihg685LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQaEeNO285BK",
        "colab_type": "code",
        "outputId": "619f79a5-ccea-4ebe-bbb2-3d3b91985818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5995, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kUXlIo82NoY",
        "colab_type": "code",
        "outputId": "4de1c69e-619e-4aae-a1e9-6b2f29847261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1499, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ZpOoIJHPar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47960
        },
        "outputId": "cfae2937-6208-47cb-bf27-5a58be811558"
      },
      "source": [
        "rate = 0.001\n",
        "# decay_rate = 1.0005**(X_train.shape[0]/BATCH_SIZE);\n",
        "decay_rate =1.26\n",
        "drates = [1.01,1.05,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.9,10]\n",
        "tracked_decay_validation = []\n",
        "for decay_rate in drates:\n",
        "  print(decay_rate)\n",
        "  logits = LeNet(x,is_testing)\n",
        "  with tf.name_scope('Train'):\n",
        "  #   cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
        "  #   loss_operation = tf.reduce_mean(cross_entropy, name='loss')\n",
        "    loss_operation = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=LeNet(x, test_mode=False), labels=y))\n",
        "    tf.summary.scalar('loss', loss_operation)\n",
        "  # optimizer = tf.train.MomentumOptimizer(learning_rate = rate,momentum=.9)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "  # tf.train.natural_exp_decay()\n",
        "  training_operation = optimizer.minimize(loss_operation)\n",
        "  new_prob = connection_probability.assign(connection_probability/decay_rate)\n",
        "\n",
        "  # def evaluate(X_data, y_data):\n",
        "  correct_pred = tf.equal(tf.argmax(LeNet(x,test_mode=True), 1), tf.argmax(y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  validation_accuracy_track = []\n",
        "  train_accuracy_track = []\n",
        "  connection_probability_track = []\n",
        "  number_of_ex = X_train.shape[0]\n",
        "  total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "  epoch_track = []\n",
        "  print_every = 100\n",
        "  with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      num_examples = len(X_train)\n",
        "      best_accuracy_valid = 0\n",
        "      print(\"Training...\")\n",
        "      print()\n",
        "      for i in range(EPOCHS):\n",
        "          X_train, y_train = shuffle(X_train, y_train)\n",
        "          for step in range(0, total_steps_for_one_pass):        \n",
        "            if step>=number_of_ex//BATCH_SIZE:\n",
        "              batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "  #             print(step,'Finishing',step*BATCH_SIZE )\n",
        "              step = 0\n",
        "\n",
        "            else:\n",
        "\n",
        "              start = step*BATCH_SIZE\n",
        "              finish = (step+1)*BATCH_SIZE\n",
        "  #             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "              batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "  #           print(batch_y.shape)\n",
        "            tr_op  = sess.run([training_operation], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "  #           train_writer.add_summary(summary_tr, i)\n",
        "          prob = sess.run(new_prob)\n",
        "          if i%print_every == 0:\n",
        "            tr_accuracy = sess.run(accuracy*100, feed_dict={x: X_train,y:y_train, is_testing: True})  # evaluate(X_train, y_train)\n",
        "            print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True}) #evaluate(X_validation, y_validation)\n",
        "            validation_accuracy_track.append(validation_accuracy)\n",
        "            train_accuracy_track.append(tr_accuracy)\n",
        "            epoch_track.append(i)\n",
        "            connection_probability_track.append(prob)\n",
        "  #           print(\"EPOCH {} ...\".format(i+1))\n",
        "            print(\"Epoch \" + str(i+1) + '/' + str(EPOCHS))\n",
        "            print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "            print(prob)\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "              saver.save(sess, './DNAAdamBased' + str(decay_rate))\n",
        "\n",
        "  #     saver.save(sess, './lenet')\n",
        "      print(\"Model saved\")\n",
        "      tracked_decay_validation.append(best_accuracy_valid)\n",
        "      print(tracked_decay_validation)\n",
        "      print('=*'*50)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.01\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.990099\n",
            "\n",
            "Train Accuracy = 98.28190\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.3660508\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 97.99866\n",
            "0.13533312\n",
            "\n",
            "Train Accuracy = 98.84904\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0500342\n",
            "\n",
            "Train Accuracy = 98.86572\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.018498203\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0068389955\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.002528454\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.00093479815\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.00034560537\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.00012777415\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.33222\n",
            "4.7239566e-05\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "1.7465e-05\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "6.457009e-06\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "2.3872292e-06\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "8.825854e-07\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "3.2630172e-07\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "1.2063745e-07\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "4.4601027e-08\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "1.6489501e-08\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.53236\n",
            "6.0963536e-09\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.59907\n",
            "2.253892e-09\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.59907\n",
            "8.3328905e-10\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "3.0807645e-10\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.59907\n",
            "1.13899334e-10\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "4.2109892e-11\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "1.5568503e-11\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "5.755852e-12\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "2.128004e-12\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "7.867473e-13\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.53236\n",
            "2.908694e-13\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "1.0753768e-13\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "3.97579e-14\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "1.469895e-14\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "5.4343673e-15\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "2.0091471e-15\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "7.4280417e-16\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "2.746231e-16\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "1.01531265e-16\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "3.7537258e-17\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "1.387795e-17\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.79920\n",
            "5.130835e-18\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "1.8969282e-18\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "7.013157e-19\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.39893\n",
            "2.5928442e-19\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "9.5860384e-20\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "3.5440683e-20\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "1.3102818e-20\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "4.844261e-21\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "1.790978e-21\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "6.6214485e-22\n",
            "\n",
            "Model saved\n",
            "[98.7992]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.05\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.952381\n",
            "\n",
            "Train Accuracy = 98.78232\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.13209\n",
            "0.0072424216\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.19880\n",
            "5.507529e-05\n",
            "\n",
            "Train Accuracy = 98.86572\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "4.1882228e-07\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "3.1849523e-09\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "2.4220103e-11\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.8418273e-13\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.4006248e-15\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.0651111e-17\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "8.099682e-20\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "6.159434e-22\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "4.683966e-24\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "3.5619406e-26\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "2.7086922e-28\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "2.0598359e-30\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "1.5664106e-32\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "1.191183e-34\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "9.058394e-37\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.1\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.9090909\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.26551\n",
            "6.596859e-05\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "4.7870397e-09\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "3.4737382e-13\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "2.5207335e-17\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.8291819e-21\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.3273544e-25\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "9.6320045e-30\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "6.9895073e-34\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "5.0719706e-38\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.93262\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.93262\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.73249\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.2\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.8333333\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.13209\n",
            "1.00622035e-08\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "1.214975e-16\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.4670397e-24\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "1.7713981e-32\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.79920\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.3\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.7692308\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.13209\n",
            "3.1025744e-12\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.19880\n",
            "1.2513764e-23\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "5.047237e-35\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.4\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.71428573\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.19880\n",
            "1.7420853e-15\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.33222\n",
            "4.2488057e-30\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.53294\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907, 98.59907]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.5\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.6666667\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.19880\n",
            "1.6397746e-18\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "4.0332912e-36\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.93262\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.79920\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907, 98.59907, 98.932625]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.6\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.625\n",
            "\n",
            "Train Accuracy = 98.86572\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.19880\n",
            "2.42037e-21\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.86591\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907, 98.59907, 98.932625, 98.865906]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.7\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.58823526\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.33222\n",
            "5.3046466e-24\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.86591\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.66578\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907, 98.59907, 98.932625, 98.865906, 98.865906]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "1.9\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.5263158\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.19880\n",
            "7.0127407e-29\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.86591\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907, 98.59907, 98.932625, 98.865906, 98.865906, 98.865906]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
            "10\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.1\n",
            "\n",
            "Train Accuracy = 98.86572\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.19880\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.7992, 98.59907, 98.932625, 98.7992, 98.59907, 98.59907, 98.932625, 98.865906, 98.865906, 98.865906, 98.59907]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxM4R7NrbQdC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78dd4038-76e7-4a07-a6bd-ef6ff3e143f4"
      },
      "source": [
        "# plt.bar(drates[0:-1],tracked_decay_validation[0:-1])\n",
        "drates"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.01, 1.05, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDA7pRBAcskw",
        "colab_type": "text"
      },
      "source": [
        "## Now use decay = 1.1 and retrain for larne number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jifyyiyduBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOeFUYbyc1GG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8619
        },
        "outputId": "626196bb-0c8c-4714-befa-baa3943016f6"
      },
      "source": [
        "rate = 0.001\n",
        "# decay_rate = 1.0005**(X_train.shape[0]/BATCH_SIZE);\n",
        "decay_rate =1.5\n",
        "drates = [1.5]\n",
        "tracked_decay_validation = []\n",
        "for decay_rate in drates:\n",
        "  print(decay_rate)\n",
        "  logits = LeNet(x,is_testing)\n",
        "  with tf.name_scope('Train'):\n",
        "  #   cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
        "  #   loss_operation = tf.reduce_mean(cross_entropy, name='loss')\n",
        "    loss_operation = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=LeNet(x, test_mode=False), labels=y))\n",
        "    tf.summary.scalar('loss', loss_operation)\n",
        "  # optimizer = tf.train.MomentumOptimizer(learning_rate = rate,momentum=.9)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "  # tf.train.natural_exp_decay()\n",
        "  training_operation = optimizer.minimize(loss_operation)\n",
        "  new_prob = connection_probability.assign(connection_probability/decay_rate)\n",
        "\n",
        "  # def evaluate(X_data, y_data):\n",
        "  correct_pred = tf.equal(tf.argmax(LeNet(x,test_mode=True), 1), tf.argmax(y, 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "  validation_accuracy_track = []\n",
        "  train_accuracy_track = []\n",
        "  connection_probability_track = []\n",
        "  number_of_ex = X_train.shape[0]\n",
        "  total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "  epoch_track = []\n",
        "  print_every = 50\n",
        "  with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      num_examples = len(X_train)\n",
        "      best_accuracy_valid = 0\n",
        "      print(\"Training...\")\n",
        "      print()\n",
        "      for i in range(EPOCHS):\n",
        "          X_train, y_train = shuffle(X_train, y_train)\n",
        "          for step in range(0, total_steps_for_one_pass):        \n",
        "            if step>=number_of_ex//BATCH_SIZE:\n",
        "              batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "  #             print(step,'Finishing',step*BATCH_SIZE )\n",
        "              step = 0\n",
        "\n",
        "            else:\n",
        "\n",
        "              start = step*BATCH_SIZE\n",
        "              finish = (step+1)*BATCH_SIZE\n",
        "  #             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "              batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "  #           print(batch_y.shape)\n",
        "            tr_op  = sess.run([training_operation], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "  #           train_writer.add_summary(summary_tr, i)\n",
        "          prob = sess.run(new_prob)\n",
        "          if i%print_every == 0:\n",
        "            tr_accuracy = sess.run(accuracy*100, feed_dict={x: X_train,y:y_train, is_testing: True})  # evaluate(X_train, y_train)\n",
        "            print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "            validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True}) #evaluate(X_validation, y_validation)\n",
        "            validation_accuracy_track.append(validation_accuracy)\n",
        "            train_accuracy_track.append(tr_accuracy)\n",
        "            epoch_track.append(i)\n",
        "            connection_probability_track.append(prob)\n",
        "  #           print(\"EPOCH {} ...\".format(i+1))\n",
        "            print(\"Epoch \" + str(i+1) + '/' + str(EPOCHS))\n",
        "            print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "            print(prob)\n",
        "            print()\n",
        "            if (validation_accuracy >= best_accuracy_valid):\n",
        "              best_accuracy_valid = validation_accuracy\n",
        "              saver.save(sess, './DNAAdamBasedTunedBest')\n",
        "\n",
        "  #     saver.save(sess, './lenet')\n",
        "      print(\"Model saved\")\n",
        "      tracked_decay_validation.append(best_accuracy_valid)\n",
        "      print(tracked_decay_validation)\n",
        "      print('=*'*50)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5\n",
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.6666667\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 51/5000\n",
            "Validation Accuracy = 98.13209\n",
            "1.0455541e-09\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 101/5000\n",
            "Validation Accuracy = 98.19880\n",
            "1.6397746e-18\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 151/5000\n",
            "Validation Accuracy = 98.26551\n",
            "2.5717093e-27\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 201/5000\n",
            "Validation Accuracy = 98.19880\n",
            "4.0332912e-36\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 251/5000\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 301/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 351/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 401/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 451/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 501/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 551/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 651/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 701/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 751/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 851/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 951/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1051/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1151/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1201/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1251/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1301/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1351/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1401/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1451/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1551/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1601/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1651/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1701/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1751/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1851/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 1901/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1951/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2051/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 2101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2151/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2251/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2301/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2351/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2451/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2551/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2601/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2651/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 2701/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2751/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2851/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 2901/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2951/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 3001/5000\n",
            "Validation Accuracy = 98.79920\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3051/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3101/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3151/5000\n",
            "Validation Accuracy = 98.86591\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 3201/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 3251/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3301/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 3351/5000\n",
            "Validation Accuracy = 98.93262\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3401/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3451/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 3501/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3551/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3601/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3651/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3701/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 3751/5000\n",
            "Validation Accuracy = 98.86591\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3801/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 3851/5000\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3901/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 3951/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4001/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41618\n",
            "Epoch 4051/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4101/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4151/5000\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4201/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4251/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4301/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4351/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43286\n",
            "Epoch 4401/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4451/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4501/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.46622\n",
            "Epoch 4551/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4601/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4651/5000\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.44954\n",
            "Epoch 4701/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4751/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 4801/5000\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39950\n",
            "Epoch 4851/5000\n",
            "Validation Accuracy = 98.66578\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4901/5000\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.48290\n",
            "Epoch 4951/5000\n",
            "Validation Accuracy = 98.13209\n",
            "0.0\n",
            "\n",
            "Model saved\n",
            "[98.932625]\n",
            "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmwkpdXVhGor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3a3adb6-b016-42e6-9976-d3bc66b392b1"
      },
      "source": [
        "best_accuracy_valid"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.932625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VP4QWKJ4ODG",
        "colab_type": "code",
        "outputId": "ea3e7137-fbc0-4bb8-cb09-b219bbfd8346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22168
        }
      },
      "source": [
        "\n",
        "# validation_accuracy_track = []\n",
        "# train_accuracy_track = []\n",
        "# connection_probability_track = []\n",
        "# number_of_ex = X_train.shape[0]\n",
        "# total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "# epoch_track = []\n",
        "# print_every = 10\n",
        "# with tf.Session() as sess:\n",
        "#     sess.run(tf.global_variables_initializer())\n",
        "#     num_examples = len(X_train)\n",
        "#     best_accuracy_valid = 0\n",
        "#     print(\"Training...\")\n",
        "#     print()\n",
        "#     for i in range(EPOCHS):\n",
        "#         X_train, y_train = shuffle(X_train, y_train)\n",
        "#         for step in range(0, total_steps_for_one_pass):        \n",
        "#           if step>=number_of_ex//BATCH_SIZE:\n",
        "#             batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "# #             print(step,'Finishing',step*BATCH_SIZE )\n",
        "#             step = 0\n",
        "\n",
        "#           else:\n",
        "\n",
        "#             start = step*BATCH_SIZE\n",
        "#             finish = (step+1)*BATCH_SIZE\n",
        "# #             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "#             batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "# #           print(batch_y.shape)\n",
        "#           tr_op  = sess.run([training_operation], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "# #           train_writer.add_summary(summary_tr, i)\n",
        "#         prob = sess.run(new_prob)\n",
        "#         if i%print_every == 0:\n",
        "#           tr_accuracy = sess.run(accuracy*100, feed_dict={x: X_train,y:y_train, is_testing: True})  # evaluate(X_train, y_train)\n",
        "#           print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "#           validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True}) #evaluate(X_validation, y_validation)\n",
        "#           validation_accuracy_track.append(validation_accuracy)\n",
        "#           train_accuracy_track.append(tr_accuracy)\n",
        "#           epoch_track.append(i)\n",
        "#           connection_probability_track.append(prob)\n",
        "# #           print(\"EPOCH {} ...\".format(i+1))\n",
        "#           print(\"Epoch \" + str(i+1) + '/' + str(EPOCHS))\n",
        "#           print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "#           print(prob)\n",
        "#           print()\n",
        "#           if (validation_accuracy >= best_accuracy_valid):\n",
        "#             best_accuracy_valid = validation_accuracy\n",
        "#             saver.save(sess, './DNAAdamBased')\n",
        "        \n",
        "# #     saver.save(sess, './lenet')\n",
        "#     print(\"Model saved\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\n",
            "Train Accuracy = 98.73228\n",
            "Epoch 1/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.7936508\n",
            "\n",
            "Train Accuracy = 97.79816\n",
            "Epoch 11/2600\n",
            "Validation Accuracy = 97.39826\n",
            "0.07869082\n",
            "\n",
            "Train Accuracy = 98.64887\n",
            "Epoch 21/2600\n",
            "Validation Accuracy = 97.86524\n",
            "0.007802228\n",
            "\n",
            "Train Accuracy = 98.76563\n",
            "Epoch 31/2600\n",
            "Validation Accuracy = 98.13209\n",
            "0.0007735943\n",
            "\n",
            "Train Accuracy = 98.78232\n",
            "Epoch 41/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.6702214e-05\n",
            "\n",
            "Train Accuracy = 98.81568\n",
            "Epoch 51/2600\n",
            "Validation Accuracy = 98.13209\n",
            "7.605058e-06\n",
            "\n",
            "Train Accuracy = 98.84904\n",
            "Epoch 61/2600\n",
            "Validation Accuracy = 98.13209\n",
            "7.540448e-07\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 71/2600\n",
            "Validation Accuracy = 98.13209\n",
            "7.4763875e-08\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 81/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.4128703e-09\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 91/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.349893e-10\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 101/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.2874505e-11\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 111/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.2255383e-12\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 121/2600\n",
            "Validation Accuracy = 98.26551\n",
            "7.164152e-13\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 131/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.1032874e-14\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 141/2600\n",
            "Validation Accuracy = 98.19880\n",
            "7.04294e-15\n",
            "\n",
            "Train Accuracy = 98.84904\n",
            "Epoch 151/2600\n",
            "Validation Accuracy = 98.19880\n",
            "6.983106e-16\n",
            "\n",
            "Train Accuracy = 98.86572\n",
            "Epoch 161/2600\n",
            "Validation Accuracy = 98.19880\n",
            "6.92378e-17\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 171/2600\n",
            "Validation Accuracy = 98.19880\n",
            "6.8649576e-18\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 181/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.8066345e-19\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 191/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.748808e-20\n",
            "\n",
            "Train Accuracy = 98.88240\n",
            "Epoch 201/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.6914715e-21\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 211/2600\n",
            "Validation Accuracy = 98.33222\n",
            "6.634623e-22\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 221/2600\n",
            "Validation Accuracy = 98.19880\n",
            "6.5782574e-23\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 231/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.522371e-24\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 241/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.46696e-25\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 251/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.412019e-26\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 261/2600\n",
            "Validation Accuracy = 98.19880\n",
            "6.357545e-27\n",
            "\n",
            "Train Accuracy = 98.89909\n",
            "Epoch 271/2600\n",
            "Validation Accuracy = 98.33222\n",
            "6.303534e-28\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 281/2600\n",
            "Validation Accuracy = 98.26551\n",
            "6.249981e-29\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 291/2600\n",
            "Validation Accuracy = 98.33222\n",
            "6.1968827e-30\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 301/2600\n",
            "Validation Accuracy = 98.33222\n",
            "6.1442356e-31\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 311/2600\n",
            "Validation Accuracy = 98.33222\n",
            "6.092036e-32\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 321/2600\n",
            "Validation Accuracy = 98.33222\n",
            "6.0402803e-33\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 331/2600\n",
            "Validation Accuracy = 98.33222\n",
            "5.9889633e-34\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 341/2600\n",
            "Validation Accuracy = 98.33222\n",
            "5.938084e-35\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 351/2600\n",
            "Validation Accuracy = 98.33222\n",
            "5.887636e-36\n",
            "\n",
            "Train Accuracy = 98.93244\n",
            "Epoch 361/2600\n",
            "Validation Accuracy = 98.33222\n",
            "5.8376157e-37\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 371/2600\n",
            "Validation Accuracy = 98.33222\n",
            "5.788021e-38\n",
            "\n",
            "Train Accuracy = 98.91576\n",
            "Epoch 381/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 391/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 401/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 411/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 421/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 431/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 441/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 451/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 461/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 471/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 481/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.94912\n",
            "Epoch 491/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 501/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 511/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 521/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 531/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 541/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 551/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 561/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 571/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 581/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 591/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 601/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 611/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.96581\n",
            "Epoch 621/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 631/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 641/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 651/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 661/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.99917\n",
            "Epoch 671/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 681/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 691/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 701/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 711/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 721/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.03252\n",
            "Epoch 731/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 741/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 751/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 761/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 771/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.01585\n",
            "Epoch 781/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 791/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 801/2600\n",
            "Validation Accuracy = 98.33222\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 811/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 821/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 831/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 841/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 98.98248\n",
            "Epoch 851/2600\n",
            "Validation Accuracy = 98.73249\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.08257\n",
            "Epoch 861/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 871/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 881/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 891/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 901/2600\n",
            "Validation Accuracy = 98.26551\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.06589\n",
            "Epoch 911/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 921/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.04921\n",
            "Epoch 931/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 941/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 951/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 961/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 971/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 981/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 991/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 1001/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1011/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1021/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1031/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1041/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1051/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1061/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1071/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1081/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1091/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1101/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1111/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1121/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1131/2600\n",
            "Validation Accuracy = 98.66578\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.13261\n",
            "Epoch 1141/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.11593\n",
            "Epoch 1151/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1161/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1171/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1181/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1191/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1201/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1211/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1221/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1231/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1241/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1251/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1261/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1271/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1281/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1291/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1301/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1311/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1321/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.09925\n",
            "Epoch 1331/2600\n",
            "Validation Accuracy = 98.93262\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1341/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1351/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1361/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1371/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1381/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1391/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1401/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1411/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.16597\n",
            "Epoch 1421/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1431/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1441/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.14929\n",
            "Epoch 1451/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1461/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1471/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1481/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1491/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1501/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1511/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1521/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1531/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1541/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1551/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1561/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1571/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1581/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 1591/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1601/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1611/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1621/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1631/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1641/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1651/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1661/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.21601\n",
            "Epoch 1671/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1681/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1691/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19933\n",
            "Epoch 1701/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1711/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1721/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1731/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1741/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1751/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1761/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1771/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 1781/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1791/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1801/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1811/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23269\n",
            "Epoch 1821/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1831/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 1841/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1851/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1861/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1871/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1881/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1891/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1901/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1911/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 1921/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1931/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1941/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 1951/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1961/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 1971/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 1981/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 1991/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2001/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 2011/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2021/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2031/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2041/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2051/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2061/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2071/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2081/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2091/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2101/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2111/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2121/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2131/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2141/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2151/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2161/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26605\n",
            "Epoch 2171/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2181/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2191/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.24937\n",
            "Epoch 2201/2600\n",
            "Validation Accuracy = 98.73249\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2211/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2221/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2231/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2241/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2251/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2261/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2271/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2281/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2291/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2301/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2311/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2321/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2331/2600\n",
            "Validation Accuracy = 98.59907\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2341/2600\n",
            "Validation Accuracy = 98.39893\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2351/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2361/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2371/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2381/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2391/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2401/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2411/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2421/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2431/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29942\n",
            "Epoch 2441/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2451/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2461/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2471/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2481/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18266\n",
            "Epoch 2491/2600\n",
            "Validation Accuracy = 98.86591\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34946\n",
            "Epoch 2501/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31609\n",
            "Epoch 2511/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2521/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2531/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2541/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.28274\n",
            "Epoch 2551/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2561/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33278\n",
            "Epoch 2571/2600\n",
            "Validation Accuracy = 98.46564\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38282\n",
            "Epoch 2581/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.36614\n",
            "Epoch 2591/2600\n",
            "Validation Accuracy = 98.53236\n",
            "0.0\n",
            "\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zydEA48dDeNA",
        "colab_type": "code",
        "outputId": "1d0486a3-e885-435e-89ef-51f9e198b2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(validation_accuracy_track)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDevMH2N3JZu",
        "colab_type": "code",
        "outputId": "8becf023-5f26-4e74-9467-63d44b0013cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_accuracy_valid"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.932625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhbuJEM0-sVm",
        "colab_type": "code",
        "outputId": "70983b68-8b59-474b-84f3-db00bf02fad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './DNAAdamBasedTunedBest')\n",
        "    saver.save(sess, './PendigitReducedAdamProbability')\n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True})\n",
        "    print(\"Validation Accuracy = {:.6f}\".format(validation_accuracy))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./DNAAdamBasedTunedBest\n",
            "Validation Accuracy = 98.932625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5okZYa4CSqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import spline\n",
        "from scipy.signal import savgol_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ou2-UqDCXZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_plot =  [step for step in range(0, epoch_track[-1], print_every)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6G17qZY_Pxq",
        "colab_type": "code",
        "outputId": "9b46a21a-9fee-4811-de5c-ce36c1e21011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(validation_accuracy_track)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNS-YE0XCg4s",
        "colab_type": "code",
        "outputId": "d0e4fd42-3095-44e9-8cfa-58fc099487cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# plt.plot( savgol_filter(np.asarray(validation_accuracy_track),51,1))\n",
        "plt.plot( (validation_accuracy_track))\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7445a7eb38>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURSlg1DRVxRF6SBU9BVFUTqI/x+FN/MxSzs8TQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBlFJwfn-45J",
        "colab_type": "code",
        "outputId": "2a955caa-6d89-472d-9a9b-16fb0fa46369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot( (connection_probability_track))\n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7445750908>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJWkF/X//ZlvpRSfVnwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCKAiyEFCg2F",
        "colab_type": "code",
        "outputId": "f25908a0-715b-4fbc-8176-fee884f38bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "steps_plot = epoch_track# [step for step in range(0, 2291, print_every)]\n",
        "# plt.plot(steps_plot, 100*np.asarray(train_accuracy))\n",
        "# plt.plot(steps_plot, val_accuracy)\n",
        "\n",
        "plt.plot(steps_plot, np.asarray(train_accuracy_track))  \n",
        "plt.plot(steps_plot, validation_accuracy_track)\n",
        "plt.tight_layout()\n",
        "# plt.xticks(np.arange(min(steps_plot), max(steps_plot)+1, 2000))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid(abs)\n",
        "plt.show()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEYCAYAAAAwH9PuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7hYf8U_CXWh",
        "colab_type": "code",
        "outputId": "2efb6ac7-f482-4bf4-bc66-b6132b1b2b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "valid_accuracy_filtered = validation_accuracy_track\n",
        "print(max(valid_accuracy_filtered))\n",
        "valid_accuracy_filtered_np = np.asarray(valid_accuracy_filtered)\n",
        "print(np.argmax(valid_accuracy_filtered))\n",
        "print(steps_plot[np.argmax(valid_accuracy_filtered)])"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.932625\n",
            "67\n",
            "3350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKucNn6bEZzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lrwM4UUCXTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sio.savemat('PendigitReducedProbBasedValid98p93.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "                                       'train_accuracy_track':train_accuracy_track,\n",
        "                                       'connection_probability_track':connection_probability_track,\n",
        "                                       'epochTrack':epoch_track, 'TestAcc':'test_accuracy',\n",
        "                                                         'BestValidation':best_accuracy_valid})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFCL8d7-CIxP",
        "colab_type": "text"
      },
      "source": [
        "### Now  retrain til 3351 Epochs and Train Accuracy = 99.18266"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqMxUbZCIRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keep aside \n",
        "aside_examples= 1\n",
        "aside_valid_test = train_valid_combined[-aside_examples:]\n",
        "aside_valid_test_label = validation_test_label_one_hot[-aside_examples:]\n",
        "combined_train_valid = train_valid_combined[:train_valid_combined.shape[0]-aside_examples,:]\n",
        "combined_train_valid_label = validation_test_label_one_hot[:train_valid_combined.shape[0]-aside_examples,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n7bYp9-FCn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 3351"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcTlcfYNshTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "275ca63c-59a3-48f6-a7a0-30c35d11aad9"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5995, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO0IpQ4hslRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8400dc3c-e4d7-493b-d208-735e55ff786e"
      },
      "source": [
        "validation_data.shape"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1499, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTIcanYdrqw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09a6eaf8-708a-41fd-d286-8e6f037334fd"
      },
      "source": [
        "print(decay_rate)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puoBTQ3fCIOT",
        "colab_type": "code",
        "outputId": "7d2fcee9-1aef-49a2-e7cf-f73f84a1e4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5848
        }
      },
      "source": [
        "\n",
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = combined_train_valid.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "\n",
        "print_every = 50\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(X_train)\n",
        "    best_accuracy_valid = 0\n",
        "    print(\"Training...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        X_train, y_train = shuffle(combined_train_valid, combined_train_valid_label)\n",
        "        for step in range(0, total_steps_for_one_pass):        \n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:],y_train[step*BATCH_SIZE:]\n",
        "#             print(step,'Finishing',step*BATCH_SIZE )\n",
        "            step = 0\n",
        "\n",
        "          else:\n",
        "\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "#             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "            batch_x, batch_y = X_train[step:finish,:],y_train[step:finish]\n",
        "#           print(batch_y.shape)\n",
        "          tr_op  = sess.run([training_operation], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "#           train_writer.add_summary(summary_tr, i)\n",
        "        prob = sess.run(new_prob)\n",
        "        if i%print_every == 0:\n",
        "          tr_accuracy = sess.run(accuracy*100, feed_dict={x: X_train,y:y_train, is_testing: True})  # evaluate(X_train, y_train)\n",
        "          print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "          validation_accuracy = sess.run(accuracy*100, feed_dict={x: aside_valid_test,y:aside_valid_test_label, is_testing: True}) #evaluate(X_validation, y_validation)\n",
        "          validation_accuracy_track.append(validation_accuracy)\n",
        "          train_accuracy_track.append(tr_accuracy)\n",
        "          connection_probability_track.append(prob)\n",
        "          print(\"EPOCH {} ...\".format(i+1))\n",
        "          print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "          print(prob)\n",
        "          print()\n",
        "          if (validation_accuracy >= best_accuracy_valid):\n",
        "            best_accuracy_valid = validation_accuracy\n",
        "            saver.save(sess, './PendigitAllPassReducedDataTemp')\n",
        "    saver.save(sess, './PendigitAllPassReducedData')   \n",
        "#     saver.save(sess, './lenet')\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\n",
            "Train Accuracy = 98.66542\n",
            "EPOCH 1 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.9090909\n",
            "\n",
            "Train Accuracy = 98.67876\n",
            "EPOCH 51 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0077441256\n",
            "\n",
            "Train Accuracy = 98.81223\n",
            "EPOCH 101 ...\n",
            "Validation Accuracy = 100.00000\n",
            "6.596859e-05\n",
            "\n",
            "Train Accuracy = 98.86561\n",
            "EPOCH 151 ...\n",
            "Validation Accuracy = 100.00000\n",
            "5.619558e-07\n",
            "\n",
            "Train Accuracy = 98.87895\n",
            "EPOCH 201 ...\n",
            "Validation Accuracy = 100.00000\n",
            "4.7870397e-09\n",
            "\n",
            "Train Accuracy = 98.89230\n",
            "EPOCH 251 ...\n",
            "Validation Accuracy = 100.00000\n",
            "4.077858e-11\n",
            "\n",
            "Train Accuracy = 98.93233\n",
            "EPOCH 301 ...\n",
            "Validation Accuracy = 100.00000\n",
            "3.4737382e-13\n",
            "\n",
            "Train Accuracy = 98.93233\n",
            "EPOCH 351 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.9591168e-15\n",
            "\n",
            "Train Accuracy = 98.94569\n",
            "EPOCH 401 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.5207335e-17\n",
            "\n",
            "Train Accuracy = 98.94569\n",
            "EPOCH 451 ...\n",
            "Validation Accuracy = 100.00000\n",
            "2.147296e-19\n",
            "\n",
            "Train Accuracy = 98.98572\n",
            "EPOCH 501 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.8291819e-21\n",
            "\n",
            "Train Accuracy = 98.98572\n",
            "EPOCH 551 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.5581951e-23\n",
            "\n",
            "Train Accuracy = 99.02576\n",
            "EPOCH 601 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.3273544e-25\n",
            "\n",
            "Train Accuracy = 99.03910\n",
            "EPOCH 651 ...\n",
            "Validation Accuracy = 100.00000\n",
            "1.1307116e-27\n",
            "\n",
            "Train Accuracy = 99.05244\n",
            "EPOCH 701 ...\n",
            "Validation Accuracy = 100.00000\n",
            "9.6320045e-30\n",
            "\n",
            "Train Accuracy = 99.22594\n",
            "EPOCH 751 ...\n",
            "Validation Accuracy = 100.00000\n",
            "8.205059e-32\n",
            "\n",
            "Train Accuracy = 99.05244\n",
            "EPOCH 801 ...\n",
            "Validation Accuracy = 100.00000\n",
            "6.9895073e-34\n",
            "\n",
            "Train Accuracy = 99.07914\n",
            "EPOCH 851 ...\n",
            "Validation Accuracy = 100.00000\n",
            "5.954038e-36\n",
            "\n",
            "Train Accuracy = 99.09248\n",
            "EPOCH 901 ...\n",
            "Validation Accuracy = 100.00000\n",
            "5.0719706e-38\n",
            "\n",
            "Train Accuracy = 99.10583\n",
            "EPOCH 951 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.10583\n",
            "EPOCH 1001 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18591\n",
            "EPOCH 1051 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.15922\n",
            "EPOCH 1101 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.15922\n",
            "EPOCH 1151 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19926\n",
            "EPOCH 1201 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.17256\n",
            "EPOCH 1251 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19926\n",
            "EPOCH 1301 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18591\n",
            "EPOCH 1351 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 1401 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.18591\n",
            "EPOCH 1451 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19926\n",
            "EPOCH 1501 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.19926\n",
            "EPOCH 1551 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.22594\n",
            "EPOCH 1601 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.22594\n",
            "EPOCH 1651 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23929\n",
            "EPOCH 1701 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.22594\n",
            "EPOCH 1751 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23929\n",
            "EPOCH 1801 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.23929\n",
            "EPOCH 1851 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25263\n",
            "EPOCH 1901 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.26598\n",
            "EPOCH 1951 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25263\n",
            "EPOCH 2001 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.25263\n",
            "EPOCH 2051 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.27933\n",
            "EPOCH 2101 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41279\n",
            "EPOCH 2151 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.27933\n",
            "EPOCH 2201 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 2251 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 2301 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 2351 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 2401 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 2451 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.41279\n",
            "EPOCH 2501 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.29267\n",
            "EPOCH 2551 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.30602\n",
            "EPOCH 2601 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.31937\n",
            "EPOCH 2651 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.43948\n",
            "EPOCH 2701 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.30602\n",
            "EPOCH 2751 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34605\n",
            "EPOCH 2801 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.35941\n",
            "EPOCH 2851 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34605\n",
            "EPOCH 2901 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.30602\n",
            "EPOCH 2951 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34605\n",
            "EPOCH 3001 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.49286\n",
            "EPOCH 3051 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.30602\n",
            "EPOCH 3101 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.33271\n",
            "EPOCH 3151 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39944\n",
            "EPOCH 3201 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.34605\n",
            "EPOCH 3251 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.39944\n",
            "EPOCH 3301 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Train Accuracy = 99.38609\n",
            "EPOCH 3351 ...\n",
            "Validation Accuracy = 100.00000\n",
            "0.0\n",
            "\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImtSTCNJF9E_",
        "colab_type": "code",
        "outputId": "c7fd06a0-8afc-4d95-d40e-b5a3b2d92816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './PendigitAllPassReducedData')\n",
        "#     saver.save(sess, './HarReducedAdamAllPass')  \n",
        "    validation_accuracy = sess.run(accuracy*100, feed_dict={x: validation_data,y:validation_label_one_hot, is_testing: True})\n",
        "    print(\"Validation Accuracy = {:.6f}\".format(validation_accuracy))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./PendigitAllPassReducedData\n",
            "Validation Accuracy = 99.332886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FVMAeXpCIL8",
        "colab_type": "code",
        "outputId": "1fb217c7-5576-472b-9331-5c7ac73ebaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Without all pass\n",
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './PendigitAllPassReducedData')\n",
        "    test_accuracy = sess.run(accuracy*100, feed_dict={x: test_data,y:test_label_one_hot, is_testing: True})\n",
        "    print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./PendigitAllPassReducedData\n",
            "Test Accuracy = 97.684387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGUWHQR3CIJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXCpiAuCIGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGYzlt7KCIDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr57zkSqCIAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q08ZXCdr-sTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Without all pass\n",
        "# with tf.Session() as sess:\n",
        "# #     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "#     saver.restore(sess, './PendigitSGDBased')\n",
        "#     test_accuracy = sess.run(accuracy*100, feed_dict={x: test_data,y:test_label_one_hot, is_testing: True})\n",
        "#     print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9z1P1DG-sQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW6V7O1e-sNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochTrack = epoch_track\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7lCgbXR3JXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFfzfjOB3JTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V98p7T98p43_LeNEt300_100EpochBasedPRob_Decay1p0005.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/preritt/Embed/blob/master/V98p7T98p43_LeNEt300_100EpochBasedPRob_Decay1p0005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qWL1XvRKt0EI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4rTq2SzhyZgD",
        "colab_type": "code",
        "outputId": "758b3ecf-b4fb-47a1-d039-7e6fb08521e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
        "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
        "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
        "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
        "\n",
        "assert(len(X_train) == len(y_train))\n",
        "assert(len(X_validation) == len(y_validation))\n",
        "assert(len(X_test) == len(y_test))\n",
        "\n",
        "print()\n",
        "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
        "print()\n",
        "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
        "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
        "print(\"Test Set:       {} samples\".format(len(X_test)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-566519a95339>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "\n",
            "Image Shape: (28, 28, 1)\n",
            "\n",
            "Training Set:   55000 samples\n",
            "Validation Set: 5000 samples\n",
            "Test Set:       10000 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lopHk729ydu5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = X_train.reshape(X_train.shape[0],-1)\n",
        "train_label = y_train\n",
        "validation_data = X_validation.reshape(X_validation.shape[0],-1)\n",
        "validation_label = y_validation\n",
        "test_data = X_test.reshape(X_test.shape[0],-1)\n",
        "test_label = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VloppGYRyrEX",
        "colab_type": "code",
        "outputId": "b19da83e-9864-4123-b65c-1cc6ff1908b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "# clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "#                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "### acc is 98.41\n",
        "clf = MLPClassifier(hidden_layer_sizes=(300,100,), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "# clf.fit(train_valid_combined, train_valid_label)\n",
        "clf.fit(train_data, train_label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.27088284\n",
            "Iteration 2, loss = 0.09284897\n",
            "Iteration 3, loss = 0.06362837\n",
            "Iteration 4, loss = 0.04513577\n",
            "Iteration 5, loss = 0.03265040\n",
            "Iteration 6, loss = 0.02556718\n",
            "Iteration 7, loss = 0.01983507\n",
            "Iteration 8, loss = 0.01265771\n",
            "Iteration 9, loss = 0.00954815\n",
            "Iteration 10, loss = 0.00746641\n",
            "Iteration 11, loss = 0.00487287\n",
            "Iteration 12, loss = 0.00280570\n",
            "Iteration 13, loss = 0.00162220\n",
            "Iteration 14, loss = 0.00092841\n",
            "Iteration 15, loss = 0.00073810\n",
            "Iteration 16, loss = 0.00063660\n",
            "Iteration 17, loss = 0.00065059\n",
            "Iteration 18, loss = 0.00056893\n",
            "Iteration 19, loss = 0.00052885\n",
            "Iteration 20, loss = 0.00050482\n",
            "Iteration 21, loss = 0.00049094\n",
            "Iteration 22, loss = 0.00047780\n",
            "Iteration 23, loss = 0.00046712\n",
            "Iteration 24, loss = 0.00045812\n",
            "Iteration 25, loss = 0.00044891\n",
            "Iteration 26, loss = 0.00044162\n",
            "Iteration 27, loss = 0.00043538\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(300, 100), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "8m9_X9bUdZJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined = np.concatenate((train_data, validation_data))\n",
        "train_valid_label = np.concatenate((train_label, validation_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fo_lFxdIc85n",
        "colab_type": "code",
        "outputId": "e3bd7b1a-5ad7-482a-cd80-6173c147ad9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "cell_type": "code",
      "source": [
        "# clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "#                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "### acc is 98.41\n",
        "clf2 = MLPClassifier(hidden_layer_sizes=(300,100,), max_iter=200, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "                    learning_rate_init=.1)\n",
        "# Test set score: 0.950119\n",
        "\n",
        "clf2.fit(train_valid_combined, train_valid_label)\n",
        "# clf2.fit(train_data, train_label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.25907034\n",
            "Iteration 2, loss = 0.09239542\n",
            "Iteration 3, loss = 0.06153412\n",
            "Iteration 4, loss = 0.04633119\n",
            "Iteration 5, loss = 0.03438245\n",
            "Iteration 6, loss = 0.02314845\n",
            "Iteration 7, loss = 0.01970873\n",
            "Iteration 8, loss = 0.01600088\n",
            "Iteration 9, loss = 0.01225262\n",
            "Iteration 10, loss = 0.01059671\n",
            "Iteration 11, loss = 0.00743295\n",
            "Iteration 12, loss = 0.00342327\n",
            "Iteration 13, loss = 0.00159669\n",
            "Iteration 14, loss = 0.00100458\n",
            "Iteration 15, loss = 0.00071399\n",
            "Iteration 16, loss = 0.00058734\n",
            "Iteration 17, loss = 0.00055026\n",
            "Iteration 18, loss = 0.00052253\n",
            "Iteration 19, loss = 0.00050488\n",
            "Iteration 20, loss = 0.00048858\n",
            "Iteration 21, loss = 0.00047578\n",
            "Iteration 22, loss = 0.00046572\n",
            "Iteration 23, loss = 0.00045739\n",
            "Iteration 24, loss = 0.00044846\n",
            "Iteration 25, loss = 0.00044014\n",
            "Iteration 26, loss = 0.00043509\n",
            "Iteration 27, loss = 0.00042904\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(300, 100), learning_rate='constant',\n",
              "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=10, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Wi_0y1C6e9Er",
        "colab_type": "code",
        "outputId": "ec2d7bc6-50bf-4a19-e696-84d121dbcc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_valid_combined.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "oy5MNJqFys-H",
        "colab_type": "code",
        "outputId": "326264d0-cf34-4c16-da10-807a0e622b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(train_data,train_label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "T0aiYNsdyuBR",
        "colab_type": "code",
        "outputId": "4d6b6102-1b28-4d5f-87d2-afa4e097de22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(validation_data,validation_label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "w7DSKjQcyvL0",
        "colab_type": "code",
        "outputId": "f040707e-7731-4631-fc9f-0ef858f27b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(test_data,test_label)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.984"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "bOJLm3y6dkCs",
        "colab_type": "code",
        "outputId": "92da95bb-cdf5-4b60-a678-580ef17bf82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(train_data,train_label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "hnUFUI4rdjwi",
        "colab_type": "code",
        "outputId": "ff33d212-9509-447a-a9e7-f28db3912afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(validation_data,validation_label)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "BtNN_G2Bdkpr",
        "colab_type": "code",
        "outputId": "9ff491a8-7b33-4629-abea-add534da15f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf2.score(test_data,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "HFVqYNiRCy47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LeNet Lab\n",
        "![LeNet Architecture](https://github.com/sujaybabruwad/LeNet-in-Tensorflow/blob/master/lenet.png?raw=1)\n",
        "Source: Yan LeCun"
      ]
    },
    {
      "metadata": {
        "id": "oWv2YnX4IxqB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.tensorboard.plugins import projector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7PXv7fjCy5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "\n",
        "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "t4iqynjrCy5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
        "# X_train, y_train           = mnist.train.images, mnist.train.labels\n",
        "# X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
        "# X_test, y_test             = mnist.test.images, mnist.test.labels\n",
        "\n",
        "# assert(len(X_train) == len(y_train))\n",
        "# assert(len(X_validation) == len(y_validation))\n",
        "# assert(len(X_test) == len(y_test))\n",
        "\n",
        "# print()\n",
        "# print(\"Image Shape: {}\".format(X_train[0].shape))\n",
        "# print()\n",
        "# print(\"Training Set:   {} samples\".format(len(X_train)))\n",
        "# print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
        "# print(\"Test Set:       {} samples\".format(len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8LwdNZ5guEpy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Jm9y17KI5QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "logs_path = \"./logs/embedding/\"  # path to the folder that we want to save the logs for Tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pV8kvNmMCy5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
        "\n",
        "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
        "\n",
        "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QBcHY4jyzH5J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Pad images with 0s\n",
        "# X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "# X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "# X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "    \n",
        "# print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6o1m5ujwMvb",
        "colab_type": "code",
        "outputId": "a5ec00b0-e26d-4967-8a1e-1a91d519f754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "fsvvfG8bwGOe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X_train_reshaped = np.reshape(X_train, newshape=(X_train.shape[0],-1))\n",
        "# X_validation_reshaped= np.reshape(X_validation, newshape=(X_validation.shape[0],-1))\n",
        "# X_test_reshaped= np.reshape(X_test, newshape=(X_test.shape[0],-1))\n",
        "\n",
        "# # X_train_reshaped.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eaMcBCNCvzWq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # clf =MLPClassifier(hidden_layer_sizes=(300,100, ), max_iter=200, alpha=1e-4,\n",
        "# #                     solver='adam', verbose=10, tol=1e-5, random_state=1,\n",
        "# #                     learning_rate_init=.1)\n",
        "# ### acc is 98.41\n",
        "# clf = MLPClassifier(hidden_layer_sizes=(300,100,), max_iter=200, alpha=1e-4,\n",
        "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
        "#                     learning_rate_init=.1)\n",
        "# # Test set score: 0.950119\n",
        "\n",
        "# # clf.fit(train_valid_combined, train_valid_label)\n",
        "# clf.fit(X_train_reshaped, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzbhg-ryyhkD",
        "colab_type": "code",
        "outputId": "aeaac9c2-f477-49f9-f797-350ec0cff60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "cell_type": "code",
      "source": [
        "plt.hist(y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5444., 6179., 5470., 5638., 5307., 4987., 5417., 5715., 5389.,\n",
              "        5454.]),\n",
              " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sfj08N7cwqqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf.score(X_train_reshaped,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTE-oU9NwssQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf.score(X_validation_reshaped,y_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBteDY2jwuF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# clf.score(X_test_reshaped,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cW7cCH1xCy5c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualize Data\n",
        "\n",
        "View a sample from the dataset.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "h7UbBX8RCy5e",
        "colab_type": "code",
        "outputId": "44b1fdc2-b169-495b-c754-69af0e8a9044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "index = random.randint(0, len(X_train))\n",
        "image = X_train[index].squeeze()\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image, cmap=\"gray\")\n",
        "print(y_train[index])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1W6py5mlCy5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data\n",
        "\n",
        "Shuffle the training data.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "UYJZs7GgCy5p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4WFIdiuCy53",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup TensorFlow\n",
        "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "est-t83SCy55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWVHSK0pCy59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TODO: Implement LeNet-5\n",
        "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
        "\n",
        "This is the only cell you need to edit.\n",
        "### Input\n",
        "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
        "\n",
        "### Architecture\n",
        "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Pooling.** The output shape should be 14x14x6.\n",
        "\n",
        "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Pooling.** The output shape should be 5x5x16.\n",
        "\n",
        "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
        "\n",
        "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
        "\n",
        "**Activation.** Your choice of activation function.\n",
        "\n",
        "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
        "\n",
        "### Output\n",
        "Return the result of the 2nd fully connected layer."
      ]
    },
    {
      "metadata": {
        "id": "Vgad6Ny0OjqN",
        "colab_type": "code",
        "outputId": "c90b217b-947e-48c8-be36-41149b1f350d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "connection_probability = tf.Variable(.9999)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YqIQlX7Rtqrz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
        "    return tf.random_normal(shape=size, stddev=xavier_stddev, seed=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Se2Hp4KQvCW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Define weights of the layer\n",
        "\n",
        "G_W1 = tf.Variable(np.float32(clf.coefs_[0]))\n",
        "G_b1 = tf.Variable(np.float32(clf.intercepts_ [0]))\n",
        "\n",
        "G_W2 =  tf.Variable(np.float32(clf.coefs_[1]))\n",
        "G_b2 = tf.Variable(np.float32(clf.intercepts_ [1]))\n",
        "\n",
        "G_W3 =  tf.Variable(np.float32(clf.coefs_[2]))\n",
        "G_b3 = tf.Variable(np.float32(clf.intercepts_ [2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iov1Mky-vohQ",
        "colab_type": "code",
        "outputId": "3f52a0e0-681e-40e6-8e38-90be1e8fc93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.coefs_[2].shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "X1nJmcI7Cy5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.layers import flatten\n",
        "\n",
        "def LeNet(x, test_mode = False):    \n",
        "    # Hyperparameters\n",
        "    mu = 0\n",
        "    sigma = 0.1\n",
        "    layer_depth = {\n",
        "        'layer_1' : 6,\n",
        "        'layer_2' : 16,\n",
        "        'layer_3' : 120,\n",
        "        'layer_f1' : 84\n",
        "    }\n",
        "\n",
        "\n",
        "    \n",
        "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
        "    x_flat = flatten(x)\n",
        "    fc1 = flatten(x)\n",
        "    fdense = fc1\n",
        "    \n",
        "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
        "    fc1_w = G_W1# tf.Variable(tf.truncated_normal(shape = (X_train.shape[1]*X_train.shape[2],300), mean = mu, stddev = sigma))\n",
        "    fc1_b = G_b1# tf.Variable(tf.zeros(300))\n",
        "    fc1 = tf.matmul(fc1,fc1_w) + fc1_b\n",
        "    \n",
        "    # TODO: Activation.\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "\n",
        "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
        "    fc2_w = G_W2# tf.Variable(tf.truncated_normal(shape = (300,100), mean = mu, stddev = sigma))\n",
        "    fc2_b = G_b2# tf.Variable(tf.zeros(100))\n",
        "    fc2 = tf.matmul(fc1,fc2_w) + fc2_b\n",
        "    # TODO: Activation.\n",
        "    fc2 = tf.nn.relu(fc2)\n",
        "    \n",
        "    \n",
        "    #################\n",
        "    ##### Inset probability connection from x to conv2\n",
        "    fc2p_w = tf.Variable(tf.truncated_normal(shape = [X_train.shape[1]*X_train.shape[2],100], mean = mu, stddev = sigma))\n",
        "    fc2p_w = tf.Variable(xavier_init([X_train.shape[1]*X_train.shape[2],clf.coefs_[1].shape[1]]))\n",
        "\n",
        "#     fc2p_b = tf.Variable(tf.zeros(clf.coefs_[1].shape[1]))\n",
        "    fc2p_b = tf.Variable(xavier_init([clf.coefs_[1].shape[1]]))\n",
        "\n",
        "    fc2_2nd_input = tf.matmul(x_flat,fc2p_w) + fc2p_b\n",
        "    fc2_2nd_input = tf.nn.relu(fc2_2nd_input)\n",
        "    connect2 = tf.logical_and(tf.random.uniform(shape = tf.shape(connection_probability)) < connection_probability, tf.equal(test_mode,False))\n",
        "    fc2 = tf.cond(connect2,lambda: fc2 + fc2_2nd_input, lambda: fc2 )    \n",
        "    ################\n",
        "    \n",
        "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
        "#     fc3_w = tf.Variable(tf.truncated_normal(shape = (clf.coefs_[1].shape[1],10), mean = mu , stddev = sigma))\n",
        "#     fc3_w = tf.Variable(tf.truncated_normal(shape = (clf.coefs_[1].shape[1],10), mean = mu , stddev = sigma))\n",
        "\n",
        "#     fc3_b = tf.Variable(tf.zeros(10))\n",
        "    fc3_w = G_W3\n",
        "    fc3_b = G_b3\n",
        "    \n",
        "    logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2V3XEMaYvjDW",
        "colab_type": "code",
        "outputId": "f9d9336e-ba06-4cf8-cf68-350f588ef73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "aCx837c9Cy6E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Features and Labels\n",
        "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
        "\n",
        "`x` is a placeholder for a batch of input images.\n",
        "`y` is a placeholder for a batch of output labels.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "iafVK0DgLRTY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mrb2FHFHCy6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('Input'):\n",
        "\n",
        "  x = tf.placeholder(tf.float32, (None, 28, 28, 1), name='X')\n",
        "  tf.summary.image('input_image', x, max_outputs=5)\n",
        "  y = tf.placeholder(tf.int32, (None), name = 'Y')\n",
        "one_hot_y = tf.one_hot(y, 10)\n",
        "is_testing= tf.placeholder(tf.bool) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uk0pcAjmCy6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Pipeline\n",
        "Create a training pipeline that uses the model to classify MNIST data.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "BPo6q2KkpDVA",
        "colab_type": "code",
        "outputId": "8af5e2fe-0725-463e-f5bc-a8a018117d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape[0]/BATCH_SIZE"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107.421875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "dvZ1AxLnoyr2",
        "colab_type": "code",
        "outputId": "fdb6062d-1dec-4bb9-a445-b08adc3f2647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(55000/512)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107.421875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "37lsIW7Zo7bB",
        "colab_type": "code",
        "outputId": "b520ac16-558b-4ae4-e1a1-573db8dcd20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "1.0002**107.421875"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0217146310875027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "3oYy_Y3FCy6N",
        "colab_type": "code",
        "outputId": "ae458e99-6346-46e0-dc0b-92352efc3fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "rate = 0.001\n",
        "decay_rate = 1.001**(X_train.shape[0]/BATCH_SIZE);\n",
        "print(decay_rate)\n",
        "logits = LeNet(x,is_testing)\n",
        "with tf.name_scope('Train'):\n",
        "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
        "  loss_operation = tf.reduce_mean(cross_entropy, name='loss')\n",
        "  tf.summary.scalar('loss', loss_operation)\n",
        "# optimizer = tf.train.MomentumOptimizer(learning_rate = rate,momentum=.9)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "# tf.train.natural_exp_decay()\n",
        "training_operation = optimizer.minimize(loss_operation)\n",
        "new_prob = connection_probability.assign(connection_probability/decay_rate)\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.113344112147168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRw7tBqHvnh9",
        "colab_type": "code",
        "outputId": "9c081bb8-b0c5-48c8-e610-feab1c46d330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(1/decay_rate)**200"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.721898585221559e-10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "KrMtHo6rCy6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "OMR9XsLBCy6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
        "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "def evaluate(X_data, y_data):\n",
        "    num_examples = len(X_data)\n",
        "    total_accuracy = 0\n",
        "    sess = tf.get_default_session()\n",
        "    for offset in range(0, num_examples, BATCH_SIZE):\n",
        "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
        "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, is_testing: True})\n",
        "        total_accuracy += (accuracy * len(batch_x))\n",
        "    tot_acc = total_accuracy / num_examples\n",
        "    with tf.name_scope('Accuracy'):\n",
        "      tf.summary.scalar('accuracy', tot_acc)\n",
        "    return total_accuracy / num_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Jw7iox3Cy6X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "Run the training data through the training pipeline to train the model.\n",
        "\n",
        "Before each epoch, shuffle the training set.\n",
        "\n",
        "After each epoch, measure the loss and accuracy of the validation set.\n",
        "\n",
        "Save the model after training.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "c98G07hDQG2g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QC1kt_DL1yU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment(images, labels,\n",
        "            resize=None, # (width, height) tuple or None\n",
        "            horizontal_flip=False,\n",
        "            vertical_flip=False,\n",
        "            rotate=0, # Maximum rotation angle in degrees\n",
        "            crop_probability=0, # How often we do crops\n",
        "            crop_min_percent=0.6, # Minimum linear dimension of a crop\n",
        "            crop_max_percent=1.,  # Maximum linear dimension of a crop\n",
        "            mixup=0):  # Mixup coeffecient, see https://arxiv.org/abs/1710.09412.pdf\n",
        "  if resize is not None:\n",
        "    images = tf.image.resize_bilinear(images, resize)\n",
        "  \n",
        "  # My experiments showed that casting on GPU improves training performance\n",
        "  if images.dtype != tf.float32:\n",
        "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)\n",
        "    images = tf.subtract(images, 0.5)\n",
        "    images = tf.multiply(images, 2.0)\n",
        "  labels = tf.to_float(labels)\n",
        "\n",
        "  with tf.name_scope('augmentation'):\n",
        "    shp = tf.shape(images)\n",
        "    batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "    width = tf.cast(width, tf.float32)\n",
        "    height = tf.cast(height, tf.float32)\n",
        "\n",
        "    # The list of affine transformations that our image will go under.\n",
        "    # Every element is Nx8 tensor, where N is a batch size.\n",
        "    transforms = []\n",
        "    identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n",
        "    if horizontal_flip:\n",
        "      coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "      flip_transform = tf.convert_to_tensor(\n",
        "          [-1., 0., width, 0., 1., 0., 0., 0.], dtype=tf.float32)\n",
        "      transforms.append(\n",
        "          tf.where(coin,\n",
        "                   tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if vertical_flip:\n",
        "      coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "      flip_transform = tf.convert_to_tensor(\n",
        "          [1, 0, 0, 0, -1, height, 0, 0], dtype=tf.float32)\n",
        "      transforms.append(\n",
        "          tf.where(coin,\n",
        "                   tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if rotate > 0:\n",
        "      angle_rad = rotate / 180 * math.pi\n",
        "      angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n",
        "      transforms.append(\n",
        "          tf.contrib.image.angles_to_projective_transforms(\n",
        "              angles, height, width))\n",
        "\n",
        "    if crop_probability > 0:\n",
        "      crop_pct = tf.random_uniform([batch_size], crop_min_percent,\n",
        "                                   crop_max_percent)\n",
        "      left = tf.random_uniform([batch_size], 0, width * (1 - crop_pct))\n",
        "      top = tf.random_uniform([batch_size], 0, height * (1 - crop_pct))\n",
        "      crop_transform = tf.stack([\n",
        "          crop_pct,\n",
        "          tf.zeros([batch_size]), top,\n",
        "          tf.zeros([batch_size]), crop_pct, left,\n",
        "          tf.zeros([batch_size]),\n",
        "          tf.zeros([batch_size])\n",
        "      ], 1)\n",
        "\n",
        "      coin = tf.less(\n",
        "          tf.random_uniform([batch_size], 0, 1.0), crop_probability)\n",
        "      transforms.append(\n",
        "          tf.where(coin, crop_transform,\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if transforms:\n",
        "      images = tf.contrib.image.transform(\n",
        "          images,\n",
        "          tf.contrib.image.compose_transforms(*transforms),\n",
        "          interpolation='BILINEAR') # or 'NEAREST'\n",
        "\n",
        "    def cshift(values): # Circular shift in batch dimension\n",
        "      return tf.concat([values[-1:, ...], values[:-1, ...]], 0)\n",
        "\n",
        "    if mixup > 0:\n",
        "      mixup = 1.0 * mixup # Convert to float, as tf.distributions.Beta requires floats.\n",
        "      beta = tf.distributions.Beta(mixup, mixup)\n",
        "      lam = beta.sample(batch_size)\n",
        "      ll = tf.expand_dims(tf.expand_dims(tf.expand_dims(lam, -1), -1), -1)\n",
        "      images = ll * images + (1 - ll) * cshift(images)\n",
        "      labels = lam * labels + (1 - lam) * cshift(labels)\n",
        "\n",
        "  return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siI7jT2RUvYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment_data(dataset, dataset_labels, augementation_factor=1, use_random_rotation=True, use_random_shear=True, use_random_shift=True, use_random_zoom=True):\n",
        "\taugmented_image = []\n",
        "\taugmented_image_labels = []\n",
        "\n",
        "\tfor num in range (0, dataset.shape[0]):\n",
        "\n",
        "\t\tfor i in range(0, augementation_factor):\n",
        "\t\t\t# original image:\n",
        "\t\t\taugmented_image.append(dataset[num])\n",
        "\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\t\t\tif use_random_rotation:\n",
        "\t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_rotation(dataset[num], 20, row_axis=0, col_axis=1, channel_axis=2))\n",
        "\t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\t\t\tif use_random_shear:\n",
        "\t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_shear(dataset[num], 0.2, row_axis=0, col_axis=1, channel_axis=2))\n",
        "\t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\t\t\tif use_random_shift:\n",
        "\t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_shift(dataset[num], 0.2, 0.2, row_axis=0, col_axis=1, channel_axis=2))\n",
        "\t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "# \t\t\tif use_random_zoom:\n",
        "# \t\t\t\taugmented_image.append(tf.contrib.keras.preprocessing.image.random_zoom(dataset[num], 0.9, row_axis=0, col_axis=1, channel_axis=2))\n",
        "# \t\t\t\taugmented_image_labels.append(dataset_labels[num])\n",
        "\n",
        "\treturn np.array(augmented_image), np.array(augmented_image_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Of2PvjkIQikg",
        "colab_type": "code",
        "outputId": "1bc423c4-d79e-4a8c-f1fa-f26a77f6ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "Eb8X_yO6QDIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sw7vjTrPxBDU",
        "colab_type": "code",
        "outputId": "caf086a1-5779-4b29-e8e6-bbf5ab634371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "MbueMHwfEbi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 200\n",
        "BATCH_SIZE= 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "INEVMxw4R0Nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mnist.test.images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYoZ96svRxfO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the test set\n",
        "x_test = mnist.test.images\n",
        "y_test = mnist.test.labels\n",
        "\n",
        "# Initialize the embedding variable with the shape of our desired tensor\n",
        "tensor_shape = (x_test.shape[0] , logits.get_shape()[1].value) # [test_set , h1] = [10000 , 200]\n",
        "embedding_var = tf.Variable(tf.zeros(tensor_shape), \n",
        "                            name='logits_embedding')\n",
        "# assign the tensor that we want to visualize to the embedding variable\n",
        "embedding_assign = embedding_var.assign(logits) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8QrvPzlGSN6S",
        "colab_type": "code",
        "outputId": "cbc5289d-c672-4543-8897-b4bd5f5e691e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# EPOCHS = 2\n",
        "X_train.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "t26ZbqMVoNRr",
        "colab_type": "code",
        "outputId": "f0931e39-3d60-40bc-a6d5-5830d50bd738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "bKU1MIyJCy6Y",
        "colab_type": "code",
        "outputId": "908d0525-05c7-4254-9851-1c1a9112356b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        }
      },
      "cell_type": "code",
      "source": [
        "validation_accuracy_track = []\n",
        "train_accuracy_track = []\n",
        "connection_probability_track = []\n",
        "number_of_ex = X_train.shape[0]\n",
        "total_steps_for_one_pass = number_of_ex//BATCH_SIZE + 1\n",
        "\n",
        "print_every = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    num_examples = len(X_train)\n",
        "    best_accuracy_valid = 0\n",
        "    train_writer = tf.summary.FileWriter(logs_path, sess.graph)\n",
        "\n",
        "    print(\"Training...\")\n",
        "    print()\n",
        "    for i in range(EPOCHS):\n",
        "        X_train, y_train = shuffle(X_train, y_train)\n",
        "        for step in range(0, total_steps_for_one_pass):        \n",
        "          if step>=number_of_ex//BATCH_SIZE:\n",
        "            batch_x, batch_y = X_train[step*BATCH_SIZE:,:,:,:],y_train[step*BATCH_SIZE:]\n",
        "#             print(step,'Finishing',step*BATCH_SIZE )\n",
        "            step = 0\n",
        "\n",
        "          else:\n",
        "\n",
        "            start = step*BATCH_SIZE\n",
        "            finish = (step+1)*BATCH_SIZE\n",
        "#             print(step,'Doing', 'Start = ', start, \"Finish = \", finish)\n",
        "            batch_x, batch_y = X_train[step:finish,:,:,:],y_train[step:finish]\n",
        "#         sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, lr: learn})\n",
        "  \n",
        "  \n",
        "#         for offset in range(0, num_examples + BATCH_SIZE, BATCH_SIZE):\n",
        "#             end = offset + BATCH_SIZE\n",
        "#             if end>X_train.shape[0]:\n",
        "#               end = X_train.shape[0]\n",
        "#             print(offset,end)\n",
        "#             batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
        "            tr_op,summary_tr  = sess.run([training_operation,merged], feed_dict={x: batch_x, y: batch_y, is_testing : False})\n",
        "            train_writer.add_summary(summary_tr, i)\n",
        "        prob = sess.run(new_prob)\n",
        "#         print(prob)\n",
        "        if i%print_every == 0:\n",
        "          tr_accuracy = evaluate(X_train, y_train)\n",
        "          print(\"Train Accuracy = {:.5f}\".format(tr_accuracy))\n",
        "          validation_accuracy = evaluate(X_validation, y_validation)\n",
        "          validation_accuracy_track.append(validation_accuracy)\n",
        "          train_accuracy_track.append(tr_accuracy)\n",
        "          connection_probability_track.append(prob)\n",
        "          print(\"EPOCH {} ...\".format(i+1))\n",
        "          print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
        "          print(prob)\n",
        "          print()\n",
        "          if (validation_accuracy >= best_accuracy_valid):\n",
        "            best_accuracy_valid = validation_accuracy\n",
        "            saver.save(sess, './lenet1p001')\n",
        "        \n",
        "#     saver.save(sess, './lenet')\n",
        "    print(\"Model saved\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 1 ...\n",
            "Validation Accuracy = 0.98560\n",
            "0.8981051\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 11 ...\n",
            "Validation Accuracy = 0.98680\n",
            "0.30692554\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 21 ...\n",
            "Validation Accuracy = 0.98660\n",
            "0.10489118\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 31 ...\n",
            "Validation Accuracy = 0.98680\n",
            "0.03584634\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 41 ...\n",
            "Validation Accuracy = 0.98680\n",
            "0.012250413\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 51 ...\n",
            "Validation Accuracy = 0.98640\n",
            "0.0041865534\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 61 ...\n",
            "Validation Accuracy = 0.98700\n",
            "0.0014307459\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 71 ...\n",
            "Validation Accuracy = 0.98660\n",
            "0.0004889545\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 81 ...\n",
            "Validation Accuracy = 0.98640\n",
            "0.00016709916\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 91 ...\n",
            "Validation Accuracy = 0.98640\n",
            "5.710579e-05\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 101 ...\n",
            "Validation Accuracy = 0.98620\n",
            "1.9515788e-05\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 111 ...\n",
            "Validation Accuracy = 0.98600\n",
            "6.6694806e-06\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 121 ...\n",
            "Validation Accuracy = 0.98620\n",
            "2.2792813e-06\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 131 ...\n",
            "Validation Accuracy = 0.98620\n",
            "7.789396e-07\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 141 ...\n",
            "Validation Accuracy = 0.98620\n",
            "2.66201e-07\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 151 ...\n",
            "Validation Accuracy = 0.98600\n",
            "9.097365e-08\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 161 ...\n",
            "Validation Accuracy = 0.98620\n",
            "3.1090057e-08\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 171 ...\n",
            "Validation Accuracy = 0.98640\n",
            "1.0624961e-08\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 181 ...\n",
            "Validation Accuracy = 0.98660\n",
            "3.6310588e-09\n",
            "\n",
            "Train Accuracy = 1.00000\n",
            "EPOCH 191 ...\n",
            "Validation Accuracy = 0.98640\n",
            "1.2409067e-09\n",
            "\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QOmTLbuCIaZJ",
        "colab_type": "code",
        "outputId": "fe9e8224-f665-4d5b-aed6-43af8a1ca421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "best_accuracy_valid"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.986999996471405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "hUc5BqhdSVtq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_w = 28\n",
        "img_h = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tr1bfaPASS3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.tensorboard.plugins import projector\n",
        "\n",
        "# Create a config object to write the configuration parameters\n",
        "config = projector.ProjectorConfig()\n",
        "\n",
        "# Add embedding variable\n",
        "embedding = config.embeddings.add()\n",
        "embedding.tensor_name = embedding_var.name\n",
        "\n",
        "# Link this tensor to its metadata file (e.g. labels) -> we will create this file later\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "\n",
        "# Specify where you find the sprite. -> we will create this image later\n",
        "embedding.sprite.image_path = 'sprite_images.png'\n",
        "embedding.sprite.single_image_dim.extend([img_w, img_h])\n",
        "\n",
        "# Write a projector_config.pbtxt in the logs_path.\n",
        "# TensorBoard will read this file during startup.\n",
        "projector.visualize_embeddings(train_writer, config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6JnCs7sUUcLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Run session to evaluate the tensor\n",
        "# with tf.Session() as sess:\n",
        "#   x_test_fc1 = sess.run(embedding_assign, feed_dict={x: X_test})\n",
        "\n",
        "#   # Save the tensor in model.ckpt file\n",
        "#   saver = tf.train.Saver()\n",
        "#   saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVIeYA_cCy6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model\n",
        "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
        "\n",
        "Be sure to only do this once!\n",
        "\n",
        "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
        "\n",
        "You do not need to modify this section."
      ]
    },
    {
      "metadata": {
        "id": "O4b5lSD5H_q9",
        "colab_type": "code",
        "outputId": "ca589b3e-a074-4c7b-bcce-6a55e0a4013b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './lenet1p001')\n",
        "    test_accuracy = evaluate(X_validation, y_validation)\n",
        "    print(\"Validation Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./lenet1p001\n",
            "Validation Accuracy = 0.987000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-KeugG2UcKb",
        "colab_type": "code",
        "outputId": "836f2dc3-d874-41f5-c5ef-7e690fe305b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(validation_accuracy_track)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff03c101860>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "r8bS_3E0qKH1",
        "colab_type": "code",
        "outputId": "7aea6e6c-dfa5-47fd-dc7a-30b5e215bccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "#     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "    saver.restore(sess, './lenet1p001')\n",
        "    test_accuracy = evaluate(X_test, y_test)\n",
        "    print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./lenet1p001\n",
            "Test Accuracy = 0.984300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V7Uw7Yj0UaaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MIMkpCgsTwRv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_tmzQ7mUs8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochTrack = [k for k in range(1,201,10)]\n",
        "# epochTrack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AOxPCQoOUSjc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sio.savemat('LeNEt300-100Tracked.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "                                       'train_accuracy_track':train_accuracy_track,\n",
        "                                       'connection_probability_track':connection_probability_track,\n",
        "                                       'epochTrack':epochTrack})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ldZP-eobLvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sio.savemat('LeNEt300-100TrackedV2Test98p42Valid98p74tNoDropConnection.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "#                                        'train_accuracy_track':train_accuracy_track,\n",
        "#                                        'connection_probability_track':connection_probability_track,\n",
        "#                                        'epochTrack':epochTrack, 'TestAcc':test_accuracy,\n",
        "#                                                          'BestValidation':best_accuracy_valid})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZQ52QIrztzH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sio.savemat('V98p70T98p43_LeNEt300_100EpochBasedPRob_Decay1p0005.mat', {'ValidationTracked':validation_accuracy_track,\n",
        "                                       'train_accuracy_track':train_accuracy_track,\n",
        "                                       'connection_probability_track':connection_probability_track,\n",
        "                                       'epochTrack':epochTrack, 'TestAcc':test_accuracy,\n",
        "                                                         'BestValidation':best_accuracy_valid})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVXJD4prT0sh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "{'ValidationTracked'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gATWCb50-pbt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with tf.Session() as sess:\n",
        "# #     saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "#     saver.restore(sess, './lenet')\n",
        "#     test_accuracy = evaluate(X_test, y_test)\n",
        "#     print(\"Test Accuracy = {:.6f}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJONJ7CeCy6f",
        "colab_type": "code",
        "outputId": "99ef394d-dcd7-4efc-d863-1bb1c8dfd18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3131
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
        "#     saver.restore(sess, './lenet')\n",
        "    x_test_fc1 = sess.run(embedding_assign, feed_dict={x: X_test,is_testing: True})\n",
        "\n",
        "    # Save the tensor in model.ckpt file\n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, os.path.join(logs_path, \"model.ckpt\"), i)\n",
        "    test_accuracy = evaluate(X_test, y_test)\n",
        "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./lenet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key logits_embedding_3 not found in checkpoint\n\t [[{{node save_5/RestoreV2}}]]\n\t [[{{node save_5/RestoreV2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\nCaused by op 'save_5/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-76-789083789e7d>\", line 7, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1591\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1592\u001b[0m   object_graph_proto = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 370\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-2a49aef686ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     saver.restore(sess, './lenet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_test_fc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_assign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_testing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1292\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\nCaused by op 'save_5/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-76-789083789e7d>\", line 7, in <module>\n    saver = tf.train.Saver()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey logits_embedding_3 not found in checkpoint\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n\t [[node save_5/RestoreV2 (defined at <ipython-input-76-789083789e7d>:7) ]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qvRqnUrrCy6m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def write_sprite_image(filename, images):\n",
        "    \"\"\"\n",
        "        Create a sprite image consisting of sample images\n",
        "        :param filename: name of the file to save on disk\n",
        "        :param shape: tensor of flattened images\n",
        "    \"\"\"\n",
        "\n",
        "    # Invert grayscale image\n",
        "    images = 1 - images\n",
        "\n",
        "    # Calculate number of plot\n",
        "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
        "\n",
        "    # Make the background of sprite image\n",
        "    sprite_image = np.ones((img_h * n_plots, img_w * n_plots))\n",
        "\n",
        "    for i in range(n_plots):\n",
        "        for j in range(n_plots):\n",
        "            img_idx = i * n_plots + j\n",
        "            if img_idx < images.shape[0]:\n",
        "                img = images[img_idx]\n",
        "                sprite_image[i * img_h:(i + 1) * img_h,\n",
        "                j * img_w:(j + 1) * img_w] = img\n",
        "\n",
        "    plt.imsave(filename, sprite_image, cmap='gray')\n",
        "    print('Sprite image saved in {}'.format(filename))\n",
        "\n",
        "def write_metadata(filename, labels):\n",
        "    \"\"\"\n",
        "            Create a metadata file image consisting of sample indices and labels\n",
        "            :param filename: name of the file to save on disk\n",
        "            :param shape: tensor of labels\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"Index\\tLabel\\n\")\n",
        "        for index, label in enumerate(labels):\n",
        "            f.write(\"{}\\t{}\\n\".format(index, label))\n",
        "\n",
        "    print('Metadata file saved in {}'.format(filename))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vE0ULEJ7XGlH",
        "colab_type": "code",
        "outputId": "521734b2-6287-4ee4-e907-495d334f9f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "F-zHFsYHWvrv",
        "colab_type": "code",
        "outputId": "54ffa52c-c52a-47e8-a521-bb74797f586b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Reshape images from vector to matrix\n",
        "x_test_images = np.reshape(np.array(X_test), (-1, img_w, img_h))\n",
        "# Reshape labels from one-hot-encode to index\n",
        "x_test_labels = y_test\n",
        "\n",
        "write_sprite_image(os.path.join(logs_path, 'sprite_images.png'), x_test_images)\n",
        "write_metadata(os.path.join(logs_path, 'metadata.tsv'), x_test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sprite image saved in ./logs/embedding/sprite_images.png\n",
            "Metadata file saved in ./logs/embedding/metadata.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uPVpeenpW8sp",
        "colab_type": "code",
        "outputId": "23e1a68e-78ab-4b89-d0ff-571473bf15b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "# logdir=logs/embedding/\n",
        "LOG_DIR = 'logs/embedding/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 22:31:50--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.73.94.166, 52.45.111.123, 52.4.95.48, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.73.94.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14977695 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.28M  7.04MB/s    in 2.0s    \n",
            "\n",
            "2019-04-07 22:31:53 (7.04 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14977695/14977695]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sULv8PgRXp2j",
        "colab_type": "code",
        "outputId": "7e8c41b2-028f-4d9d-ff5b-4cf9db24e07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ngrok_url = !curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "        \n",
        "ngrok_url = ngrok_url[0].replace(\"'\", '')\n",
        "print(ngrok_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://d310ebff.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7TjVgm-X6N1",
        "colab_type": "code",
        "outputId": "b58870c5-0ee1-4f23-f15e-fd4e0a933754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(ngrok_url, width=700, height=900)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"700\"\n",
              "            height=\"900\"\n",
              "            src=\"https://d310ebff.ngrok.io\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f82b37fed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "u5OZDSZ7X9eO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}